{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Industrial Applications of Artificial Intelligence - Predicting Salary and possible Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is part of the third hand-in regarding the tertiary sector in the lecture Industrial Applications of AI by Niklas Sabel (Matr. no. 1599748)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit decisions, personal potential evaluation or support in judgements. Machine Learning algorithms are touching more and more areas of people's personal lives. However, this is not always benefitial. A sensation has been caused in 2016 by the publication of ProPublica about the software COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) that should help in discovering the underlying risk of a criminal becoming a recidivist [[1]](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing). The authors found out that the algorithm is highly biased towards black people such that \"black defendants are far more likely than white defendants to be incorrectly judged to be at a higher risk of recidivism\" [[2]](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm). This impressively illustrates that if developers and designers are not careful, human bias is picked up by algorithms leading to highly unfair results. Therefore, one has to be especially cautious involving personal sensitive data, for example sex, political attitude or religious affiliation. In the following notebook, we explore the influence of sensitive information in the case of income prediction and investigate how sensitive data can influence the decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold\n",
    "from sklearn.feature_selection import f_classif, RFECV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be found on kaggle unter the following [URL](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset).  It was published by the Center for Machine Learning and Intelligent Systems of the University of California and the original dataset can be found under the following [link](http://www.cs.toronto.edu/~delve/data/adult/desc.html). The task is modelled as a binary classification to predict if an individual's income excceds $50,000 based on data from the US Census Bureau. We want to explore if sensitive information does have an influence on the result and compare it to the case, when some features are discarded.\n",
    "First of all, the dataset consists out of 48,842 entries containing 14 features and one target, which will be described in the following. We are not given a test set such that we have to create a split in the course of the work.\n",
    "* age: Integer indicating the age of a person.\n",
    "* workclass: Categorical variable indicating the employment status of a person.\n",
    "* fnlwgt: Integer without further description. Nearly unique value per row, so might be kind of an identifier that may need to be discarded.\n",
    "* education: Categorical variable indicating the highest degree of a person. \n",
    "* educational-num: Integer indicating the number of years spent on education.\n",
    "* marital-status: Categorical variable indicating the marriage status.\n",
    "* occupation: Categorical variable that indicates the employment type that a person has. \n",
    "* relationship: Categorical variable indicating the relationship status.\n",
    "* race: Categorical variable indicating the origin of a person.\n",
    "* gender: Binary variable that indicates wether a person is male or female.\n",
    "* capital-gain: Integer indicating if a person has capital gains.\n",
    "* capital-loss: Integer indicating if a person has capital losses.\n",
    "* hours-per-week: Integer indicating how much hours a person works per week\n",
    "* native-country: Categorical variable indicating the native-country of a person.\n",
    "* income: Target. Binary variable that indicates wether a person has more than 50k income or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path ='../../src/data/Abgabe_3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>198693</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>?</td>\n",
       "      <td>227026</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>104626</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>3103</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>Private</td>\n",
       "      <td>369667</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>Private</td>\n",
       "      <td>104996</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  educational-num  \\\n",
       "0   25           Private  226802          11th                7   \n",
       "1   38           Private   89814       HS-grad                9   \n",
       "2   28         Local-gov  336951    Assoc-acdm               12   \n",
       "3   44           Private  160323  Some-college               10   \n",
       "4   18                 ?  103497  Some-college               10   \n",
       "5   34           Private  198693          10th                6   \n",
       "6   29                 ?  227026       HS-grad                9   \n",
       "7   63  Self-emp-not-inc  104626   Prof-school               15   \n",
       "8   24           Private  369667  Some-college               10   \n",
       "9   55           Private  104996       7th-8th                4   \n",
       "\n",
       "       marital-status         occupation   relationship   race  gender  \\\n",
       "0       Never-married  Machine-op-inspct      Own-child  Black    Male   \n",
       "1  Married-civ-spouse    Farming-fishing        Husband  White    Male   \n",
       "2  Married-civ-spouse    Protective-serv        Husband  White    Male   \n",
       "3  Married-civ-spouse  Machine-op-inspct        Husband  Black    Male   \n",
       "4       Never-married                  ?      Own-child  White  Female   \n",
       "5       Never-married      Other-service  Not-in-family  White    Male   \n",
       "6       Never-married                  ?      Unmarried  Black    Male   \n",
       "7  Married-civ-spouse     Prof-specialty        Husband  White    Male   \n",
       "8       Never-married      Other-service      Unmarried  White  Female   \n",
       "9  Married-civ-spouse       Craft-repair        Husband  White    Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0             0             0              40  United-States  <=50K  \n",
       "1             0             0              50  United-States  <=50K  \n",
       "2             0             0              40  United-States   >50K  \n",
       "3          7688             0              40  United-States   >50K  \n",
       "4             0             0              30  United-States  <=50K  \n",
       "5             0             0              30  United-States  <=50K  \n",
       "6             0             0              40  United-States  <=50K  \n",
       "7          3103             0              32  United-States   >50K  \n",
       "8             0             0              40  United-States  <=50K  \n",
       "9             0             0              10  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(dir_path, \"adult.csv\"))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>48842.00</td>\n",
       "      <td>38.64</td>\n",
       "      <td>13.71</td>\n",
       "      <td>17.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>48842.00</td>\n",
       "      <td>189664.13</td>\n",
       "      <td>105604.03</td>\n",
       "      <td>12285.00</td>\n",
       "      <td>117550.50</td>\n",
       "      <td>178144.50</td>\n",
       "      <td>237642.00</td>\n",
       "      <td>1490400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational-num</th>\n",
       "      <td>48842.00</td>\n",
       "      <td>10.08</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>48842.00</td>\n",
       "      <td>1079.07</td>\n",
       "      <td>7452.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>48842.00</td>\n",
       "      <td>87.50</td>\n",
       "      <td>403.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4356.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>48842.00</td>\n",
       "      <td>40.42</td>\n",
       "      <td>12.39</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       mean        std       min        25%  \\\n",
       "age              48842.00      38.64      13.71     17.00      28.00   \n",
       "fnlwgt           48842.00  189664.13  105604.03  12285.00  117550.50   \n",
       "educational-num  48842.00      10.08       2.57      1.00       9.00   \n",
       "capital-gain     48842.00    1079.07    7452.02      0.00       0.00   \n",
       "capital-loss     48842.00      87.50     403.00      0.00       0.00   \n",
       "hours-per-week   48842.00      40.42      12.39      1.00      40.00   \n",
       "\n",
       "                       50%        75%         max  \n",
       "age                  37.00      48.00       90.00  \n",
       "fnlwgt           178144.50  237642.00  1490400.00  \n",
       "educational-num      10.00      12.00       16.00  \n",
       "capital-gain          0.00       0.00    99999.00  \n",
       "capital-loss          0.00       0.00     4356.00  \n",
       "hours-per-week       40.00      45.00       99.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at distribution\n",
    "df.describe().transpose().applymap(\"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that we have two highly critical features inside our data: race and gender. On top of that, the native-country could have an influence as well. If an algorithm would be totally objective, neither of these variables should have big influence on the result. That means the distribution of income should not differ wether a person is male or female or he/she belongs to a different race. As a first step, we explore the distribution of those variables and investigate if there are already obvious conspicuities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender  income\n",
       "Female  <=50K     14423\n",
       "        >50K       1769\n",
       "Male    <=50K     22732\n",
       "        >50K       9918\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('gender').income.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race                income\n",
       "Amer-Indian-Eskimo  <=50K       415\n",
       "                    >50K         55\n",
       "Asian-Pac-Islander  <=50K      1110\n",
       "                    >50K        409\n",
       "Black               <=50K      4119\n",
       "                    >50K        566\n",
       "Other               <=50K       356\n",
       "                    >50K         50\n",
       "White               <=50K     31155\n",
       "                    >50K      10607\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('race').income.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax, ax2) = plt.subplots(2, 1,  figsize=(10,10))\n",
    "\n",
    "df.groupby('gender').income.value_counts().plot(kind='barh',ax=ax)\n",
    "ax.set_ylabel('Gender')\n",
    "[ax.text(v+700, i, '{:}'.format(v), horizontalalignment='center') for i, v in enumerate(df.groupby('gender').income.value_counts())]\n",
    "df.groupby('race').income.value_counts().plot(kind='barh',ax=ax2)\n",
    "ax2.set_ylabel('Race')\n",
    "[ax2.text(v+1000, i, '{:}'.format(v), horizontalalignment='center') for i, v in enumerate(df.groupby('race').income.value_counts())]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is already a difference in the distribution towards women having less income than men. In the case of the race feature, it is also obvious that the distributions differ a lot with white people having higher income overall, which looks a lot like bias. The question remains if this is picked up by an algorithm in a way that it is more likely to predict whites having overall higher income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gonna investigate right now, if the distributions of the numerical variables differ a lot for gender. For this reason, we split the dataset based on the feature and have a look at the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male\n",
    "df_male = df[df['gender'] == 'Male']\n",
    "#Female\n",
    "df_female = df[df['gender'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>32650.00</td>\n",
       "      <td>39.49</td>\n",
       "      <td>13.41</td>\n",
       "      <td>17.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>32650.00</td>\n",
       "      <td>191727.02</td>\n",
       "      <td>106709.38</td>\n",
       "      <td>13492.00</td>\n",
       "      <td>117963.00</td>\n",
       "      <td>180138.00</td>\n",
       "      <td>241722.50</td>\n",
       "      <td>1490400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational-num</th>\n",
       "      <td>32650.00</td>\n",
       "      <td>10.09</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>32650.00</td>\n",
       "      <td>1326.21</td>\n",
       "      <td>8367.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>32650.00</td>\n",
       "      <td>100.41</td>\n",
       "      <td>430.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3770.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>32650.00</td>\n",
       "      <td>42.42</td>\n",
       "      <td>12.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       mean        std       min        25%  \\\n",
       "age              32650.00      39.49      13.41     17.00      29.00   \n",
       "fnlwgt           32650.00  191727.02  106709.38  13492.00  117963.00   \n",
       "educational-num  32650.00      10.09       2.66      1.00       9.00   \n",
       "capital-gain     32650.00    1326.21    8367.78      0.00       0.00   \n",
       "capital-loss     32650.00     100.41     430.22      0.00       0.00   \n",
       "hours-per-week   32650.00      42.42      12.12      1.00      40.00   \n",
       "\n",
       "                       50%        75%         max  \n",
       "age                  38.00      48.00       90.00  \n",
       "fnlwgt           180138.00  241722.50  1490400.00  \n",
       "educational-num      10.00      13.00       16.00  \n",
       "capital-gain          0.00       0.00    99999.00  \n",
       "capital-loss          0.00       0.00     3770.00  \n",
       "hours-per-week       40.00      48.00       99.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at distribution\n",
    "df_male.describe().transpose().applymap(\"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>16192.00</td>\n",
       "      <td>36.93</td>\n",
       "      <td>14.14</td>\n",
       "      <td>17.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>16192.00</td>\n",
       "      <td>185504.47</td>\n",
       "      <td>103217.15</td>\n",
       "      <td>12285.00</td>\n",
       "      <td>116560.00</td>\n",
       "      <td>175572.00</td>\n",
       "      <td>228609.25</td>\n",
       "      <td>1484705.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational-num</th>\n",
       "      <td>16192.00</td>\n",
       "      <td>10.04</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>16192.00</td>\n",
       "      <td>580.73</td>\n",
       "      <td>5094.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>16192.00</td>\n",
       "      <td>61.48</td>\n",
       "      <td>340.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4356.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>16192.00</td>\n",
       "      <td>36.40</td>\n",
       "      <td>11.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       mean        std       min        25%  \\\n",
       "age              16192.00      36.93      14.14     17.00      25.00   \n",
       "fnlwgt           16192.00  185504.47  103217.15  12285.00  116560.00   \n",
       "educational-num  16192.00      10.04       2.38      1.00       9.00   \n",
       "capital-gain     16192.00     580.73    5094.23      0.00       0.00   \n",
       "capital-loss     16192.00      61.48     340.11      0.00       0.00   \n",
       "hours-per-week   16192.00      36.40      11.95      1.00      30.00   \n",
       "\n",
       "                       50%        75%         max  \n",
       "age                  35.00      46.00       90.00  \n",
       "fnlwgt           175572.00  228609.25  1484705.00  \n",
       "educational-num      10.00      12.00       16.00  \n",
       "capital-gain          0.00       0.00    99999.00  \n",
       "capital-loss          0.00       0.00     4356.00  \n",
       "hours-per-week       40.00      40.00       99.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at distribution\n",
    "df_female.describe().transpose().applymap(\"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in most cases the statistical properties of the features do not differ by a lot. However, there are two features that stand out: age and hours-per-week. It seems that women in the dataset are overal younger and work less. This might be a possible explanation. In contrast, years of education are higher, which should actually indicate that women earn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we preprocess the dataset and execute predictions, we examine some of the feature distributions to get more insights into the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3,  figsize=(15,8))\n",
    "\n",
    "#list of features to show\n",
    "features = ['gender','race','workclass','educational-num','relationship','marital-status']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        df[features[3*i+j]].value_counts().plot(kind='bar', ax = axes[i,j])\n",
    "fig.tight_layout(h_pad=2, w_pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see that we have a lot more male than female persons within the dataset and that the race distribution is clearly skewed in favor of whites, which could be problematic in the remaining analysis. On top of that, it is also noticeable that the majority of people in the study work in the private sector.\n",
    "Most of people have 9 years of school education, which is equivalent to a high school graduation. Furthermore, it is evident that we have far more people pursuing higher education than stopping before nine years. Regarding relationship and marital-status, it seems that most people are either married or have never-married. We also see that relationship and marital-status might be somehow redundant, because there is a clear overlap. Therefore, we investigate the correlations between all the features in the course of the work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen that the educational level and hours-per-week differ between male and females. We want to further investigate the relations and compare them to each other for sex and race. We normalize the values for better comparison, because the distribution is skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax, ax2) = plt.subplots(1,2 ,  figsize=(15,6))\n",
    "\n",
    "#plot for gender\n",
    "X_axis = np.arange(len(df['educational-num'].unique()))\n",
    "  \n",
    "ax.bar(X_axis - 0.2, df[df['gender']=='Female'].groupby('gender')['educational-num'].value_counts().sort_index().shift(1)/len(df[df['gender']=='Female']), 0.4, label = 'Female')\n",
    "ax.bar(X_axis + 0.2, df[df['gender']=='Male'].groupby('gender')['educational-num'].value_counts().sort_index().shift(1)/len(df[df['gender']=='Male']), 0.4, label = 'Male')\n",
    "  \n",
    "ax.set_xlabel(\"Sex\")\n",
    "ax.set_ylabel(\"Number of people\")\n",
    "ax.set_title(\"Normalized distribution of education within each group\")\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "#plot for race\n",
    "X_axis = np.arange(len(df['educational-num'].unique()))\n",
    "  \n",
    "ax2.bar(X_axis - 0.3, df[df['race']=='Black'].groupby('race')['educational-num'].value_counts().sort_index().shift(1)/len(df[df['race']=='Black']), 0.2, label = 'Black')\n",
    "ax2.bar(X_axis - 0.15, df[df['race']=='White'].groupby('race')['educational-num'].value_counts().sort_index().shift(1)/len(df[df['race']=='White']), 0.2, label = 'White')\n",
    "ax2.bar(X_axis , df[df['race']=='Asian-Pac-Islander'].groupby('race')['educational-num'].value_counts().sort_index().shift(1)/len(df[df['race']=='Asian-Pac-Islander']), 0.2, label = 'Asian-Pac-Islander')\n",
    "ax2.bar(X_axis + 0.15, df[df['race']=='Other'].groupby('race')['educational-num'].value_counts().sort_index().shift(1)/len(df[df['race']=='Other']), 0.2, label = 'Other')\n",
    "ax2.bar(X_axis + 0.3, df[df['race']=='Amer-Indian-Eskimo'].groupby('race')['educational-num'].value_counts().sort_index().shift(1)/len(df[df['race']=='Amer-Indian-Eskimo']), 0.2, label = 'Amer-Indian-Eskimo')\n",
    "  \n",
    "ax2.set_xlabel(\"Race\")\n",
    "ax2.set_ylabel(\"Number of people\")\n",
    "ax2.set_title(\"Normalized distribution of education within each group\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a small tendency for women to have a higher percentage share completing higher education (e.g., a college: 10-12 years). However, the tendency shifts again, when it comes to doctoral degress (>12 years), where the share of man is higher again in percentage.\n",
    "Based on the race there is a clear tendency that Asian-American pursue higher degrees, even doctoral dignities. For the other groups it seems that the main percentage of people having nine years of education, with some exceptions, e.g., Whites having a clear edge in percentage in >=13 years of education over the other groups outside Asian-American. Based on the educational-data, we can see that there might be problematic cases of having different distributions, especially for the races. In contrast, we have already seen that women earn less than men, which cannot be based on the number of years of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we investigate how good an algorithm is able to predict the income and if the distributions may further change due to bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start with our preprocessing, we investigate the feature fnlwgt, because we noticed that it seems to be pretty unique and could therefore be redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48842"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28523"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fnlwgt.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44479</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1719</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt  education  educational-num marital-status  \\\n",
       "44479   23   Private  151910  Bachelors               13  Never-married   \n",
       "48839   58   Private  151910    HS-grad                9        Widowed   \n",
       "\n",
       "              occupation relationship   race  gender  capital-gain  \\\n",
       "44479  Machine-op-inspct    Own-child  White  Female             0   \n",
       "48839       Adm-clerical    Unmarried  White  Female             0   \n",
       "\n",
       "       capital-loss  hours-per-week native-country income  \n",
       "44479          1719              40  United-States  <=50K  \n",
       "48839             0              40  United-States  <=50K  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.fnlwgt==151910]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that more than half of the entries have unique labels in the fnlwgt feature and if two entries have the same, they do not seem to be related. It is for this reason that we discard the feature as it does not offer any generalization improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['fnlwgt'],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass     education  educational-num      marital-status  \\\n",
       "0   25    Private          11th                7       Never-married   \n",
       "1   38    Private       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use an algorithm on the data, we gonna preprocess the features for better usage. In a first step, we check the set for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "education          0\n",
       "educational-num    0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "gender             0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per-week     0\n",
       "native-country     0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in the whole set are no missing values. But is seems like in the dataset missing values are encoded as '?', because the publishers of the dataset state that there are around 7% missing values in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>?</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>58</td>\n",
       "      <td>?</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>?</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>72</td>\n",
       "      <td>?</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48811</th>\n",
       "      <td>35</td>\n",
       "      <td>?</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48812</th>\n",
       "      <td>30</td>\n",
       "      <td>?</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48820</th>\n",
       "      <td>71</td>\n",
       "      <td>?</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48822</th>\n",
       "      <td>41</td>\n",
       "      <td>?</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48823</th>\n",
       "      <td>72</td>\n",
       "      <td>?</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3620 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass     education  educational-num      marital-status  \\\n",
       "4       18         ?  Some-college               10       Never-married   \n",
       "6       29         ?       HS-grad                9       Never-married   \n",
       "13      58         ?       HS-grad                9  Married-civ-spouse   \n",
       "19      40   Private     Doctorate               16  Married-civ-spouse   \n",
       "22      72         ?       7th-8th                4            Divorced   \n",
       "...    ...       ...           ...              ...                 ...   \n",
       "48811   35         ?     Bachelors               13  Married-civ-spouse   \n",
       "48812   30         ?     Bachelors               13       Never-married   \n",
       "48820   71         ?     Doctorate               16  Married-civ-spouse   \n",
       "48822   41         ?       HS-grad                9           Separated   \n",
       "48823   72         ?       HS-grad                9  Married-civ-spouse   \n",
       "\n",
       "           occupation   relationship                race  gender  \\\n",
       "4                   ?      Own-child               White  Female   \n",
       "6                   ?      Unmarried               Black    Male   \n",
       "13                  ?        Husband               White    Male   \n",
       "19     Prof-specialty        Husband  Asian-Pac-Islander    Male   \n",
       "22                  ?  Not-in-family               White  Female   \n",
       "...               ...            ...                 ...     ...   \n",
       "48811               ?           Wife               White  Female   \n",
       "48812               ?  Not-in-family  Asian-Pac-Islander  Female   \n",
       "48820               ?        Husband               White    Male   \n",
       "48822               ?  Not-in-family               Black  Female   \n",
       "48823               ?        Husband               White    Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "4                 0             0              30  United-States  <=50K  \n",
       "6                 0             0              40  United-States  <=50K  \n",
       "13                0             0              35  United-States  <=50K  \n",
       "19                0             0              45              ?   >50K  \n",
       "22                0             0               6  United-States  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "48811             0             0              55  United-States   >50K  \n",
       "48812             0             0              99  United-States  <=50K  \n",
       "48820             0             0              10  United-States   >50K  \n",
       "48822             0             0              32  United-States  <=50K  \n",
       "48823             0             0              25  United-States  <=50K  \n",
       "\n",
       "[3620 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.eq(\"?\").any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature age has 0 missing values\n",
      "Feature workclass has 2799 missing values\n",
      "Feature education has 0 missing values\n",
      "Feature educational-num has 0 missing values\n",
      "Feature marital-status has 0 missing values\n",
      "Feature occupation has 2809 missing values\n",
      "Feature relationship has 0 missing values\n",
      "Feature race has 0 missing values\n",
      "Feature gender has 0 missing values\n",
      "Feature capital-gain has 0 missing values\n",
      "Feature capital-loss has 0 missing values\n",
      "Feature hours-per-week has 0 missing values\n",
      "Feature native-country has 857 missing values\n",
      "Feature income has 0 missing values\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f'Feature {col} has {len(df[df[col]==\"?\"])} missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 3,620 out of 48,842 rows (7.4%) with a least one question mark. We see that only workclass, occupation and native-country have missing values. We also know that workclass and occupation have a clear overlap and if someone does not offer his occupation than we do not get the workclass. First, we have a look at the correlations and see if we can fill features up based on other features. For this reason, we one-hot-encode the categorical features with the exception of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df, columns=[\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"native-country\",\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix=df_ohe.corr()\n",
    "df_corr = corrMatrix[['workclass_?', 'occupation_?','native-country_?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>occupation_?</th>\n",
       "      <th>native-country_?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>workclass_?</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998110</td>\n",
       "      <td>-0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation_?</th>\n",
       "      <td>0.998110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country_?</th>\n",
       "      <td>-0.002088</td>\n",
       "      <td>-0.002202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  workclass_?  occupation_?  native-country_?\n",
       "workclass_?          1.000000      0.998110         -0.002088\n",
       "occupation_?         0.998110      1.000000         -0.002202\n",
       "native-country_?    -0.002088     -0.002202          1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr[(abs(df_corr['workclass_?'])>=0.5) | (abs(df_corr['occupation_?'])>=0.5)|(abs(df_corr['native-country_?'])>=0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the correlations do not offer a lot of value to us, outside the occupation-workclass relationship. However, in most cases both values are missing. Therefore, we will update those values where one is given and the other one not. Since every imputation is not really better than guessing at the moment, we do not fill up the question marks yet and keep them, because they could provide usefull information. In our further work, we might investigate if discarding them completely or imputation, e.g., by median, offers better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8785</th>\n",
       "      <td>17</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>20</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27126</th>\n",
       "      <td>23</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31053</th>\n",
       "      <td>17</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36618</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39513</th>\n",
       "      <td>20</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48585</th>\n",
       "      <td>30</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48595</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass     education  educational-num  \\\n",
       "8785    17  Never-worked          11th                7   \n",
       "11607   20  Never-worked       HS-grad                9   \n",
       "13898   18  Never-worked          11th                7   \n",
       "21642   18  Never-worked          10th                6   \n",
       "27126   23  Never-worked       7th-8th                4   \n",
       "31053   17  Never-worked          10th                6   \n",
       "36618   18  Never-worked          11th                7   \n",
       "39513   20  Never-worked  Some-college               10   \n",
       "48585   30  Never-worked       HS-grad                9   \n",
       "48595   18  Never-worked  Some-college               10   \n",
       "\n",
       "              marital-status occupation    relationship   race  gender  \\\n",
       "8785           Never-married          ?       Own-child  Black  Female   \n",
       "11607  Married-spouse-absent          ?  Other-relative  White    Male   \n",
       "13898          Never-married          ?       Own-child  White    Male   \n",
       "21642          Never-married          ?       Own-child  White    Male   \n",
       "27126               Divorced          ?   Not-in-family  White    Male   \n",
       "31053          Never-married          ?       Own-child  White    Male   \n",
       "36618          Never-married          ?       Own-child  White  Female   \n",
       "39513          Never-married          ?       Own-child  Black    Male   \n",
       "48585     Married-civ-spouse          ?            Wife  Black  Female   \n",
       "48595          Never-married          ?       Own-child  White    Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "8785              0             0              20  United-States  <=50K  \n",
       "11607             0             0              35  United-States  <=50K  \n",
       "13898             0             0              35  United-States  <=50K  \n",
       "21642             0             0              40  United-States  <=50K  \n",
       "27126             0             0              35  United-States  <=50K  \n",
       "31053             0             0              30  United-States  <=50K  \n",
       "36618             0             0              10  United-States  <=50K  \n",
       "39513             0             0              40  United-States  <=50K  \n",
       "48585             0             0              40  United-States  <=50K  \n",
       "48595             0             0               4  United-States  <=50K  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[((df['workclass']=='?')&(df['occupation']!='?'))|((df['workclass']!='?')&(df['occupation']=='?'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in all cases, where an occupation is missing that person has never worked before, which explaines the question mark. We have a short look on other cases with workclass equals never-worked and see if imputing those values would make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8785</th>\n",
       "      <td>17</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>20</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27126</th>\n",
       "      <td>23</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31053</th>\n",
       "      <td>17</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36618</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39513</th>\n",
       "      <td>20</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48585</th>\n",
       "      <td>30</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48595</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass     education  educational-num  \\\n",
       "8785    17  Never-worked          11th                7   \n",
       "11607   20  Never-worked       HS-grad                9   \n",
       "13898   18  Never-worked          11th                7   \n",
       "21642   18  Never-worked          10th                6   \n",
       "27126   23  Never-worked       7th-8th                4   \n",
       "31053   17  Never-worked          10th                6   \n",
       "36618   18  Never-worked          11th                7   \n",
       "39513   20  Never-worked  Some-college               10   \n",
       "48585   30  Never-worked       HS-grad                9   \n",
       "48595   18  Never-worked  Some-college               10   \n",
       "\n",
       "              marital-status occupation    relationship   race  gender  \\\n",
       "8785           Never-married          ?       Own-child  Black  Female   \n",
       "11607  Married-spouse-absent          ?  Other-relative  White    Male   \n",
       "13898          Never-married          ?       Own-child  White    Male   \n",
       "21642          Never-married          ?       Own-child  White    Male   \n",
       "27126               Divorced          ?   Not-in-family  White    Male   \n",
       "31053          Never-married          ?       Own-child  White    Male   \n",
       "36618          Never-married          ?       Own-child  White  Female   \n",
       "39513          Never-married          ?       Own-child  Black    Male   \n",
       "48585     Married-civ-spouse          ?            Wife  Black  Female   \n",
       "48595          Never-married          ?       Own-child  White    Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "8785              0             0              20  United-States  <=50K  \n",
       "11607             0             0              35  United-States  <=50K  \n",
       "13898             0             0              35  United-States  <=50K  \n",
       "21642             0             0              40  United-States  <=50K  \n",
       "27126             0             0              35  United-States  <=50K  \n",
       "31053             0             0              30  United-States  <=50K  \n",
       "36618             0             0              10  United-States  <=50K  \n",
       "39513             0             0              40  United-States  <=50K  \n",
       "48585             0             0              40  United-States  <=50K  \n",
       "48595             0             0               4  United-States  <=50K  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['workclass']=='Never-worked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems, that there are no further cases and the question mark actually delivers information. Since there are more question marks in the occupation column, we will distinguish the never-workers by imputing no occupation instead of the question mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['workclass']=='Never-worked'), 'occupation'] = 'No occupation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8785</th>\n",
       "      <td>17</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11607</th>\n",
       "      <td>20</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27126</th>\n",
       "      <td>23</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31053</th>\n",
       "      <td>17</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36618</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39513</th>\n",
       "      <td>20</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48585</th>\n",
       "      <td>30</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48595</th>\n",
       "      <td>18</td>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>No occupation</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass     education  educational-num  \\\n",
       "8785    17  Never-worked          11th                7   \n",
       "11607   20  Never-worked       HS-grad                9   \n",
       "13898   18  Never-worked          11th                7   \n",
       "21642   18  Never-worked          10th                6   \n",
       "27126   23  Never-worked       7th-8th                4   \n",
       "31053   17  Never-worked          10th                6   \n",
       "36618   18  Never-worked          11th                7   \n",
       "39513   20  Never-worked  Some-college               10   \n",
       "48585   30  Never-worked       HS-grad                9   \n",
       "48595   18  Never-worked  Some-college               10   \n",
       "\n",
       "              marital-status     occupation    relationship   race  gender  \\\n",
       "8785           Never-married  No occupation       Own-child  Black  Female   \n",
       "11607  Married-spouse-absent  No occupation  Other-relative  White    Male   \n",
       "13898          Never-married  No occupation       Own-child  White    Male   \n",
       "21642          Never-married  No occupation       Own-child  White    Male   \n",
       "27126               Divorced  No occupation   Not-in-family  White    Male   \n",
       "31053          Never-married  No occupation       Own-child  White    Male   \n",
       "36618          Never-married  No occupation       Own-child  White  Female   \n",
       "39513          Never-married  No occupation       Own-child  Black    Male   \n",
       "48585     Married-civ-spouse  No occupation            Wife  Black  Female   \n",
       "48595          Never-married  No occupation       Own-child  White    Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "8785              0             0              20  United-States  <=50K  \n",
       "11607             0             0              35  United-States  <=50K  \n",
       "13898             0             0              35  United-States  <=50K  \n",
       "21642             0             0              40  United-States  <=50K  \n",
       "27126             0             0              35  United-States  <=50K  \n",
       "31053             0             0              30  United-States  <=50K  \n",
       "36618             0             0              10  United-States  <=50K  \n",
       "39513             0             0              40  United-States  <=50K  \n",
       "48585             0             0              40  United-States  <=50K  \n",
       "48595             0             0               4  United-States  <=50K  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['workclass']=='Never-worked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we encode all the categorical variables. The binary target variable and the binary variable for gender are encoded with 1 and 0, while the remaining categorical variables are one-hot-encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass     education  educational-num      marital-status  \\\n",
       "0   25    Private          11th                7       Never-married   \n",
       "1   38    Private       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black       0             0             0   \n",
       "1    Farming-fishing      Husband  White       0             0             0   \n",
       "2    Protective-serv      Husband  White       0             0             0   \n",
       "3  Machine-op-inspct      Husband  Black       0          7688             0   \n",
       "4                  ?    Own-child  White       1             0             0   \n",
       "\n",
       "   hours-per-week native-country  income  \n",
       "0              40  United-States       0  \n",
       "1              50  United-States       0  \n",
       "2              40  United-States       1  \n",
       "3              40  United-States       1  \n",
       "4              30  United-States       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup_nums = {\"gender\": {'Female': 1, 'Male': 0},\n",
    "                \"income\": {'>50K': 1, '<=50K': 0}}\n",
    "df_preprocessed = df.replace(cleanup_nums)\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.get_dummies(df_preprocessed, columns=[\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"native-country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  educational-num  gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   25                7       0             0             0              40   \n",
       "1   38                9       0             0             0              50   \n",
       "2   28               12       0             0             0              40   \n",
       "3   44               10       0          7688             0              40   \n",
       "4   18               10       1             0             0              30   \n",
       "\n",
       "   income  workclass_?  workclass_Federal-gov  workclass_Local-gov  ...  \\\n",
       "0       0            0                      0                    0  ...   \n",
       "1       0            0                      0                    0  ...   \n",
       "2       1            0                      0                    1  ...   \n",
       "3       1            0                      0                    0  ...   \n",
       "4       0            1                      0                    0  ...   \n",
       "\n",
       "   native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                        0                     0                      0   \n",
       "1                        0                     0                      0   \n",
       "2                        0                     0                      0   \n",
       "3                        0                     0                      0   \n",
       "4                        0                     0                      0   \n",
       "\n",
       "   native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                        0                               0   \n",
       "1                        0                               0   \n",
       "2                        0                               0   \n",
       "3                        0                               0   \n",
       "4                        0                               0   \n",
       "\n",
       "   native-country_United-States  native-country_Vietnam  \\\n",
       "0                             1                       0   \n",
       "1                             1                       0   \n",
       "2                             1                       0   \n",
       "3                             1                       0   \n",
       "4                             1                       0   \n",
       "\n",
       "   native-country_Yugoslavia  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To not always copy and paste those steps in further processing, we will define a function for the small preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df:pd.DataFrame, cleanup_nums: dict, categ:list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function preprocess the dataset\n",
    "    :param df: general dataframe\n",
    "    :param cleanup_nums: dictionary of binary categorical columns to encode\n",
    "    :param categ: list of categorical columns to one-hot-encode\n",
    "    :return: preprocessed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.replace(cleanup_nums)\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=categ)\n",
    "    # To avoid later processing problems, we rename the feature \"educational_num\" into \"training_num\"\n",
    "    df.rename(columns = {'educational-num':'training-num'}, inplace = True )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = preprocessing(df,{\"gender\": {'Female': 1, 'Male': 0}, \"income\": {'>50K': 1, '<=50K': 0}}, [\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"native-country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows  108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  training-num  gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       25             7       0             0             0              40   \n",
       "1       38             9       0             0             0              50   \n",
       "2       28            12       0             0             0              40   \n",
       "3       44            10       0          7688             0              40   \n",
       "4       18            10       1             0             0              30   \n",
       "...    ...           ...     ...           ...           ...             ...   \n",
       "48837   27            12       1             0             0              38   \n",
       "48838   40             9       0             0             0              40   \n",
       "48839   58             9       1             0             0              40   \n",
       "48840   22             9       0             0             0              20   \n",
       "48841   52             9       1         15024             0              40   \n",
       "\n",
       "       income  workclass_?  workclass_Federal-gov  workclass_Local-gov  ...  \\\n",
       "0           0            0                      0                    0  ...   \n",
       "1           0            0                      0                    0  ...   \n",
       "2           1            0                      0                    1  ...   \n",
       "3           1            0                      0                    0  ...   \n",
       "4           0            1                      0                    0  ...   \n",
       "...       ...          ...                    ...                  ...  ...   \n",
       "48837       0            0                      0                    0  ...   \n",
       "48838       1            0                      0                    0  ...   \n",
       "48839       0            0                      0                    0  ...   \n",
       "48840       0            0                      0                    0  ...   \n",
       "48841       1            0                      0                    0  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "...                        ...                         ...   \n",
       "48837                        0                           0   \n",
       "48838                        0                           0   \n",
       "48839                        0                           0   \n",
       "48840                        0                           0   \n",
       "48841                        0                           0   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "0                            0                     0                      0   \n",
       "1                            0                     0                      0   \n",
       "2                            0                     0                      0   \n",
       "3                            0                     0                      0   \n",
       "4                            0                     0                      0   \n",
       "...                        ...                   ...                    ...   \n",
       "48837                        0                     0                      0   \n",
       "48838                        0                     0                      0   \n",
       "48839                        0                     0                      0   \n",
       "48840                        0                     0                      0   \n",
       "48841                        0                     0                      0   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "...                        ...                             ...   \n",
       "48837                        0                               0   \n",
       "48838                        0                               0   \n",
       "48839                        0                               0   \n",
       "48840                        0                               0   \n",
       "48841                        0                               0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "0                                 1                       0   \n",
       "1                                 1                       0   \n",
       "2                                 1                       0   \n",
       "3                                 1                       0   \n",
       "4                                 1                       0   \n",
       "...                             ...                     ...   \n",
       "48837                             1                       0   \n",
       "48838                             1                       0   \n",
       "48839                             1                       0   \n",
       "48840                             1                       0   \n",
       "48841                             1                       0   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "48837                          0  \n",
       "48838                          0  \n",
       "48839                          0  \n",
       "48840                          0  \n",
       "48841                          0  \n",
       "\n",
       "[48842 rows x 108 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are not given a test set, we create a train-validation-test split to check the hypothesis in a next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Train-Validation-Test-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we split our given data into 60% train, 20% val and 20% test. Before we do that, we will have a short look on the distribution of our target to check for an imbalanced set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_preprocessed['income'].value_counts().plot(kind ='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that we have an imbalanced dataset with the majority of people earning less than 50k and therefore need to make sure to include this distribution in our splitted sets via stratified sampling. The imbalance is also an indicator for the usage of the f1-score as metric for our further downstream task instead of focusing only on accuracy, as accuracy would also deliver a good result if we have good results in the major class. We also keep the test set completely out of all steps except the last prediction to see how the algorithms performs on the test set as a generalization indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split up in train+val and test\n",
    "data_train_val, data_test, target_train_val, target_test = train_test_split(df_preprocessed.drop(columns=['income']), df_preprocessed['income'], test_size=0.2, random_state=42, stratify=df_preprocessed['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split up train+val in train and val\n",
    "data_train, data_val, target_train, target_val = train_test_split(data_train_val, target_train_val, test_size=0.2, random_state=42, stratify=target_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now have a look at the values in our different sets to check wether the distribution of the target is nearly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define values for plots\n",
    "x = ['>50k','<=50k']\n",
    "y_train = target_train.value_counts().to_list()\n",
    "y_val = target_val.value_counts().to_list()\n",
    "y_test = target_test.value_counts().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3,  figsize=(15,3))\n",
    "fig.suptitle('Distribution of target in all the sets')\n",
    "ax1.bar(x, y_train)\n",
    "ax1.set_xlabel('Train')\n",
    "ax2.bar(x, y_val)\n",
    "ax2.set_xlabel('Validation')\n",
    "ax3.bar(x, y_test)\n",
    "ax3.set_xlabel('Test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the distribution is nearly the same for all our sets. As we generated the train-test-validation split in the previous step, we now want to scale the data. This is for the reason, that different scales might actually distort our algorithm a lot due to big differences in the scales. For scaling, we use the StandardScaler from the sklearn package. It should be noted that we only fit the scaler on our training data and use only the transformation on the validation and testing part, because we do not want to include information about validation and test that could already help the algorithm (data leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define standard scaler\n",
    "scaler = StandardScaler()\n",
    "# features to scale\n",
    "numerical_features = ['age','training-num', 'capital-gain','capital-loss','hours-per-week' ]\n",
    "# transform data\n",
    "data_train[numerical_features] = scaler.fit_transform(data_train[numerical_features])\n",
    "data_val[numerical_features] = scaler.transform(data_val[numerical_features])\n",
    "data_test[numerical_features] = scaler.transform(data_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32707</th>\n",
       "      <td>1.260788</td>\n",
       "      <td>-1.196134</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-0.042541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34860</th>\n",
       "      <td>-0.049988</td>\n",
       "      <td>1.132320</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-0.445174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32860</th>\n",
       "      <td>-1.506406</td>\n",
       "      <td>-0.808058</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-1.653073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39091</th>\n",
       "      <td>-0.996659</td>\n",
       "      <td>-0.419983</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>2.373257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608</th>\n",
       "      <td>0.969505</td>\n",
       "      <td>-0.419983</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-0.042541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  training-num  gender  capital-gain  capital-loss  \\\n",
       "32707  1.260788     -1.196134       0     -0.144436     -0.219322   \n",
       "34860 -0.049988      1.132320       1     -0.144436     -0.219322   \n",
       "32860 -1.506406     -0.808058       1     -0.144436     -0.219322   \n",
       "39091 -0.996659     -0.419983       0     -0.144436     -0.219322   \n",
       "17608  0.969505     -0.419983       1     -0.144436     -0.219322   \n",
       "\n",
       "       hours-per-week  workclass_?  workclass_Federal-gov  \\\n",
       "32707       -0.042541            0                      0   \n",
       "34860       -0.445174            0                      0   \n",
       "32860       -1.653073            0                      0   \n",
       "39091        2.373257            0                      0   \n",
       "17608       -0.042541            0                      0   \n",
       "\n",
       "       workclass_Local-gov  workclass_Never-worked  ...  \\\n",
       "32707                    0                       0  ...   \n",
       "34860                    0                       0  ...   \n",
       "32860                    0                       0  ...   \n",
       "39091                    0                       0  ...   \n",
       "17608                    0                       0  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "32707                        0                           0   \n",
       "34860                        0                           0   \n",
       "32860                        0                           0   \n",
       "39091                        0                           0   \n",
       "17608                        0                           0   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "32707                        0                     0                      0   \n",
       "34860                        0                     0                      0   \n",
       "32860                        0                     0                      0   \n",
       "39091                        0                     0                      0   \n",
       "17608                        0                     0                      0   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "32707                        0                               0   \n",
       "34860                        0                               0   \n",
       "32860                        0                               0   \n",
       "39091                        0                               0   \n",
       "17608                        0                               0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "32707                             1                       0   \n",
       "34860                             1                       0   \n",
       "32860                             1                       0   \n",
       "39091                             1                       0   \n",
       "17608                             0                       0   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "32707                          0  \n",
       "34860                          0  \n",
       "32860                          0  \n",
       "39091                          0  \n",
       "17608                          0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>-0.414092</td>\n",
       "      <td>-0.031907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>1.567991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37436</th>\n",
       "      <td>-0.195630</td>\n",
       "      <td>0.744244</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>3.879509</td>\n",
       "      <td>0.360092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>-1.142301</td>\n",
       "      <td>-0.031907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>0.279566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>-0.705376</td>\n",
       "      <td>-0.031907</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-0.042541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14601</th>\n",
       "      <td>-1.069480</td>\n",
       "      <td>1.132320</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-1.653073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  training-num  gender  capital-gain  capital-loss  \\\n",
       "2190  -0.414092     -0.031907       0     -0.144436     -0.219322   \n",
       "37436 -0.195630      0.744244       0     -0.144436      3.879509   \n",
       "18121 -1.142301     -0.031907       0     -0.144436     -0.219322   \n",
       "5554  -0.705376     -0.031907       1     -0.144436     -0.219322   \n",
       "14601 -1.069480      1.132320       0     -0.144436     -0.219322   \n",
       "\n",
       "       hours-per-week  workclass_?  workclass_Federal-gov  \\\n",
       "2190         1.567991            0                      0   \n",
       "37436        0.360092            0                      0   \n",
       "18121        0.279566            0                      0   \n",
       "5554        -0.042541            0                      0   \n",
       "14601       -1.653073            0                      0   \n",
       "\n",
       "       workclass_Local-gov  workclass_Never-worked  ...  \\\n",
       "2190                     0                       0  ...   \n",
       "37436                    0                       0  ...   \n",
       "18121                    0                       0  ...   \n",
       "5554                     0                       0  ...   \n",
       "14601                    1                       0  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "2190                         0                           0   \n",
       "37436                        0                           0   \n",
       "18121                        0                           0   \n",
       "5554                         0                           0   \n",
       "14601                        0                           0   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "2190                         0                     0                      0   \n",
       "37436                        0                     0                      0   \n",
       "18121                        0                     0                      0   \n",
       "5554                         0                     0                      0   \n",
       "14601                        0                     0                      0   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "2190                         0                               0   \n",
       "37436                        0                               0   \n",
       "18121                        0                               0   \n",
       "5554                         0                               0   \n",
       "14601                        0                               0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "2190                              1                       0   \n",
       "37436                             1                       0   \n",
       "18121                             1                       0   \n",
       "5554                              0                       0   \n",
       "14601                             1                       0   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "2190                           0  \n",
       "37436                          0  \n",
       "18121                          0  \n",
       "5554                           0  \n",
       "14601                          0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40342</th>\n",
       "      <td>1.115147</td>\n",
       "      <td>-0.419983</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-0.042541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47680</th>\n",
       "      <td>-0.778197</td>\n",
       "      <td>-0.419983</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-1.653073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1.042326</td>\n",
       "      <td>-0.031907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>0.762725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8508</th>\n",
       "      <td>1.406430</td>\n",
       "      <td>-0.419983</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287581</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-1.975179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31692</th>\n",
       "      <td>0.605400</td>\n",
       "      <td>0.744244</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-0.042541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  training-num  gender  capital-gain  capital-loss  \\\n",
       "40342  1.115147     -0.419983       1     -0.144436     -0.219322   \n",
       "47680 -0.778197     -0.419983       0     -0.144436     -0.219322   \n",
       "524    1.042326     -0.031907       0     -0.144436     -0.219322   \n",
       "8508   1.406430     -0.419983       0      0.287581     -0.219322   \n",
       "31692  0.605400      0.744244       0     -0.144436     -0.219322   \n",
       "\n",
       "       hours-per-week  workclass_?  workclass_Federal-gov  \\\n",
       "40342       -0.042541            0                      0   \n",
       "47680       -1.653073            0                      0   \n",
       "524          0.762725            0                      0   \n",
       "8508        -1.975179            0                      0   \n",
       "31692       -0.042541            0                      0   \n",
       "\n",
       "       workclass_Local-gov  workclass_Never-worked  ...  \\\n",
       "40342                    0                       0  ...   \n",
       "47680                    1                       0  ...   \n",
       "524                      1                       0  ...   \n",
       "8508                     0                       0  ...   \n",
       "31692                    1                       0  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "40342                        0                           0   \n",
       "47680                        0                           0   \n",
       "524                          0                           0   \n",
       "8508                         0                           0   \n",
       "31692                        0                           0   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "40342                        0                     0                      0   \n",
       "47680                        0                     0                      0   \n",
       "524                          0                     0                      0   \n",
       "8508                         0                     0                      0   \n",
       "31692                        0                     0                      0   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "40342                        0                               0   \n",
       "47680                        0                               0   \n",
       "524                          0                               0   \n",
       "8508                         0                               0   \n",
       "31692                        0                               0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "40342                             1                       0   \n",
       "47680                             1                       0   \n",
       "524                               1                       0   \n",
       "8508                              1                       0   \n",
       "31692                             1                       0   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "40342                          0  \n",
       "47680                          0  \n",
       "524                            0  \n",
       "8508                           0  \n",
       "31692                          0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. First algorithm and possible bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a classic decision tree classifier for the testing purposes, as we can easily see which features have the highest influence on our results. We first define a function to train the model that can be reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(x_train:pd.DataFrame, y_train:pd.DataFrame, x_val:pd.DataFrame, y_val:pd.DataFrame, model, test =False):\n",
    "    \"\"\"\n",
    "    Function to train a model\n",
    "    :param x_train: dataframe of features for training\n",
    "    :param y_train: target dataframe for training\n",
    "    :param x_val: dataframe of features for validation\n",
    "    :param y_val: target dataframe for validation\n",
    "    :param model: model class that should be fitted\n",
    "    :param test: indication if we are evaluating on the tet or validation set\n",
    "    :return: trained model\n",
    "    \"\"\"\n",
    "    model_fit = model\n",
    "    model_fit.fit(x_train, y_train)\n",
    "    prediction = model_fit.predict(x_val)\n",
    "    acc = accuracy_score(y_val,prediction) \n",
    "    f1= f1_score(y_val,prediction, average = 'macro') \n",
    "    if test== False:\n",
    "        print(\"The Accuracy on the validation set: {:.4f}\".format(acc))\n",
    "        print(\"The F1-Score on the validation set: {:.4f}\".format(f1))\n",
    "    else: \n",
    "        print(\"The Accuracy on the test set: {:.4f}\".format(acc))\n",
    "        print(\"The F1-Score on the test set: {:.4f}\".format(f1))\n",
    "    print('Confusion Matrix : \\n' + str(confusion_matrix(y_val,prediction)))\n",
    "\n",
    "    return model_fit, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8216\n",
      "The F1-Score on the validation set: 0.7546\n",
      "Confusion Matrix : \n",
      "[[5253  692]\n",
      " [ 702 1168]]\n"
     ]
    }
   ],
   "source": [
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gender, Score: 0.00810\n",
      "Feature: race_Amer-Indian-Eskimo, Score: 0.00156\n",
      "Feature: race_Asian-Pac-Islander, Score: 0.00327\n",
      "Feature: race_Black, Score: 0.00494\n",
      "Feature: race_Other, Score: 0.00075\n",
      "Feature: race_White, Score: 0.00768\n"
     ]
    }
   ],
   "source": [
    "#feature importance  for race and gender\n",
    "# get importance\n",
    "importance = dt.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    if data_train.columns[i].split(\"_\")[0] in ('race','gender'):\n",
    "        print(F'Feature: {data_train.columns[i]}, Score: %.5f' % (v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the race and the gender both have influence, although it is not too high and may be overshadowed by the other variables. However, since it has an influence, the results might be prone to bias due to sensitive information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we concatenate the validation set, the target and the prediction to see if we can see any anomalies in the false negatives based on gender and race. If there are some that may be a hint for bias in the model. In a first step, we to revert the one-hot-encoding for better understandability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_ohe(df, prefix_sep=\"_\"):\n",
    "    # get columns to revert based on the seperator\n",
    "    col_revert = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    #list of final dataframe input\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in col_revert.items():\n",
    "        if needs_to_collapse:\n",
    "        # revert ohe per column and append it\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            # if column does not need to be reverted, just append it\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = revert_ohe(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>-0.414092</td>\n",
       "      <td>-0.031907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>1.567991</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37436</th>\n",
       "      <td>-0.195630</td>\n",
       "      <td>0.744244</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>3.879509</td>\n",
       "      <td>0.360092</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>-1.142301</td>\n",
       "      <td>-0.031907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>0.279566</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>-0.705376</td>\n",
       "      <td>-0.031907</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-0.042541</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Guatemala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14601</th>\n",
       "      <td>-1.069480</td>\n",
       "      <td>1.132320</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.144436</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>-1.653073</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  training-num  gender  capital-gain  capital-loss  \\\n",
       "2190  -0.414092     -0.031907       0     -0.144436     -0.219322   \n",
       "37436 -0.195630      0.744244       0     -0.144436      3.879509   \n",
       "18121 -1.142301     -0.031907       0     -0.144436     -0.219322   \n",
       "5554  -0.705376     -0.031907       1     -0.144436     -0.219322   \n",
       "14601 -1.069480      1.132320       0     -0.144436     -0.219322   \n",
       "\n",
       "       hours-per-week  workclass     education marital-status  \\\n",
       "2190         1.567991    Private  Some-college      Separated   \n",
       "37436        0.360092    Private    Assoc-acdm  Never-married   \n",
       "18121        0.279566    Private  Some-college  Never-married   \n",
       "5554        -0.042541    Private  Some-college  Never-married   \n",
       "14601       -1.653073  Local-gov     Bachelors  Never-married   \n",
       "\n",
       "             occupation   relationship   race native-country  \n",
       "2190       Craft-repair      Own-child  White  United-States  \n",
       "37436    Prof-specialty  Not-in-family  White  United-States  \n",
       "18121      Craft-repair  Not-in-family  White  United-States  \n",
       "5554       Adm-clerical  Not-in-family  White      Guatemala  \n",
       "14601  Transport-moving      Own-child  White  United-States  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14601</th>\n",
       "      <td>24</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37436</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1669</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass     education  educational-num marital-status  \\\n",
       "2190    33    Private  Some-college               10      Separated   \n",
       "5554    29    Private  Some-college               10  Never-married   \n",
       "14601   24  Local-gov     Bachelors               13  Never-married   \n",
       "18121   23    Private  Some-college               10  Never-married   \n",
       "37436   36    Private    Assoc-acdm               12  Never-married   \n",
       "\n",
       "             occupation   relationship   race  gender  capital-gain  \\\n",
       "2190       Craft-repair      Own-child  White    Male             0   \n",
       "5554       Adm-clerical  Not-in-family  White  Female             0   \n",
       "14601  Transport-moving      Own-child  White    Male             0   \n",
       "18121      Craft-repair  Not-in-family  White    Male             0   \n",
       "37436    Prof-specialty  Not-in-family  White    Male             0   \n",
       "\n",
       "       capital-loss  hours-per-week native-country income  \n",
       "2190              0              60  United-States  <=50K  \n",
       "5554              0              40      Guatemala  <=50K  \n",
       "14601             0              20  United-States  <=50K  \n",
       "18121             0              44  United-States  <=50K  \n",
       "37436          1669              45  United-States  <=50K  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double check if reverting was succesful\n",
    "df[(df.index==2190)|(df.index==37436)|(df.index==18121)|(df.index==5554)|(df.index==14601)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate test set, target and final prediction for further use\n",
    "df_comparison = pd.concat([df_comparison.reset_index(), target_val.reset_index(drop=True),pd.Series(prediction),], axis=1).set_index('index')\n",
    "df_comparison.rename(columns={0 :'Prediction'}, inplace=True )\n",
    "# on top of that we inverse transform the numerical columns and change them to integer again\n",
    "numerical_features = ['age','training-num', 'capital-gain','capital-loss','hours-per-week' ]\n",
    "df_comparison[numerical_features] = scaler.inverse_transform(df_comparison[numerical_features])\n",
    "df_comparison[numerical_features] = df_comparison[numerical_features].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37436</th>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1669</td>\n",
       "      <td>45</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14601</th>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  training-num  gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "index                                                                          \n",
       "2190    33            10       0             0             0              60   \n",
       "37436   36            12       0             0          1669              45   \n",
       "18121   23            10       0             0             0              44   \n",
       "5554    29            10       1             0             0              40   \n",
       "14601   24            13       0             0             0              20   \n",
       "\n",
       "       workclass     education marital-status        occupation  \\\n",
       "index                                                             \n",
       "2190     Private  Some-college      Separated      Craft-repair   \n",
       "37436    Private    Assoc-acdm  Never-married    Prof-specialty   \n",
       "18121    Private  Some-college  Never-married      Craft-repair   \n",
       "5554     Private  Some-college  Never-married      Adm-clerical   \n",
       "14601  Local-gov     Bachelors  Never-married  Transport-moving   \n",
       "\n",
       "        relationship   race native-country  income  Prediction  \n",
       "index                                                           \n",
       "2190       Own-child  White  United-States       0           0  \n",
       "37436  Not-in-family  White  United-States       0           0  \n",
       "18121  Not-in-family  White  United-States       0           0  \n",
       "5554   Not-in-family  White      Guatemala       0           0  \n",
       "14601      Own-child  White  United-States       0           0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter on the different values of the sensitive features race and gender to get an overview if the algorithm is distorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compare amount of predictions and income\n",
    "# rename labels into interpretable text\n",
    "df2 = df_comparison.replace({\"Prediction\": { 1:'>50K', 0:'<=50K'}, \"income\": { 1:'>50K', 0:'<=50K'},\"gender\":{1:\"Female\",0:\"Male\"}})\n",
    "fig, (ax, ax2) = plt.subplots(1,2 ,  figsize=(15,3))\n",
    "\n",
    "#plot for gender\n",
    "X_axis = np.arange(len(df2['Prediction'].unique()))\n",
    "for axes in [ax,ax2]:\n",
    "    if axes == ax:\n",
    "        sex=\"Female\"\n",
    "    else: \n",
    "        sex=\"Male\"\n",
    "    axes.bar(X_axis - 0.2, df2[df2['gender']==sex].groupby('gender')['Prediction'].value_counts(), 0.4, label = 'Prediction')\n",
    "    axes.bar(X_axis + 0.2, df2[df2['gender']==sex].groupby('gender')['income'].value_counts(), 0.4, label = 'Income')\n",
    "    axes.set_xticks(X_axis,df2['Prediction'].unique())\n",
    "    axes.set_xlabel(sex)\n",
    "    axes.set_ylabel(\"Number of people\")\n",
    "    axes.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not seem to biased based on the gender feature, as their is no real big difference in the predictions and the labels per class. Therefore, there is not real tendency to predict more false positives per class, which means no bias in that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,5 ,  figsize=(15,3))\n",
    "\n",
    "#plot for gender\n",
    "X_axis = np.arange(len(df2['Prediction'].unique()))\n",
    "race_list = df2['race'].unique().tolist()\n",
    "count = 0\n",
    "for ax in axes:\n",
    "    race = race_list[count]\n",
    "    ax.bar(X_axis - 0.2, df2[df2['race']==race].groupby('race')['Prediction'].value_counts(), 0.4, label = 'Prediction')\n",
    "    ax.bar(X_axis + 0.2, df2[df2['race']==race].groupby('race')['income'].value_counts(), 0.4, label = 'Income')\n",
    "    ax.set_xticks(X_axis,df2['Prediction'].unique())\n",
    "    ax.set_xlabel(race)\n",
    "    ax.set_ylabel(\"Number of people\")\n",
    "    ax.legend()\n",
    "    count += 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race                income  Prediction\n",
       "Amer-Indian-Eskimo  0       0               60\n",
       "                            1                5\n",
       "                    1       1                5\n",
       "                            0                2\n",
       "Asian-Pac-Islander  0       0              152\n",
       "                    1       1               34\n",
       "                    0       1               30\n",
       "                    1       0               19\n",
       "Black               0       0              606\n",
       "                    1       1               61\n",
       "                    0       1               45\n",
       "                    1       0               35\n",
       "Other               0       0               54\n",
       "                    1       1                5\n",
       "                            0                4\n",
       "                    0       1                2\n",
       "White               0       0             4412\n",
       "                    1       1             1064\n",
       "                            0              641\n",
       "                    0       1              579\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison.groupby('race')['income','Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the contrary, for the race feature, there seems to be some bias involved. We can clearly see that for Amer-Indian-Eskimo, Asian-Pac-Islander and Black persons the model is more likely to predict a higher income although that is not the case, while for Other and White people, it is more likely to predict less income. This shows that there is some small bias against those two groups. Unfortunately, we do not know, which people fall under the Other category. However, we see that the sample is not really big for most groups. So, these deviations could be by chance as well and if we would have more samples, it would balance out (law of large numbers) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Reiterate and discard race feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, we discard the race feature and train the same setting again to have a look if this bias was introduced due to the feature or not. We gonna check if the distributions above are still the same if we train the model without the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = df.drop(columns=['race'])\n",
    "#use the defined functions for preprocessing\n",
    "df_preprocessed = preprocessing(df_preprocessed,{\"gender\": {'Female': 1, 'Male': 0}, \"income\": {'>50K': 1, '<=50K': 0}}, [\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",'native-country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split up in train+val and test\n",
    "data_train_val, data_test, target_train_val, target_test = train_test_split(df_preprocessed.drop(columns=['income']), df_preprocessed['income'], test_size=0.2, random_state=42, stratify=df_preprocessed['income'])\n",
    "\n",
    "#  split up train+val in train and val\n",
    "data_train, data_val, target_train, target_val = train_test_split(data_train_val, target_train_val, test_size=0.2, random_state=42, stratify=target_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define standard scaler as above\n",
    "scaler = StandardScaler()\n",
    "# features to scale\n",
    "numerical_features = ['age','training-num', 'capital-gain','capital-loss','hours-per-week' ]\n",
    "# transform data\n",
    "data_train[numerical_features] = scaler.fit_transform(data_train[numerical_features])\n",
    "data_val[numerical_features] = scaler.transform(data_val[numerical_features])\n",
    "data_test[numerical_features] = scaler.transform(data_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8260\n",
      "The F1-Score on the validation set: 0.7597\n",
      "Confusion Matrix : \n",
      "[[5280  665]\n",
      " [ 695 1175]]\n"
     ]
    }
   ],
   "source": [
    "#use the defined functions for training the model\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the results above, we already see that there is an improvement. But we need to be careful, because we do not use CV. So, this could be due to randomness as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the defined functions for revert the ohe \n",
    "df_comparison = revert_ohe(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate test set, target and final prediction for further use\n",
    "df_comparison = pd.concat([df_comparison.reset_index(), target_val.reset_index(drop=True),pd.Series(prediction),], axis=1).set_index('index')\n",
    "df_comparison.rename(columns={0 :'Prediction'}, inplace=True )\n",
    "# on top of that we inverse transform the numerical columns and change them to integer again\n",
    "numerical_features = ['age','training-num', 'capital-gain','capital-loss','hours-per-week' ]\n",
    "df_comparison[numerical_features] = scaler.inverse_transform(df_comparison[numerical_features])\n",
    "df_comparison[numerical_features] = df_comparison[numerical_features].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the distribution for the race feature, we join the original table based on the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = pd.merge(df_comparison, df['race'], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37436</th>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1669</td>\n",
       "      <td>45</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Guatemala</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14601</th>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  training-num  gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "2190    33            10       0             0             0              60   \n",
       "37436   36            12       0             0          1669              45   \n",
       "18121   23            10       0             0             0              44   \n",
       "5554    29            10       1             0             0              40   \n",
       "14601   24            13       0             0             0              20   \n",
       "\n",
       "       workclass     education marital-status        occupation  \\\n",
       "2190     Private  Some-college      Separated      Craft-repair   \n",
       "37436    Private    Assoc-acdm  Never-married    Prof-specialty   \n",
       "18121    Private  Some-college  Never-married      Craft-repair   \n",
       "5554     Private  Some-college  Never-married      Adm-clerical   \n",
       "14601  Local-gov     Bachelors  Never-married  Transport-moving   \n",
       "\n",
       "        relationship native-country  income  Prediction   race  \n",
       "2190       Own-child  United-States       0           0  White  \n",
       "37436  Not-in-family  United-States       0           0  White  \n",
       "18121  Not-in-family  United-States       0           0  White  \n",
       "5554   Not-in-family      Guatemala       0           0  White  \n",
       "14601      Own-child  United-States       0           0  White  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compare amount of predictions and income\n",
    "# rename labels into interpretable text\n",
    "df2 = df_comparison.replace({\"Prediction\": { 1:'>50K', 0:'<=50K'}, \"income\": { 1:'>50K', 0:'<=50K'}})\n",
    "fig, axes = plt.subplots(1,5 ,  figsize=(15,3))\n",
    "\n",
    "#plot for gender\n",
    "X_axis = np.arange(len(df2['Prediction'].unique()))\n",
    "race_list = df2['race'].unique().tolist()\n",
    "count = 0\n",
    "for ax in axes:\n",
    "    race = race_list[count]\n",
    "    ax.bar(X_axis - 0.2, df2[df2['race']==race].groupby('race')['Prediction'].value_counts(), 0.4, label = 'Prediction')\n",
    "    ax.bar(X_axis + 0.2, df2[df2['race']==race].groupby('race')['income'].value_counts(), 0.4, label = 'Income')\n",
    "    ax.set_xticks(X_axis,df2['Prediction'].unique())\n",
    "    ax.set_xlabel(race)\n",
    "    ax.set_ylabel(\"Number of people\")\n",
    "    ax.legend()\n",
    "    count += 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race                income  Prediction\n",
       "Amer-Indian-Eskimo  0       0               60\n",
       "                    1       1                6\n",
       "                    0       1                5\n",
       "                    1       0                1\n",
       "Asian-Pac-Islander  0       0              155\n",
       "                    1       1               32\n",
       "                    0       1               27\n",
       "                    1       0               21\n",
       "Black               0       0              602\n",
       "                    1       1               65\n",
       "                    0       1               49\n",
       "                    1       0               31\n",
       "Other               0       0               56\n",
       "                    1       1                5\n",
       "                            0                4\n",
       "White               0       0             4407\n",
       "                    1       1             1067\n",
       "                            0              638\n",
       "                    0       1              584\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison.groupby('race')['income','Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After discarding the feature, we get less false negatives (less income predicted, although it is high) for White (641 to 638), and Black (35 to 31) people, while the other results stay the same. However, as the amount of data is that small for some groups, we cannot really distinguish that this happens by chance or if there is bias inside the model. But it seems that discarding the race feature benefits the model performance overall and since it is a highly critical feature, it seems appropriate to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Biased Train-Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following part of the notebook, we show another way how bias could be introduced when we are not careful. We split the whole dataset again, but this time not based on a stratified split. We manipulate our split such that most of the cases where women have low income are in the training set and high income women are in the test set. We discard the gender feature and show that even without the feature, it might happen that the algorithm is prone to bias based on the training split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating the preprocessed dataset and split up the set in train and test. However, this time we manipulate the dataset by filtering out the women with high income first (around 1,800 entries/4% of whole set), put them into the test set and then create the remaining split of 16% for the test data. This leads to a split of 80% train and 20% test data. We are not creating a validation set, since we are not gonna optimize anything based on this split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the defined functions for preprocessing\n",
    "df_preprocessed = preprocessing(df,{\"gender\": {'Female': 1, 'Male': 0}, \"income\": {'>50K': 1, '<=50K': 0}}, [\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",\"native-country\",\"race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>race_Amer-Indian-Eskimo</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48811</th>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48817</th>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48819</th>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>15020</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48826</th>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1769 rows  108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  training-num  gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "45      28            11       1             0             0              36   \n",
       "89      41            14       1          7688             0              10   \n",
       "92      33            14       1          5178             0              10   \n",
       "119     43            13       1             0             0              40   \n",
       "126     48            16       1             0             0              40   \n",
       "...    ...           ...     ...           ...           ...             ...   \n",
       "48811   35            13       1             0             0              55   \n",
       "48817   34            13       1             0             0              55   \n",
       "48819   38            13       1         15020             0              45   \n",
       "48826   39            12       1             0             0              20   \n",
       "48841   52             9       1         15024             0              40   \n",
       "\n",
       "       income  workclass_?  workclass_Federal-gov  workclass_Local-gov  ...  \\\n",
       "45          1            0                      0                    0  ...   \n",
       "89          1            1                      0                    0  ...   \n",
       "92          1            0                      0                    0  ...   \n",
       "119         1            0                      0                    0  ...   \n",
       "126         1            0                      1                    0  ...   \n",
       "...       ...          ...                    ...                  ...  ...   \n",
       "48811       1            1                      0                    0  ...   \n",
       "48817       1            0                      0                    0  ...   \n",
       "48819       1            0                      0                    0  ...   \n",
       "48826       1            0                      0                    1  ...   \n",
       "48841       1            0                      0                    0  ...   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "45                           0                               0   \n",
       "89                           0                               0   \n",
       "92                           0                               0   \n",
       "119                          0                               0   \n",
       "126                          0                               0   \n",
       "...                        ...                             ...   \n",
       "48811                        0                               0   \n",
       "48817                        0                               0   \n",
       "48819                        0                               0   \n",
       "48826                        0                               0   \n",
       "48841                        0                               0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "45                                1                       0   \n",
       "89                                1                       0   \n",
       "92                                1                       0   \n",
       "119                               1                       0   \n",
       "126                               1                       0   \n",
       "...                             ...                     ...   \n",
       "48811                             1                       0   \n",
       "48817                             1                       0   \n",
       "48819                             1                       0   \n",
       "48826                             1                       0   \n",
       "48841                             1                       0   \n",
       "\n",
       "       native-country_Yugoslavia  race_Amer-Indian-Eskimo  \\\n",
       "45                             0                        0   \n",
       "89                             0                        0   \n",
       "92                             0                        0   \n",
       "119                            0                        0   \n",
       "126                            0                        0   \n",
       "...                          ...                      ...   \n",
       "48811                          0                        0   \n",
       "48817                          0                        0   \n",
       "48819                          0                        0   \n",
       "48826                          0                        0   \n",
       "48841                          0                        0   \n",
       "\n",
       "       race_Asian-Pac-Islander  race_Black  race_Other  race_White  \n",
       "45                           0           0           0           1  \n",
       "89                           0           0           0           1  \n",
       "92                           0           0           0           1  \n",
       "119                          0           0           0           1  \n",
       "126                          0           0           0           1  \n",
       "...                        ...         ...         ...         ...  \n",
       "48811                        0           0           0           1  \n",
       "48817                        0           0           0           1  \n",
       "48819                        0           1           0           0  \n",
       "48826                        0           0           0           1  \n",
       "48841                        0           0           0           1  \n",
       "\n",
       "[1769 rows x 108 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed[(df_preprocessed['gender']==1)&(df_preprocessed['income']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_woman_high = df_preprocessed[(df_preprocessed['gender']==1)&(df_preprocessed['income']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_bias = df_preprocessed[~((df_preprocessed['gender']==1)&(df_preprocessed['income']==1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split up in train and test\n",
    "data_train, data_test, target_train, target_test = train_test_split(df_preprocessed_bias.drop(columns=['income']), df_preprocessed_bias['income'], test_size=0.16, random_state=42, stratify=df_preprocessed_bias['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.concat([data_test, df_woman_high.drop(columns=['income'])])\n",
    "target_test = pd.concat([target_test, df_woman_high['income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again train a scaler for the numeric features, but we drop the gender column in train and test first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns=['gender'],inplace=True)\n",
    "data_test.drop(columns=['gender'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define standard scaler as above\n",
    "scaler = StandardScaler()\n",
    "# features to scale\n",
    "numerical_features = ['age','training-num', 'capital-gain','capital-loss','hours-per-week' ]\n",
    "# transform data\n",
    "data_train[numerical_features] = scaler.fit_transform(data_train[numerical_features])\n",
    "data_test[numerical_features] = scaler.transform(data_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.7251\n",
      "The F1-Score on the validation set: 0.6567\n",
      "Confusion Matrix : \n",
      "[[5447  498]\n",
      " [2059 1297]]\n"
     ]
    }
   ],
   "source": [
    "#use the defined functions for training the model\n",
    "dt,prediction = model_training(data_train, target_train, data_test, target_test, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the defined functions for revert the ohe \n",
    "df_comparison = revert_ohe(data_test)\n",
    "# concate test set, target and final prediction for further use\n",
    "df_comparison = pd.concat([df_comparison.reset_index(), target_test.reset_index(drop=True),pd.Series(prediction),], axis=1).set_index('index')\n",
    "df_comparison.rename(columns={0 :'Prediction'}, inplace=True )\n",
    "# on top of that we inverse transform the numerical columns and change them to integer again\n",
    "numerical_features = ['age','training-num', 'capital-gain','capital-loss','hours-per-week' ]\n",
    "df_comparison[numerical_features] = scaler.inverse_transform(df_comparison[numerical_features])\n",
    "df_comparison[numerical_features] = df_comparison[numerical_features].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we discarded the gender feature, we join it again from the original table based on the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = pd.merge(df_comparison, df['gender'], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>native-country</th>\n",
       "      <th>race</th>\n",
       "      <th>income</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13182</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>United-States</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35159</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32068</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>45</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21305</th>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1672</td>\n",
       "      <td>40</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47885</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  training-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "13182   21             6             0             0              40   \n",
       "35159   42             9             0             0              40   \n",
       "32068   41             9             0          1887              45   \n",
       "21305   45             9             0          1672              40   \n",
       "47885   52             9             0             0              40   \n",
       "\n",
       "         workclass education      marital-status         occupation  \\\n",
       "13182      Private      10th       Never-married       Craft-repair   \n",
       "35159      Private   HS-grad  Married-civ-spouse  Handlers-cleaners   \n",
       "32068      Private   HS-grad  Married-civ-spouse   Transport-moving   \n",
       "21305  Federal-gov   HS-grad  Married-civ-spouse       Adm-clerical   \n",
       "47885      Private   HS-grad  Married-civ-spouse  Machine-op-inspct   \n",
       "\n",
       "      relationship native-country   race  income  Prediction gender  \n",
       "13182    Own-child  United-States  White       0           0   Male  \n",
       "35159      Husband  United-States  White       1           0   Male  \n",
       "32068      Husband  United-States  White       1           1   Male  \n",
       "21305      Husband  United-States  White       0           1   Male  \n",
       "47885      Husband  United-States  White       1           0   Male  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compare amount of predictions and income\n",
    "# rename labels into interpretable text\n",
    "df2 = df_comparison.replace({\"Prediction\": { 1:'>50K', 0:'<=50K'}, \"income\": { 1:'>50K', 0:'<=50K'}})\n",
    "fig, (ax, ax2) = plt.subplots(1,2 ,  figsize=(15,3))\n",
    "\n",
    "#plot for gender\n",
    "X_axis = np.arange(len(df2['Prediction'].unique()))\n",
    "for axes in [ax,ax2]:\n",
    "    if axes == ax:\n",
    "        sex=\"Female\"\n",
    "    else: \n",
    "        sex=\"Male\"\n",
    "    axes.bar(X_axis - 0.2, df2[df2['gender']==sex].groupby('gender')['Prediction'].value_counts(), 0.4, label = 'Prediction')\n",
    "    axes.bar(X_axis + 0.2, df2[df2['gender']==sex].groupby('gender')['income'].value_counts(), 0.4, label = 'Income')\n",
    "    axes.set_xticks(X_axis,df2['Prediction'].unique())\n",
    "    axes.set_xlabel(sex)\n",
    "    axes.set_ylabel(\"Number of people\")\n",
    "    axes.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison, to our earlier results for gender, we can clearly see that we have a lot of more false negatives for women such that we predict the lower income class instead of the higher income class. This happens, because we excluded all high income women from the training set. Therefore, the model could not learn that women can have a high income. This shows that bias cannot only be introduced by features itself, but by a biased train-test split as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Model improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we can not give a final answer about the question if bias is introduced or not based on the features itself, although there are signs that it is better to discard the race feature. However, how bias can be introduced by a bad train-test-split is quite obvious and has to be taken into account. In the remaining work, we focus on improving the model by different feature selection methods and hyperparameter optimization. Thereby, we first try three other models, namely Logistic Regression, XGBoost and Random Forest to compare the results to our decision tree and see if they are already better. As baselines, we gonna implement a random rate classifier that uses prior knowledge of class assignments in predicting the class and the prior used decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = df.drop(columns=['race'])\n",
    "#use the defined functions for preprocessing\n",
    "df_preprocessed = preprocessing(df_preprocessed,{\"gender\": {'Female': 1, 'Male': 0}, \"income\": {'>50K': 1, '<=50K': 0}}, [\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",\"native-country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split up in train+val and test\n",
    "data_train_val, data_test, target_train_val, target_test = train_test_split(df_preprocessed.drop(columns=['income']), df_preprocessed['income'], test_size=0.2, random_state=42, stratify=df_preprocessed['income'])\n",
    "\n",
    "#  split up train+val in train and val\n",
    "data_train, data_val, target_train, target_val = train_test_split(data_train_val, target_train_val, test_size=0.2, random_state=42, stratify=target_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define standard scaler as above\n",
    "scaler = StandardScaler()\n",
    "# features to scale\n",
    "numerical_features = ['age','training-num', 'capital-gain','capital-loss','hours-per-week' ]\n",
    "# transform data\n",
    "data_train[numerical_features] = scaler.fit_transform(data_train[numerical_features])\n",
    "data_val[numerical_features] = scaler.transform(data_val[numerical_features])\n",
    "data_test[numerical_features] = scaler.transform(data_test[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting higher income happens in 23.9 % of cases\n",
      "Predicting lower income happens in 76.1 % of cases\n"
     ]
    }
   ],
   "source": [
    "# random rate classifier\n",
    "# first get the probabilities of each class\n",
    "prop_high_income = round(len(target_val[target_val==1])/len(target_val),3)\n",
    "prop_low_income = round(len(target_val[target_val==0])/len(target_val),3)\n",
    "print(f'Predicting higher income happens in {prop_high_income*100} % of cases')\n",
    "print(f'Predicting lower income happens in {prop_low_income*100} % of cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.6292\n",
      "The F1-Score on the validation set: 0.4955\n",
      "Confusion Matrix : \n",
      "[[4470 1475]\n",
      " [1423  447]]\n"
     ]
    }
   ],
   "source": [
    "#Create prediction vector\n",
    "pred = np.random.choice([0, 1], size=len(target_val), p=[prop_low_income, prop_high_income])\n",
    "acc = accuracy_score(target_val,pred) \n",
    "f1= f1_score(target_val,pred, average = 'macro') \n",
    "print(\"The Accuracy on the validation set: {:.4f}\".format(acc))\n",
    "print(\"The F1-Score on the validation set: {:.4f}\".format(f1))\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(target_val,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8261\n",
      "The F1-Score on the validation set: 0.7592\n",
      "Confusion Matrix : \n",
      "[[5288  657]\n",
      " [ 702 1168]]\n"
     ]
    }
   ],
   "source": [
    "#check the results for the decision tree\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More sophisticated Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8535\n",
      "The F1-Score on the validation set: 0.7847\n",
      "Confusion Matrix : \n",
      "[[5544  401]\n",
      " [ 744 1126]]\n"
     ]
    }
   ],
   "source": [
    "#check the results for logistic regression\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8477\n",
      "The F1-Score on the validation set: 0.7824\n",
      "Confusion Matrix : \n",
      "[[5453  492]\n",
      " [ 698 1172]]\n"
     ]
    }
   ],
   "source": [
    "#check the results for random forest\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8760\n",
      "The F1-Score on the validation set: 0.8200\n",
      "Confusion Matrix : \n",
      "[[5602  343]\n",
      " [ 626 1244]]\n"
     ]
    }
   ],
   "source": [
    "#check the results for xgboost\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, XGBClassifier(eval_metric='error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that XGBoost has far better performances than the simple decision tree, logistic regression and random forest. Thus, we gonna focus on XGBoost for further optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gonna try two different feature selection methods to see if reducing the amount of features might benefit model performance. In a first step, we perform a f-test for calculating the feature importance and if the features are significant for the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>F value</th>\n",
       "      <th>p value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>1725.197091</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training-num</td>\n",
       "      <td>3894.319306</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender</td>\n",
       "      <td>1507.788825</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital-gain</td>\n",
       "      <td>1606.728813</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capital-loss</td>\n",
       "      <td>755.327196</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>native-country_Thailand</td>\n",
       "      <td>0.274817</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>native-country_Trinadad&amp;Tobago</td>\n",
       "      <td>5.350344</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>native-country_United-States</td>\n",
       "      <td>34.716022</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>native-country_Vietnam</td>\n",
       "      <td>5.945293</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>native-country_Yugoslavia</td>\n",
       "      <td>2.215147</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature      F value  p value\n",
       "0                               age  1725.197091     0.00\n",
       "1                      training-num  3894.319306     0.00\n",
       "2                            gender  1507.788825     0.00\n",
       "3                      capital-gain  1606.728813     0.00\n",
       "4                      capital-loss   755.327196     0.00\n",
       "..                              ...          ...      ...\n",
       "97          native-country_Thailand     0.274817     0.60\n",
       "98   native-country_Trinadad&Tobago     5.350344     0.02\n",
       "99     native-country_United-States    34.716022     0.00\n",
       "100          native-country_Vietnam     5.945293     0.01\n",
       "101       native-country_Yugoslavia     2.215147     0.14\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the F-Test\n",
    "f, pval = f_classif(data_train, target_train)\n",
    "\n",
    "# prepare a dataframe to inspect the results\n",
    "stat = pd.DataFrame({ 'feature': data_train.columns, 'F value': f, 'p value': pval })\n",
    "stat['p value'] = round(stat['p value'], 2)\n",
    "\n",
    "# show the results\n",
    "display(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of all the features that have a p value of 0.05 or higher, because they are not significant. We discard them and retrain the model to see if we achieve an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsignificant = stat[stat['p value']>=0.05]['feature'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train2 = data_train.drop(columns=unsignificant)\n",
    "data_val2 = data_val.drop(columns=unsignificant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8731\n",
      "The F1-Score on the validation set: 0.8161\n",
      "Confusion Matrix : \n",
      "[[5586  359]\n",
      " [ 633 1237]]\n"
     ]
    }
   ],
   "source": [
    "#check the results for xgboost reduction via f-test\n",
    "dt,prediction = model_training(data_train2, target_train, data_val2, target_val, XGBClassifier(eval_metric='error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it seems that this easy method did not improve our model. Therefore, we gonna try a more sophisticated feature selection method by using a backward selection within a cross valdidation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation with Backward Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, use the backward selection with cross validation to filter out features beginning with the whole set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_stratified = StratifiedKFold(n_splits=10,shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "      estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, enable_categorical=False,\n",
       "                              eval_metric='error', gamma=None, gpu_id=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_delta_step=None, max_depth=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=100,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None, reg_alpha=None,\n",
       "                              reg_lambda=None, scale_pos_weight=None,\n",
       "                              subsample=None, tree_method=None,\n",
       "                              validate_parameters=None, verbosity=None),\n",
       "      scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(eval_metric='error')\n",
    "rfecv = RFECV(xgb, step=1, cv=cv_stratified,scoring='f1_macro', verbose=2)\n",
    "rfecv.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 67\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimum number of features: %d\" % rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(16, 6))\n",
    "plt.title('Total features selected versus accuracy')\n",
    "plt.xlabel('Total features selected')\n",
    "plt.ylabel('Model accuracy')\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8  10  11  12  13  16  17  19  20  22\n",
      "  23  24  26  27  29  30  31  32  33  34  35  36  37  39  41  42  43  44\n",
      "  45  47  48  49  50  51  52  53  54  55  56  57  58  59  60  62  63  64\n",
      "  69  71  73  80  81  84  86  90  93  95  98  99 101]\n"
     ]
    }
   ],
   "source": [
    "selected_features = rfecv.get_support(1)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [ 0 ,  1,   2,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,  16,  17,  19,  20,  22,\n",
    "  23,  24,  26,  27,  29,  30,  31,  32,  33,  34,  35,  36,  37,  39,  41,  42,  43,  44,\n",
    "  45,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  62,  63,  64,\n",
    "  69,  71,  73,  80,  81,  84,  86,  90,  93,  95,  98,  99, 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_features = rfecv.get_support(1)\n",
    "data_train = data_train[data_train.columns[selected_features]]\n",
    "data_val = data_val[data_val.columns[selected_features]]\n",
    "data_test = data_test[data_test.columns[selected_features]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the optimal number of features is 67 and that the algorithm reaches a saturation level. We filter down our sets on the recommended 67 features and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8765\n",
      "The F1-Score on the validation set: 0.8215\n",
      "Confusion Matrix : \n",
      "[[5595  350]\n",
      " [ 615 1255]]\n"
     ]
    }
   ],
   "source": [
    "#check the results for xgboost backward feature selection\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, XGBClassifier(eval_metric='error'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results improved compared to our previous best outcomes from accuracy = 0.8760 and f1_score = 0.8200 to accuracy = 0.8765 and f1_score = 0.8215. We cannot be 100% sure that that might a sustainable improvement or if its random variation. However, since we have approximately the same performance with 35% less features, we prefer the new feature selection (Occam's Razor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a last improvement step, we optimize our hyperparameters. Since the search space of possible solutions is too big for a brute force search, we use a two step approach. First, we utilize bayesian search for finding a good solution by optimizing a surrogate. Afterwards, we use the best parameters of the bayesian search or the default settings to try to improve the model locally in that area via a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.06610098295419149, colsample_bytree=0.28539836866041823, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=7, max_depth=21, min_child_weight=2, n_estimators=371, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, subsample=0.5544643023916863; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.06610098295419149, colsample_bytree=0.28539836866041823, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=7, max_depth=21, min_child_weight=2, n_estimators=371, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, subsample=0.5544643023916863; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.06610098295419149, colsample_bytree=0.28539836866041823, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=7, max_depth=21, min_child_weight=2, n_estimators=371, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, subsample=0.5544643023916863; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.06610098295419149, colsample_bytree=0.28539836866041823, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=7, max_depth=21, min_child_weight=2, n_estimators=371, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, subsample=0.5544643023916863; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.06610098295419149, colsample_bytree=0.28539836866041823, gamma=0.13031389926541354, learning_rate=0.042815319280763466, max_delta_step=7, max_depth=21, min_child_weight=2, n_estimators=371, reg_alpha=5.497557739289786e-07, reg_lambda=0.05936070635912049, subsample=0.5544643023916863; total time=   5.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.4729080547055919, colsample_bytree=0.5842928269761146, gamma=4.358684608480795e-07, learning_rate=0.7988179462781242, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=180, reg_alpha=0.0005266983003701547, reg_lambda=276.5424475574225, subsample=0.6336020558163782; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.4729080547055919, colsample_bytree=0.5842928269761146, gamma=4.358684608480795e-07, learning_rate=0.7988179462781242, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=180, reg_alpha=0.0005266983003701547, reg_lambda=276.5424475574225, subsample=0.6336020558163782; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.4729080547055919, colsample_bytree=0.5842928269761146, gamma=4.358684608480795e-07, learning_rate=0.7988179462781242, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=180, reg_alpha=0.0005266983003701547, reg_lambda=276.5424475574225, subsample=0.6336020558163782; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.4729080547055919, colsample_bytree=0.5842928269761146, gamma=4.358684608480795e-07, learning_rate=0.7988179462781242, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=180, reg_alpha=0.0005266983003701547, reg_lambda=276.5424475574225, subsample=0.6336020558163782; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.4729080547055919, colsample_bytree=0.5842928269761146, gamma=4.358684608480795e-07, learning_rate=0.7988179462781242, max_delta_step=9, max_depth=4, min_child_weight=1, n_estimators=180, reg_alpha=0.0005266983003701547, reg_lambda=276.5424475574225, subsample=0.6336020558163782; total time=   3.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.07756486208064789, colsample_bytree=0.6877728743793542, gamma=8.168958221061441e-09, learning_rate=0.07356404539935663, max_delta_step=2, max_depth=23, min_child_weight=1, n_estimators=377, reg_alpha=0.00010376808625045426, reg_lambda=476.96194787286544, subsample=0.7064328557952411; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.07756486208064789, colsample_bytree=0.6877728743793542, gamma=8.168958221061441e-09, learning_rate=0.07356404539935663, max_delta_step=2, max_depth=23, min_child_weight=1, n_estimators=377, reg_alpha=0.00010376808625045426, reg_lambda=476.96194787286544, subsample=0.7064328557952411; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.07756486208064789, colsample_bytree=0.6877728743793542, gamma=8.168958221061441e-09, learning_rate=0.07356404539935663, max_delta_step=2, max_depth=23, min_child_weight=1, n_estimators=377, reg_alpha=0.00010376808625045426, reg_lambda=476.96194787286544, subsample=0.7064328557952411; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.07756486208064789, colsample_bytree=0.6877728743793542, gamma=8.168958221061441e-09, learning_rate=0.07356404539935663, max_delta_step=2, max_depth=23, min_child_weight=1, n_estimators=377, reg_alpha=0.00010376808625045426, reg_lambda=476.96194787286544, subsample=0.7064328557952411; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.07756486208064789, colsample_bytree=0.6877728743793542, gamma=8.168958221061441e-09, learning_rate=0.07356404539935663, max_delta_step=2, max_depth=23, min_child_weight=1, n_estimators=377, reg_alpha=0.00010376808625045426, reg_lambda=476.96194787286544, subsample=0.7064328557952411; total time=   6.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.42149456283334996, colsample_bytree=0.022066991249460103, gamma=0.00015936523535755285, learning_rate=0.4032083917998946, max_delta_step=5, max_depth=6, min_child_weight=4, n_estimators=437, reg_alpha=0.1611980387486336, reg_lambda=4.3806965488564525e-05, subsample=0.34817978468161015; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.42149456283334996, colsample_bytree=0.022066991249460103, gamma=0.00015936523535755285, learning_rate=0.4032083917998946, max_delta_step=5, max_depth=6, min_child_weight=4, n_estimators=437, reg_alpha=0.1611980387486336, reg_lambda=4.3806965488564525e-05, subsample=0.34817978468161015; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.42149456283334996, colsample_bytree=0.022066991249460103, gamma=0.00015936523535755285, learning_rate=0.4032083917998946, max_delta_step=5, max_depth=6, min_child_weight=4, n_estimators=437, reg_alpha=0.1611980387486336, reg_lambda=4.3806965488564525e-05, subsample=0.34817978468161015; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.42149456283334996, colsample_bytree=0.022066991249460103, gamma=0.00015936523535755285, learning_rate=0.4032083917998946, max_delta_step=5, max_depth=6, min_child_weight=4, n_estimators=437, reg_alpha=0.1611980387486336, reg_lambda=4.3806965488564525e-05, subsample=0.34817978468161015; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.42149456283334996, colsample_bytree=0.022066991249460103, gamma=0.00015936523535755285, learning_rate=0.4032083917998946, max_delta_step=5, max_depth=6, min_child_weight=4, n_estimators=437, reg_alpha=0.1611980387486336, reg_lambda=4.3806965488564525e-05, subsample=0.34817978468161015; total time=   4.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.3972893133963027, colsample_bytree=0.07517239253342656, gamma=3.811128976537413e-05, learning_rate=0.2700390206185342, max_delta_step=9, max_depth=36, min_child_weight=2, n_estimators=327, reg_alpha=1.5057560255472018e-06, reg_lambda=0.08186810622382998, subsample=0.5178580699961443; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.3972893133963027, colsample_bytree=0.07517239253342656, gamma=3.811128976537413e-05, learning_rate=0.2700390206185342, max_delta_step=9, max_depth=36, min_child_weight=2, n_estimators=327, reg_alpha=1.5057560255472018e-06, reg_lambda=0.08186810622382998, subsample=0.5178580699961443; total time=   4.1s\n",
      "[CV] END colsample_bylevel=0.3972893133963027, colsample_bytree=0.07517239253342656, gamma=3.811128976537413e-05, learning_rate=0.2700390206185342, max_delta_step=9, max_depth=36, min_child_weight=2, n_estimators=327, reg_alpha=1.5057560255472018e-06, reg_lambda=0.08186810622382998, subsample=0.5178580699961443; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.3972893133963027, colsample_bytree=0.07517239253342656, gamma=3.811128976537413e-05, learning_rate=0.2700390206185342, max_delta_step=9, max_depth=36, min_child_weight=2, n_estimators=327, reg_alpha=1.5057560255472018e-06, reg_lambda=0.08186810622382998, subsample=0.5178580699961443; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.3972893133963027, colsample_bytree=0.07517239253342656, gamma=3.811128976537413e-05, learning_rate=0.2700390206185342, max_delta_step=9, max_depth=36, min_child_weight=2, n_estimators=327, reg_alpha=1.5057560255472018e-06, reg_lambda=0.08186810622382998, subsample=0.5178580699961443; total time=   4.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.29380287142759304, colsample_bytree=0.7563790218678241, gamma=2.6498051478267012e-08, learning_rate=0.0238149998729586, max_delta_step=8, max_depth=19, min_child_weight=2, n_estimators=270, reg_alpha=0.011683028450342707, reg_lambda=0.0048879464985534336, subsample=0.5930070264428381; total time=  14.6s\n",
      "[CV] END colsample_bylevel=0.29380287142759304, colsample_bytree=0.7563790218678241, gamma=2.6498051478267012e-08, learning_rate=0.0238149998729586, max_delta_step=8, max_depth=19, min_child_weight=2, n_estimators=270, reg_alpha=0.011683028450342707, reg_lambda=0.0048879464985534336, subsample=0.5930070264428381; total time=  14.8s\n",
      "[CV] END colsample_bylevel=0.29380287142759304, colsample_bytree=0.7563790218678241, gamma=2.6498051478267012e-08, learning_rate=0.0238149998729586, max_delta_step=8, max_depth=19, min_child_weight=2, n_estimators=270, reg_alpha=0.011683028450342707, reg_lambda=0.0048879464985534336, subsample=0.5930070264428381; total time=  14.2s\n",
      "[CV] END colsample_bylevel=0.29380287142759304, colsample_bytree=0.7563790218678241, gamma=2.6498051478267012e-08, learning_rate=0.0238149998729586, max_delta_step=8, max_depth=19, min_child_weight=2, n_estimators=270, reg_alpha=0.011683028450342707, reg_lambda=0.0048879464985534336, subsample=0.5930070264428381; total time=  14.4s\n",
      "[CV] END colsample_bylevel=0.29380287142759304, colsample_bytree=0.7563790218678241, gamma=2.6498051478267012e-08, learning_rate=0.0238149998729586, max_delta_step=8, max_depth=19, min_child_weight=2, n_estimators=270, reg_alpha=0.011683028450342707, reg_lambda=0.0048879464985534336, subsample=0.5930070264428381; total time=  14.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.1714583803805369, colsample_bytree=0.35540927532494104, gamma=1.3277909848852635e-06, learning_rate=0.5605967693796124, max_delta_step=6, max_depth=30, min_child_weight=3, n_estimators=214, reg_alpha=0.004026635957416632, reg_lambda=0.040887904512512056, subsample=0.9250385544668723; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.1714583803805369, colsample_bytree=0.35540927532494104, gamma=1.3277909848852635e-06, learning_rate=0.5605967693796124, max_delta_step=6, max_depth=30, min_child_weight=3, n_estimators=214, reg_alpha=0.004026635957416632, reg_lambda=0.040887904512512056, subsample=0.9250385544668723; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.1714583803805369, colsample_bytree=0.35540927532494104, gamma=1.3277909848852635e-06, learning_rate=0.5605967693796124, max_delta_step=6, max_depth=30, min_child_weight=3, n_estimators=214, reg_alpha=0.004026635957416632, reg_lambda=0.040887904512512056, subsample=0.9250385544668723; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.1714583803805369, colsample_bytree=0.35540927532494104, gamma=1.3277909848852635e-06, learning_rate=0.5605967693796124, max_delta_step=6, max_depth=30, min_child_weight=3, n_estimators=214, reg_alpha=0.004026635957416632, reg_lambda=0.040887904512512056, subsample=0.9250385544668723; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.1714583803805369, colsample_bytree=0.35540927532494104, gamma=1.3277909848852635e-06, learning_rate=0.5605967693796124, max_delta_step=6, max_depth=30, min_child_weight=3, n_estimators=214, reg_alpha=0.004026635957416632, reg_lambda=0.040887904512512056, subsample=0.9250385544668723; total time=   4.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.12212543829922852, colsample_bytree=0.6918603669668356, gamma=2.083286323303108e-05, learning_rate=0.4734922490673386, max_delta_step=3, max_depth=4, min_child_weight=3, n_estimators=18, reg_alpha=2.9618722230360503e-06, reg_lambda=8.153638964242, subsample=0.37377280619679043; total time=   0.3s\n",
      "[CV] END colsample_bylevel=0.12212543829922852, colsample_bytree=0.6918603669668356, gamma=2.083286323303108e-05, learning_rate=0.4734922490673386, max_delta_step=3, max_depth=4, min_child_weight=3, n_estimators=18, reg_alpha=2.9618722230360503e-06, reg_lambda=8.153638964242, subsample=0.37377280619679043; total time=   0.3s\n",
      "[CV] END colsample_bylevel=0.12212543829922852, colsample_bytree=0.6918603669668356, gamma=2.083286323303108e-05, learning_rate=0.4734922490673386, max_delta_step=3, max_depth=4, min_child_weight=3, n_estimators=18, reg_alpha=2.9618722230360503e-06, reg_lambda=8.153638964242, subsample=0.37377280619679043; total time=   0.3s\n",
      "[CV] END colsample_bylevel=0.12212543829922852, colsample_bytree=0.6918603669668356, gamma=2.083286323303108e-05, learning_rate=0.4734922490673386, max_delta_step=3, max_depth=4, min_child_weight=3, n_estimators=18, reg_alpha=2.9618722230360503e-06, reg_lambda=8.153638964242, subsample=0.37377280619679043; total time=   0.3s\n",
      "[CV] END colsample_bylevel=0.12212543829922852, colsample_bytree=0.6918603669668356, gamma=2.083286323303108e-05, learning_rate=0.4734922490673386, max_delta_step=3, max_depth=4, min_child_weight=3, n_estimators=18, reg_alpha=2.9618722230360503e-06, reg_lambda=8.153638964242, subsample=0.37377280619679043; total time=   0.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.8146216961026963, colsample_bytree=0.2519085390684862, gamma=0.03823613443879595, learning_rate=0.06786442521779147, max_delta_step=4, max_depth=11, min_child_weight=0, n_estimators=188, reg_alpha=0.00022356829889037284, reg_lambda=1.2908532337409298e-07, subsample=0.7697045536001489; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.8146216961026963, colsample_bytree=0.2519085390684862, gamma=0.03823613443879595, learning_rate=0.06786442521779147, max_delta_step=4, max_depth=11, min_child_weight=0, n_estimators=188, reg_alpha=0.00022356829889037284, reg_lambda=1.2908532337409298e-07, subsample=0.7697045536001489; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.8146216961026963, colsample_bytree=0.2519085390684862, gamma=0.03823613443879595, learning_rate=0.06786442521779147, max_delta_step=4, max_depth=11, min_child_weight=0, n_estimators=188, reg_alpha=0.00022356829889037284, reg_lambda=1.2908532337409298e-07, subsample=0.7697045536001489; total time=   7.7s\n",
      "[CV] END colsample_bylevel=0.8146216961026963, colsample_bytree=0.2519085390684862, gamma=0.03823613443879595, learning_rate=0.06786442521779147, max_delta_step=4, max_depth=11, min_child_weight=0, n_estimators=188, reg_alpha=0.00022356829889037284, reg_lambda=1.2908532337409298e-07, subsample=0.7697045536001489; total time=   8.0s\n",
      "[CV] END colsample_bylevel=0.8146216961026963, colsample_bytree=0.2519085390684862, gamma=0.03823613443879595, learning_rate=0.06786442521779147, max_delta_step=4, max_depth=11, min_child_weight=0, n_estimators=188, reg_alpha=0.00022356829889037284, reg_lambda=1.2908532337409298e-07, subsample=0.7697045536001489; total time=   8.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.010168587136004645, colsample_bytree=0.43217539671382244, gamma=0.002807995180059625, learning_rate=0.03229300915669146, max_delta_step=6, max_depth=14, min_child_weight=2, n_estimators=81, reg_alpha=0.11080071157037095, reg_lambda=5.745523087821567, subsample=0.7557881303057526; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.010168587136004645, colsample_bytree=0.43217539671382244, gamma=0.002807995180059625, learning_rate=0.03229300915669146, max_delta_step=6, max_depth=14, min_child_weight=2, n_estimators=81, reg_alpha=0.11080071157037095, reg_lambda=5.745523087821567, subsample=0.7557881303057526; total time=   1.0s\n",
      "[CV] END colsample_bylevel=0.010168587136004645, colsample_bytree=0.43217539671382244, gamma=0.002807995180059625, learning_rate=0.03229300915669146, max_delta_step=6, max_depth=14, min_child_weight=2, n_estimators=81, reg_alpha=0.11080071157037095, reg_lambda=5.745523087821567, subsample=0.7557881303057526; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.010168587136004645, colsample_bytree=0.43217539671382244, gamma=0.002807995180059625, learning_rate=0.03229300915669146, max_delta_step=6, max_depth=14, min_child_weight=2, n_estimators=81, reg_alpha=0.11080071157037095, reg_lambda=5.745523087821567, subsample=0.7557881303057526; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.010168587136004645, colsample_bytree=0.43217539671382244, gamma=0.002807995180059625, learning_rate=0.03229300915669146, max_delta_step=6, max_depth=14, min_child_weight=2, n_estimators=81, reg_alpha=0.11080071157037095, reg_lambda=5.745523087821567, subsample=0.7557881303057526; total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time= 1.1min\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time=  58.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.7002475020638926, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.01, max_delta_step=8, max_depth=46, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.7002475020638926, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.01, max_delta_step=8, max_depth=46, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.7002475020638926, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.01, max_delta_step=8, max_depth=46, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.7002475020638926, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.01, max_delta_step=8, max_depth=46, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.7002475020638926, colsample_bytree=0.01, gamma=0.49999999999999994, learning_rate=0.01, max_delta_step=8, max_depth=46, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   4.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.8421806800195952, colsample_bytree=0.5115420210512832, gamma=0.49999999999999994, learning_rate=0.08398167362197384, max_delta_step=0, max_depth=1, min_child_weight=1, n_estimators=236, reg_alpha=0.06526490502645614, reg_lambda=1e-09, subsample=0.934261570031225; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.8421806800195952, colsample_bytree=0.5115420210512832, gamma=0.49999999999999994, learning_rate=0.08398167362197384, max_delta_step=0, max_depth=1, min_child_weight=1, n_estimators=236, reg_alpha=0.06526490502645614, reg_lambda=1e-09, subsample=0.934261570031225; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.8421806800195952, colsample_bytree=0.5115420210512832, gamma=0.49999999999999994, learning_rate=0.08398167362197384, max_delta_step=0, max_depth=1, min_child_weight=1, n_estimators=236, reg_alpha=0.06526490502645614, reg_lambda=1e-09, subsample=0.934261570031225; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.8421806800195952, colsample_bytree=0.5115420210512832, gamma=0.49999999999999994, learning_rate=0.08398167362197384, max_delta_step=0, max_depth=1, min_child_weight=1, n_estimators=236, reg_alpha=0.06526490502645614, reg_lambda=1e-09, subsample=0.934261570031225; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.8421806800195952, colsample_bytree=0.5115420210512832, gamma=0.49999999999999994, learning_rate=0.08398167362197384, max_delta_step=0, max_depth=1, min_child_weight=1, n_estimators=236, reg_alpha=0.06526490502645614, reg_lambda=1e-09, subsample=0.934261570031225; total time=   2.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.39735337889912864, colsample_bytree=0.035913329429128955, gamma=8.847716779237782e-06, learning_rate=1.0, max_delta_step=5, max_depth=1, min_child_weight=4, n_estimators=427, reg_alpha=0.0011624585141953537, reg_lambda=0.18694361193002548, subsample=0.22013164048388031; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.39735337889912864, colsample_bytree=0.035913329429128955, gamma=8.847716779237782e-06, learning_rate=1.0, max_delta_step=5, max_depth=1, min_child_weight=4, n_estimators=427, reg_alpha=0.0011624585141953537, reg_lambda=0.18694361193002548, subsample=0.22013164048388031; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.39735337889912864, colsample_bytree=0.035913329429128955, gamma=8.847716779237782e-06, learning_rate=1.0, max_delta_step=5, max_depth=1, min_child_weight=4, n_estimators=427, reg_alpha=0.0011624585141953537, reg_lambda=0.18694361193002548, subsample=0.22013164048388031; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.39735337889912864, colsample_bytree=0.035913329429128955, gamma=8.847716779237782e-06, learning_rate=1.0, max_delta_step=5, max_depth=1, min_child_weight=4, n_estimators=427, reg_alpha=0.0011624585141953537, reg_lambda=0.18694361193002548, subsample=0.22013164048388031; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.39735337889912864, colsample_bytree=0.035913329429128955, gamma=8.847716779237782e-06, learning_rate=1.0, max_delta_step=5, max_depth=1, min_child_weight=4, n_estimators=427, reg_alpha=0.0011624585141953537, reg_lambda=0.18694361193002548, subsample=0.22013164048388031; total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.19590135289560326, colsample_bytree=0.577286259420219, gamma=1e-09, learning_rate=0.022594281389108052, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.470413722692899e-06, reg_lambda=3.8622627096202335, subsample=0.7606701653268505; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.19590135289560326, colsample_bytree=0.577286259420219, gamma=1e-09, learning_rate=0.022594281389108052, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.470413722692899e-06, reg_lambda=3.8622627096202335, subsample=0.7606701653268505; total time=  17.6s\n",
      "[CV] END colsample_bylevel=0.19590135289560326, colsample_bytree=0.577286259420219, gamma=1e-09, learning_rate=0.022594281389108052, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.470413722692899e-06, reg_lambda=3.8622627096202335, subsample=0.7606701653268505; total time=  17.7s\n",
      "[CV] END colsample_bylevel=0.19590135289560326, colsample_bytree=0.577286259420219, gamma=1e-09, learning_rate=0.022594281389108052, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.470413722692899e-06, reg_lambda=3.8622627096202335, subsample=0.7606701653268505; total time=  17.1s\n",
      "[CV] END colsample_bylevel=0.19590135289560326, colsample_bytree=0.577286259420219, gamma=1e-09, learning_rate=0.022594281389108052, max_delta_step=10, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.470413722692899e-06, reg_lambda=3.8622627096202335, subsample=0.7606701653268505; total time=  17.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.2785973550322379, colsample_bytree=0.08484464337192284, gamma=1e-09, learning_rate=0.04548086224105032, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=400, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.6440189879951507; total time=   3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.2785973550322379, colsample_bytree=0.08484464337192284, gamma=1e-09, learning_rate=0.04548086224105032, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=400, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.6440189879951507; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.2785973550322379, colsample_bytree=0.08484464337192284, gamma=1e-09, learning_rate=0.04548086224105032, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=400, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.6440189879951507; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.2785973550322379, colsample_bytree=0.08484464337192284, gamma=1e-09, learning_rate=0.04548086224105032, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=400, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.6440189879951507; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.2785973550322379, colsample_bytree=0.08484464337192284, gamma=1e-09, learning_rate=0.04548086224105032, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=400, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.6440189879951507; total time=   4.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.04763579590804077, colsample_bytree=0.0550938577481903, gamma=1.4811457837971553e-07, learning_rate=0.04285299872119978, max_delta_step=1, max_depth=9, min_child_weight=4, n_estimators=500, reg_alpha=0.001360938202759837, reg_lambda=1.1633756268462119e-07, subsample=0.49515738090365274; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.04763579590804077, colsample_bytree=0.0550938577481903, gamma=1.4811457837971553e-07, learning_rate=0.04285299872119978, max_delta_step=1, max_depth=9, min_child_weight=4, n_estimators=500, reg_alpha=0.001360938202759837, reg_lambda=1.1633756268462119e-07, subsample=0.49515738090365274; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.04763579590804077, colsample_bytree=0.0550938577481903, gamma=1.4811457837971553e-07, learning_rate=0.04285299872119978, max_delta_step=1, max_depth=9, min_child_weight=4, n_estimators=500, reg_alpha=0.001360938202759837, reg_lambda=1.1633756268462119e-07, subsample=0.49515738090365274; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.04763579590804077, colsample_bytree=0.0550938577481903, gamma=1.4811457837971553e-07, learning_rate=0.04285299872119978, max_delta_step=1, max_depth=9, min_child_weight=4, n_estimators=500, reg_alpha=0.001360938202759837, reg_lambda=1.1633756268462119e-07, subsample=0.49515738090365274; total time=   5.9s\n",
      "[CV] END colsample_bylevel=0.04763579590804077, colsample_bytree=0.0550938577481903, gamma=1.4811457837971553e-07, learning_rate=0.04285299872119978, max_delta_step=1, max_depth=9, min_child_weight=4, n_estimators=500, reg_alpha=0.001360938202759837, reg_lambda=1.1633756268462119e-07, subsample=0.49515738090365274; total time=   6.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=2, max_depth=6, min_child_weight=0, n_estimators=5, reg_alpha=0.02926937701637235, reg_lambda=0.0003241533953121653, subsample=0.7780383942948236; total time=   0.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=2, max_depth=6, min_child_weight=0, n_estimators=5, reg_alpha=0.02926937701637235, reg_lambda=0.0003241533953121653, subsample=0.7780383942948236; total time=   0.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=2, max_depth=6, min_child_weight=0, n_estimators=5, reg_alpha=0.02926937701637235, reg_lambda=0.0003241533953121653, subsample=0.7780383942948236; total time=   0.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=2, max_depth=6, min_child_weight=0, n_estimators=5, reg_alpha=0.02926937701637235, reg_lambda=0.0003241533953121653, subsample=0.7780383942948236; total time=   0.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=1e-09, learning_rate=1.0, max_delta_step=2, max_depth=6, min_child_weight=0, n_estimators=5, reg_alpha=0.02926937701637235, reg_lambda=0.0003241533953121653, subsample=0.7780383942948236; total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.030138122814774963, colsample_bytree=0.03176377683536847, gamma=1.3899622274340941e-06, learning_rate=0.02376704960208185, max_delta_step=1, max_depth=32, min_child_weight=0, n_estimators=148, reg_alpha=0.005453921727404934, reg_lambda=1.543485342647626e-08, subsample=0.6613411626620876; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.030138122814774963, colsample_bytree=0.03176377683536847, gamma=1.3899622274340941e-06, learning_rate=0.02376704960208185, max_delta_step=1, max_depth=32, min_child_weight=0, n_estimators=148, reg_alpha=0.005453921727404934, reg_lambda=1.543485342647626e-08, subsample=0.6613411626620876; total time=   1.5s\n",
      "[CV] END colsample_bylevel=0.030138122814774963, colsample_bytree=0.03176377683536847, gamma=1.3899622274340941e-06, learning_rate=0.02376704960208185, max_delta_step=1, max_depth=32, min_child_weight=0, n_estimators=148, reg_alpha=0.005453921727404934, reg_lambda=1.543485342647626e-08, subsample=0.6613411626620876; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.030138122814774963, colsample_bytree=0.03176377683536847, gamma=1.3899622274340941e-06, learning_rate=0.02376704960208185, max_delta_step=1, max_depth=32, min_child_weight=0, n_estimators=148, reg_alpha=0.005453921727404934, reg_lambda=1.543485342647626e-08, subsample=0.6613411626620876; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.030138122814774963, colsample_bytree=0.03176377683536847, gamma=1.3899622274340941e-06, learning_rate=0.02376704960208185, max_delta_step=1, max_depth=32, min_child_weight=0, n_estimators=148, reg_alpha=0.005453921727404934, reg_lambda=1.543485342647626e-08, subsample=0.6613411626620876; total time=   1.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.7790164074492844, colsample_bytree=0.4671968243893972, gamma=0.49999999999999994, learning_rate=0.11888108618739511, max_delta_step=10, max_depth=24, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   6.0s\n",
      "[CV] END colsample_bylevel=0.7790164074492844, colsample_bytree=0.4671968243893972, gamma=0.49999999999999994, learning_rate=0.11888108618739511, max_delta_step=10, max_depth=24, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   6.7s\n",
      "[CV] END colsample_bylevel=0.7790164074492844, colsample_bytree=0.4671968243893972, gamma=0.49999999999999994, learning_rate=0.11888108618739511, max_delta_step=10, max_depth=24, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.7790164074492844, colsample_bytree=0.4671968243893972, gamma=0.49999999999999994, learning_rate=0.11888108618739511, max_delta_step=10, max_depth=24, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.7790164074492844, colsample_bytree=0.4671968243893972, gamma=0.49999999999999994, learning_rate=0.11888108618739511, max_delta_step=10, max_depth=24, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   6.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.07667788323250989, gamma=0.000855984119157048, learning_rate=0.8034551477830688, max_delta_step=8, max_depth=23, min_child_weight=2, n_estimators=50, reg_alpha=2.6726775928135054e-08, reg_lambda=224.31952590703915, subsample=0.09107172332043588; total time=   0.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.07667788323250989, gamma=0.000855984119157048, learning_rate=0.8034551477830688, max_delta_step=8, max_depth=23, min_child_weight=2, n_estimators=50, reg_alpha=2.6726775928135054e-08, reg_lambda=224.31952590703915, subsample=0.09107172332043588; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.07667788323250989, gamma=0.000855984119157048, learning_rate=0.8034551477830688, max_delta_step=8, max_depth=23, min_child_weight=2, n_estimators=50, reg_alpha=2.6726775928135054e-08, reg_lambda=224.31952590703915, subsample=0.09107172332043588; total time=   0.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.07667788323250989, gamma=0.000855984119157048, learning_rate=0.8034551477830688, max_delta_step=8, max_depth=23, min_child_weight=2, n_estimators=50, reg_alpha=2.6726775928135054e-08, reg_lambda=224.31952590703915, subsample=0.09107172332043588; total time=   0.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.07667788323250989, gamma=0.000855984119157048, learning_rate=0.8034551477830688, max_delta_step=8, max_depth=23, min_child_weight=2, n_estimators=50, reg_alpha=2.6726775928135054e-08, reg_lambda=224.31952590703915, subsample=0.09107172332043588; total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.39438462331170243, colsample_bytree=0.7877212669558505, gamma=2.1780347201025553e-07, learning_rate=0.24171018707628852, max_delta_step=3, max_depth=29, min_child_weight=3, n_estimators=252, reg_alpha=0.00033583999311666805, reg_lambda=0.0026177639175983757, subsample=0.5308592443131508; total time=  16.4s\n",
      "[CV] END colsample_bylevel=0.39438462331170243, colsample_bytree=0.7877212669558505, gamma=2.1780347201025553e-07, learning_rate=0.24171018707628852, max_delta_step=3, max_depth=29, min_child_weight=3, n_estimators=252, reg_alpha=0.00033583999311666805, reg_lambda=0.0026177639175983757, subsample=0.5308592443131508; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.39438462331170243, colsample_bytree=0.7877212669558505, gamma=2.1780347201025553e-07, learning_rate=0.24171018707628852, max_delta_step=3, max_depth=29, min_child_weight=3, n_estimators=252, reg_alpha=0.00033583999311666805, reg_lambda=0.0026177639175983757, subsample=0.5308592443131508; total time=  16.6s\n",
      "[CV] END colsample_bylevel=0.39438462331170243, colsample_bytree=0.7877212669558505, gamma=2.1780347201025553e-07, learning_rate=0.24171018707628852, max_delta_step=3, max_depth=29, min_child_weight=3, n_estimators=252, reg_alpha=0.00033583999311666805, reg_lambda=0.0026177639175983757, subsample=0.5308592443131508; total time=  16.4s\n",
      "[CV] END colsample_bylevel=0.39438462331170243, colsample_bytree=0.7877212669558505, gamma=2.1780347201025553e-07, learning_rate=0.24171018707628852, max_delta_step=3, max_depth=29, min_child_weight=3, n_estimators=252, reg_alpha=0.00033583999311666805, reg_lambda=0.0026177639175983757, subsample=0.5308592443131508; total time=  16.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.01, gamma=2.6114124817811317e-09, learning_rate=1.0, max_delta_step=9, max_depth=1, min_child_weight=1, n_estimators=500, reg_alpha=1.9494001915285432e-05, reg_lambda=5.382159627088889e-05, subsample=0.030888863293971933; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.01, gamma=2.6114124817811317e-09, learning_rate=1.0, max_delta_step=9, max_depth=1, min_child_weight=1, n_estimators=500, reg_alpha=1.9494001915285432e-05, reg_lambda=5.382159627088889e-05, subsample=0.030888863293971933; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.01, gamma=2.6114124817811317e-09, learning_rate=1.0, max_delta_step=9, max_depth=1, min_child_weight=1, n_estimators=500, reg_alpha=1.9494001915285432e-05, reg_lambda=5.382159627088889e-05, subsample=0.030888863293971933; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.01, gamma=2.6114124817811317e-09, learning_rate=1.0, max_delta_step=9, max_depth=1, min_child_weight=1, n_estimators=500, reg_alpha=1.9494001915285432e-05, reg_lambda=5.382159627088889e-05, subsample=0.030888863293971933; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.01, gamma=2.6114124817811317e-09, learning_rate=1.0, max_delta_step=9, max_depth=1, min_child_weight=1, n_estimators=500, reg_alpha=1.9494001915285432e-05, reg_lambda=5.382159627088889e-05, subsample=0.030888863293971933; total time=   4.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=500, reg_alpha=3.58424864715395e-08, reg_lambda=1e-09, subsample=0.41297330306432767; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=500, reg_alpha=3.58424864715395e-08, reg_lambda=1e-09, subsample=0.41297330306432767; total time=   6.4s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=500, reg_alpha=3.58424864715395e-08, reg_lambda=1e-09, subsample=0.41297330306432767; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=500, reg_alpha=3.58424864715395e-08, reg_lambda=1e-09, subsample=0.41297330306432767; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=4, n_estimators=500, reg_alpha=3.58424864715395e-08, reg_lambda=1e-09, subsample=0.41297330306432767; total time=   6.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.21056036902598296, colsample_bytree=1.0, gamma=3.7319549114662194e-05, learning_rate=0.011651420336706313, max_delta_step=7, max_depth=29, min_child_weight=4, n_estimators=500, reg_alpha=2.035792628354188e-06, reg_lambda=15.427136601443614, subsample=0.7734244978499148; total time=  23.6s\n",
      "[CV] END colsample_bylevel=0.21056036902598296, colsample_bytree=1.0, gamma=3.7319549114662194e-05, learning_rate=0.011651420336706313, max_delta_step=7, max_depth=29, min_child_weight=4, n_estimators=500, reg_alpha=2.035792628354188e-06, reg_lambda=15.427136601443614, subsample=0.7734244978499148; total time=  24.2s\n",
      "[CV] END colsample_bylevel=0.21056036902598296, colsample_bytree=1.0, gamma=3.7319549114662194e-05, learning_rate=0.011651420336706313, max_delta_step=7, max_depth=29, min_child_weight=4, n_estimators=500, reg_alpha=2.035792628354188e-06, reg_lambda=15.427136601443614, subsample=0.7734244978499148; total time=  24.7s\n",
      "[CV] END colsample_bylevel=0.21056036902598296, colsample_bytree=1.0, gamma=3.7319549114662194e-05, learning_rate=0.011651420336706313, max_delta_step=7, max_depth=29, min_child_weight=4, n_estimators=500, reg_alpha=2.035792628354188e-06, reg_lambda=15.427136601443614, subsample=0.7734244978499148; total time=  24.6s\n",
      "[CV] END colsample_bylevel=0.21056036902598296, colsample_bytree=1.0, gamma=3.7319549114662194e-05, learning_rate=0.011651420336706313, max_delta_step=7, max_depth=29, min_child_weight=4, n_estimators=500, reg_alpha=2.035792628354188e-06, reg_lambda=15.427136601443614, subsample=0.7734244978499148; total time=  24.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.11089794249828201, colsample_bytree=0.10849130966839833, gamma=0.04401938175814953, learning_rate=1.0, max_delta_step=2, max_depth=32, min_child_weight=1, n_estimators=500, reg_alpha=2.573110505563528e-08, reg_lambda=0.001552361594290632, subsample=0.7408465389290919; total time=   5.6s\n",
      "[CV] END colsample_bylevel=0.11089794249828201, colsample_bytree=0.10849130966839833, gamma=0.04401938175814953, learning_rate=1.0, max_delta_step=2, max_depth=32, min_child_weight=1, n_estimators=500, reg_alpha=2.573110505563528e-08, reg_lambda=0.001552361594290632, subsample=0.7408465389290919; total time=   6.2s\n",
      "[CV] END colsample_bylevel=0.11089794249828201, colsample_bytree=0.10849130966839833, gamma=0.04401938175814953, learning_rate=1.0, max_delta_step=2, max_depth=32, min_child_weight=1, n_estimators=500, reg_alpha=2.573110505563528e-08, reg_lambda=0.001552361594290632, subsample=0.7408465389290919; total time=   6.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.11089794249828201, colsample_bytree=0.10849130966839833, gamma=0.04401938175814953, learning_rate=1.0, max_delta_step=2, max_depth=32, min_child_weight=1, n_estimators=500, reg_alpha=2.573110505563528e-08, reg_lambda=0.001552361594290632, subsample=0.7408465389290919; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.11089794249828201, colsample_bytree=0.10849130966839833, gamma=0.04401938175814953, learning_rate=1.0, max_delta_step=2, max_depth=32, min_child_weight=1, n_estimators=500, reg_alpha=2.573110505563528e-08, reg_lambda=0.001552361594290632, subsample=0.7408465389290919; total time=   6.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.10444757251692395, colsample_bytree=0.0962663794150312, gamma=0.12870479757534006, learning_rate=0.21760003988266768, max_delta_step=5, max_depth=1, min_child_weight=0, n_estimators=500, reg_alpha=0.3180658822751873, reg_lambda=4.58098157111617e-09, subsample=0.5852469561972665; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.10444757251692395, colsample_bytree=0.0962663794150312, gamma=0.12870479757534006, learning_rate=0.21760003988266768, max_delta_step=5, max_depth=1, min_child_weight=0, n_estimators=500, reg_alpha=0.3180658822751873, reg_lambda=4.58098157111617e-09, subsample=0.5852469561972665; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.10444757251692395, colsample_bytree=0.0962663794150312, gamma=0.12870479757534006, learning_rate=0.21760003988266768, max_delta_step=5, max_depth=1, min_child_weight=0, n_estimators=500, reg_alpha=0.3180658822751873, reg_lambda=4.58098157111617e-09, subsample=0.5852469561972665; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.10444757251692395, colsample_bytree=0.0962663794150312, gamma=0.12870479757534006, learning_rate=0.21760003988266768, max_delta_step=5, max_depth=1, min_child_weight=0, n_estimators=500, reg_alpha=0.3180658822751873, reg_lambda=4.58098157111617e-09, subsample=0.5852469561972665; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.10444757251692395, colsample_bytree=0.0962663794150312, gamma=0.12870479757534006, learning_rate=0.21760003988266768, max_delta_step=5, max_depth=1, min_child_weight=0, n_estimators=500, reg_alpha=0.3180658822751873, reg_lambda=4.58098157111617e-09, subsample=0.5852469561972665; total time=   5.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=0.5040255818983609; total time=   5.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=0.5040255818983609; total time=   5.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=0.5040255818983609; total time=   5.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=0.5040255818983609; total time=   5.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=0.5040255818983609; total time=   5.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.09767241328091507, gamma=1.5561687272463924e-08, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=407, reg_alpha=0.00029865943624145946, reg_lambda=1.9384772933815473e-09, subsample=0.31991809228352; total time=   8.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.09767241328091507, gamma=1.5561687272463924e-08, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=407, reg_alpha=0.00029865943624145946, reg_lambda=1.9384772933815473e-09, subsample=0.31991809228352; total time=   8.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.09767241328091507, gamma=1.5561687272463924e-08, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=407, reg_alpha=0.00029865943624145946, reg_lambda=1.9384772933815473e-09, subsample=0.31991809228352; total time=   9.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.09767241328091507, gamma=1.5561687272463924e-08, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=407, reg_alpha=0.00029865943624145946, reg_lambda=1.9384772933815473e-09, subsample=0.31991809228352; total time=   8.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.09767241328091507, gamma=1.5561687272463924e-08, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=407, reg_alpha=0.00029865943624145946, reg_lambda=1.9384772933815473e-09, subsample=0.31991809228352; total time=   8.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.19534675445433802, colsample_bytree=0.897025648721257, gamma=1e-09, learning_rate=0.022172474388689894, max_delta_step=10, max_depth=45, min_child_weight=5, n_estimators=500, reg_alpha=4.996054364269141e-05, reg_lambda=6.268264725350347, subsample=0.7596679515594221; total time=  25.9s\n",
      "[CV] END colsample_bylevel=0.19534675445433802, colsample_bytree=0.897025648721257, gamma=1e-09, learning_rate=0.022172474388689894, max_delta_step=10, max_depth=45, min_child_weight=5, n_estimators=500, reg_alpha=4.996054364269141e-05, reg_lambda=6.268264725350347, subsample=0.7596679515594221; total time=  26.5s\n",
      "[CV] END colsample_bylevel=0.19534675445433802, colsample_bytree=0.897025648721257, gamma=1e-09, learning_rate=0.022172474388689894, max_delta_step=10, max_depth=45, min_child_weight=5, n_estimators=500, reg_alpha=4.996054364269141e-05, reg_lambda=6.268264725350347, subsample=0.7596679515594221; total time=  28.9s\n",
      "[CV] END colsample_bylevel=0.19534675445433802, colsample_bytree=0.897025648721257, gamma=1e-09, learning_rate=0.022172474388689894, max_delta_step=10, max_depth=45, min_child_weight=5, n_estimators=500, reg_alpha=4.996054364269141e-05, reg_lambda=6.268264725350347, subsample=0.7596679515594221; total time=  26.1s\n",
      "[CV] END colsample_bylevel=0.19534675445433802, colsample_bytree=0.897025648721257, gamma=1e-09, learning_rate=0.022172474388689894, max_delta_step=10, max_depth=45, min_child_weight=5, n_estimators=500, reg_alpha=4.996054364269141e-05, reg_lambda=6.268264725350347, subsample=0.7596679515594221; total time=  29.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.14829985193380493, colsample_bytree=0.5182992496604915, gamma=3.844561639074477e-06, learning_rate=0.027922938314627905, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=500, reg_alpha=0.00022507553985555762, reg_lambda=0.007069756714818584, subsample=0.5440591360974508; total time=  16.5s\n",
      "[CV] END colsample_bylevel=0.14829985193380493, colsample_bytree=0.5182992496604915, gamma=3.844561639074477e-06, learning_rate=0.027922938314627905, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=500, reg_alpha=0.00022507553985555762, reg_lambda=0.007069756714818584, subsample=0.5440591360974508; total time=  20.4s\n",
      "[CV] END colsample_bylevel=0.14829985193380493, colsample_bytree=0.5182992496604915, gamma=3.844561639074477e-06, learning_rate=0.027922938314627905, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=500, reg_alpha=0.00022507553985555762, reg_lambda=0.007069756714818584, subsample=0.5440591360974508; total time=  37.6s\n",
      "[CV] END colsample_bylevel=0.14829985193380493, colsample_bytree=0.5182992496604915, gamma=3.844561639074477e-06, learning_rate=0.027922938314627905, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=500, reg_alpha=0.00022507553985555762, reg_lambda=0.007069756714818584, subsample=0.5440591360974508; total time=  23.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.14829985193380493, colsample_bytree=0.5182992496604915, gamma=3.844561639074477e-06, learning_rate=0.027922938314627905, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=500, reg_alpha=0.00022507553985555762, reg_lambda=0.007069756714818584, subsample=0.5440591360974508; total time=  27.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.28648244943778445, colsample_bytree=0.08727556696439354, gamma=0.00020513592996544092, learning_rate=0.39951065752927256, max_delta_step=10, max_depth=22, min_child_weight=2, n_estimators=337, reg_alpha=4.5535864899521004e-05, reg_lambda=1000.0, subsample=0.9486626695568322; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.28648244943778445, colsample_bytree=0.08727556696439354, gamma=0.00020513592996544092, learning_rate=0.39951065752927256, max_delta_step=10, max_depth=22, min_child_weight=2, n_estimators=337, reg_alpha=4.5535864899521004e-05, reg_lambda=1000.0, subsample=0.9486626695568322; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.28648244943778445, colsample_bytree=0.08727556696439354, gamma=0.00020513592996544092, learning_rate=0.39951065752927256, max_delta_step=10, max_depth=22, min_child_weight=2, n_estimators=337, reg_alpha=4.5535864899521004e-05, reg_lambda=1000.0, subsample=0.9486626695568322; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.28648244943778445, colsample_bytree=0.08727556696439354, gamma=0.00020513592996544092, learning_rate=0.39951065752927256, max_delta_step=10, max_depth=22, min_child_weight=2, n_estimators=337, reg_alpha=4.5535864899521004e-05, reg_lambda=1000.0, subsample=0.9486626695568322; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.28648244943778445, colsample_bytree=0.08727556696439354, gamma=0.00020513592996544092, learning_rate=0.39951065752927256, max_delta_step=10, max_depth=22, min_child_weight=2, n_estimators=337, reg_alpha=4.5535864899521004e-05, reg_lambda=1000.0, subsample=0.9486626695568322; total time=   4.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.0437230688035735, colsample_bytree=1.0, gamma=0.2551420865427861, learning_rate=1.0, max_delta_step=2, max_depth=1, min_child_weight=3, n_estimators=500, reg_alpha=3.8323194911783535e-08, reg_lambda=0.00029901116775550747, subsample=0.01; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.0437230688035735, colsample_bytree=1.0, gamma=0.2551420865427861, learning_rate=1.0, max_delta_step=2, max_depth=1, min_child_weight=3, n_estimators=500, reg_alpha=3.8323194911783535e-08, reg_lambda=0.00029901116775550747, subsample=0.01; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.0437230688035735, colsample_bytree=1.0, gamma=0.2551420865427861, learning_rate=1.0, max_delta_step=2, max_depth=1, min_child_weight=3, n_estimators=500, reg_alpha=3.8323194911783535e-08, reg_lambda=0.00029901116775550747, subsample=0.01; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.0437230688035735, colsample_bytree=1.0, gamma=0.2551420865427861, learning_rate=1.0, max_delta_step=2, max_depth=1, min_child_weight=3, n_estimators=500, reg_alpha=3.8323194911783535e-08, reg_lambda=0.00029901116775550747, subsample=0.01; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.0437230688035735, colsample_bytree=1.0, gamma=0.2551420865427861, learning_rate=1.0, max_delta_step=2, max_depth=1, min_child_weight=3, n_estimators=500, reg_alpha=3.8323194911783535e-08, reg_lambda=0.00029901116775550747, subsample=0.01; total time=   5.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.1727835565726224, colsample_bytree=1.0, gamma=2.2508236826320875e-08, learning_rate=0.025958792260523056, max_delta_step=10, max_depth=34, min_child_weight=4, n_estimators=500, reg_alpha=0.0006475636813875049, reg_lambda=0.0018463775274436315, subsample=0.6247399197692135; total time=  31.2s\n",
      "[CV] END colsample_bylevel=0.1727835565726224, colsample_bytree=1.0, gamma=2.2508236826320875e-08, learning_rate=0.025958792260523056, max_delta_step=10, max_depth=34, min_child_weight=4, n_estimators=500, reg_alpha=0.0006475636813875049, reg_lambda=0.0018463775274436315, subsample=0.6247399197692135; total time=  39.1s\n",
      "[CV] END colsample_bylevel=0.1727835565726224, colsample_bytree=1.0, gamma=2.2508236826320875e-08, learning_rate=0.025958792260523056, max_delta_step=10, max_depth=34, min_child_weight=4, n_estimators=500, reg_alpha=0.0006475636813875049, reg_lambda=0.0018463775274436315, subsample=0.6247399197692135; total time=  39.2s\n",
      "[CV] END colsample_bylevel=0.1727835565726224, colsample_bytree=1.0, gamma=2.2508236826320875e-08, learning_rate=0.025958792260523056, max_delta_step=10, max_depth=34, min_child_weight=4, n_estimators=500, reg_alpha=0.0006475636813875049, reg_lambda=0.0018463775274436315, subsample=0.6247399197692135; total time=  34.3s\n",
      "[CV] END colsample_bylevel=0.1727835565726224, colsample_bytree=1.0, gamma=2.2508236826320875e-08, learning_rate=0.025958792260523056, max_delta_step=10, max_depth=34, min_child_weight=4, n_estimators=500, reg_alpha=0.0006475636813875049, reg_lambda=0.0018463775274436315, subsample=0.6247399197692135; total time=  23.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.011623902357054803, colsample_bytree=0.25057038741540144, gamma=0.0012362424437348486, learning_rate=0.06660959466007564, max_delta_step=7, max_depth=47, min_child_weight=5, n_estimators=500, reg_alpha=1.5965524928527002e-06, reg_lambda=1e-09, subsample=0.01; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.011623902357054803, colsample_bytree=0.25057038741540144, gamma=0.0012362424437348486, learning_rate=0.06660959466007564, max_delta_step=7, max_depth=47, min_child_weight=5, n_estimators=500, reg_alpha=1.5965524928527002e-06, reg_lambda=1e-09, subsample=0.01; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.011623902357054803, colsample_bytree=0.25057038741540144, gamma=0.0012362424437348486, learning_rate=0.06660959466007564, max_delta_step=7, max_depth=47, min_child_weight=5, n_estimators=500, reg_alpha=1.5965524928527002e-06, reg_lambda=1e-09, subsample=0.01; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.011623902357054803, colsample_bytree=0.25057038741540144, gamma=0.0012362424437348486, learning_rate=0.06660959466007564, max_delta_step=7, max_depth=47, min_child_weight=5, n_estimators=500, reg_alpha=1.5965524928527002e-06, reg_lambda=1e-09, subsample=0.01; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.011623902357054803, colsample_bytree=0.25057038741540144, gamma=0.0012362424437348486, learning_rate=0.06660959466007564, max_delta_step=7, max_depth=47, min_child_weight=5, n_estimators=500, reg_alpha=1.5965524928527002e-06, reg_lambda=1e-09, subsample=0.01; total time=   4.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.15773384952231573, colsample_bytree=1.0, gamma=5.448915562036313e-07, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=127, reg_alpha=3.0265273049519783e-06, reg_lambda=161.6969865188672, subsample=0.9267124623993075; total time=   8.4s\n",
      "[CV] END colsample_bylevel=0.15773384952231573, colsample_bytree=1.0, gamma=5.448915562036313e-07, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=127, reg_alpha=3.0265273049519783e-06, reg_lambda=161.6969865188672, subsample=0.9267124623993075; total time=   9.4s\n",
      "[CV] END colsample_bylevel=0.15773384952231573, colsample_bytree=1.0, gamma=5.448915562036313e-07, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=127, reg_alpha=3.0265273049519783e-06, reg_lambda=161.6969865188672, subsample=0.9267124623993075; total time=   9.1s\n",
      "[CV] END colsample_bylevel=0.15773384952231573, colsample_bytree=1.0, gamma=5.448915562036313e-07, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=127, reg_alpha=3.0265273049519783e-06, reg_lambda=161.6969865188672, subsample=0.9267124623993075; total time=   9.9s\n",
      "[CV] END colsample_bylevel=0.15773384952231573, colsample_bytree=1.0, gamma=5.448915562036313e-07, learning_rate=1.0, max_delta_step=9, max_depth=50, min_child_weight=0, n_estimators=127, reg_alpha=3.0265273049519783e-06, reg_lambda=161.6969865188672, subsample=0.9267124623993075; total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.5690121129021709, colsample_bytree=0.7889526306926968, gamma=2.9314917580657545e-06, learning_rate=0.024223631884345398, max_delta_step=8, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0.001468214211444276, reg_lambda=3.2674306775447106e-05, subsample=0.5279228646144373; total time=  14.0s\n",
      "[CV] END colsample_bylevel=0.5690121129021709, colsample_bytree=0.7889526306926968, gamma=2.9314917580657545e-06, learning_rate=0.024223631884345398, max_delta_step=8, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0.001468214211444276, reg_lambda=3.2674306775447106e-05, subsample=0.5279228646144373; total time=  17.2s\n",
      "[CV] END colsample_bylevel=0.5690121129021709, colsample_bytree=0.7889526306926968, gamma=2.9314917580657545e-06, learning_rate=0.024223631884345398, max_delta_step=8, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0.001468214211444276, reg_lambda=3.2674306775447106e-05, subsample=0.5279228646144373; total time=  12.7s\n",
      "[CV] END colsample_bylevel=0.5690121129021709, colsample_bytree=0.7889526306926968, gamma=2.9314917580657545e-06, learning_rate=0.024223631884345398, max_delta_step=8, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0.001468214211444276, reg_lambda=3.2674306775447106e-05, subsample=0.5279228646144373; total time=  11.1s\n",
      "[CV] END colsample_bylevel=0.5690121129021709, colsample_bytree=0.7889526306926968, gamma=2.9314917580657545e-06, learning_rate=0.024223631884345398, max_delta_step=8, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0.001468214211444276, reg_lambda=3.2674306775447106e-05, subsample=0.5279228646144373; total time=  14.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.44851329708204246, colsample_bytree=0.01, gamma=6.886095162913656e-05, learning_rate=0.9438871846199989, max_delta_step=0, max_depth=21, min_child_weight=3, n_estimators=500, reg_alpha=0.0006497466112508792, reg_lambda=1e-09, subsample=0.01; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.44851329708204246, colsample_bytree=0.01, gamma=6.886095162913656e-05, learning_rate=0.9438871846199989, max_delta_step=0, max_depth=21, min_child_weight=3, n_estimators=500, reg_alpha=0.0006497466112508792, reg_lambda=1e-09, subsample=0.01; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.44851329708204246, colsample_bytree=0.01, gamma=6.886095162913656e-05, learning_rate=0.9438871846199989, max_delta_step=0, max_depth=21, min_child_weight=3, n_estimators=500, reg_alpha=0.0006497466112508792, reg_lambda=1e-09, subsample=0.01; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.44851329708204246, colsample_bytree=0.01, gamma=6.886095162913656e-05, learning_rate=0.9438871846199989, max_delta_step=0, max_depth=21, min_child_weight=3, n_estimators=500, reg_alpha=0.0006497466112508792, reg_lambda=1e-09, subsample=0.01; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.44851329708204246, colsample_bytree=0.01, gamma=6.886095162913656e-05, learning_rate=0.9438871846199989, max_delta_step=0, max_depth=21, min_child_weight=3, n_estimators=500, reg_alpha=0.0006497466112508792, reg_lambda=1e-09, subsample=0.01; total time=   5.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.02807346415580887, gamma=0.0034736468532378215, learning_rate=1.0, max_delta_step=4, max_depth=50, min_child_weight=5, n_estimators=5, reg_alpha=0.09856793934589639, reg_lambda=19.156232770984133, subsample=0.09777370309302626; total time=   0.1s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.02807346415580887, gamma=0.0034736468532378215, learning_rate=1.0, max_delta_step=4, max_depth=50, min_child_weight=5, n_estimators=5, reg_alpha=0.09856793934589639, reg_lambda=19.156232770984133, subsample=0.09777370309302626; total time=   0.1s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.02807346415580887, gamma=0.0034736468532378215, learning_rate=1.0, max_delta_step=4, max_depth=50, min_child_weight=5, n_estimators=5, reg_alpha=0.09856793934589639, reg_lambda=19.156232770984133, subsample=0.09777370309302626; total time=   0.1s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.02807346415580887, gamma=0.0034736468532378215, learning_rate=1.0, max_delta_step=4, max_depth=50, min_child_weight=5, n_estimators=5, reg_alpha=0.09856793934589639, reg_lambda=19.156232770984133, subsample=0.09777370309302626; total time=   0.1s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.02807346415580887, gamma=0.0034736468532378215, learning_rate=1.0, max_delta_step=4, max_depth=50, min_child_weight=5, n_estimators=5, reg_alpha=0.09856793934589639, reg_lambda=19.156232770984133, subsample=0.09777370309302626; total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=0.1331896895769328, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=3.598488787309334e-08, subsample=0.9719772092049738; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=0.1331896895769328, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=3.598488787309334e-08, subsample=0.9719772092049738; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=0.1331896895769328, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=3.598488787309334e-08, subsample=0.9719772092049738; total time=   2.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=0.1331896895769328, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=3.598488787309334e-08, subsample=0.9719772092049738; total time=   2.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=0.1331896895769328, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=3.598488787309334e-08, subsample=0.9719772092049738; total time=   2.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.6170416683147022, colsample_bytree=0.03158505515174435, gamma=2.928628486549676e-05, learning_rate=0.429080541094093, max_delta_step=8, max_depth=13, min_child_weight=3, n_estimators=388, reg_alpha=1.0, reg_lambda=9.61697262113541e-09, subsample=0.14006440545976545; total time=   4.1s\n",
      "[CV] END colsample_bylevel=0.6170416683147022, colsample_bytree=0.03158505515174435, gamma=2.928628486549676e-05, learning_rate=0.429080541094093, max_delta_step=8, max_depth=13, min_child_weight=3, n_estimators=388, reg_alpha=1.0, reg_lambda=9.61697262113541e-09, subsample=0.14006440545976545; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.6170416683147022, colsample_bytree=0.03158505515174435, gamma=2.928628486549676e-05, learning_rate=0.429080541094093, max_delta_step=8, max_depth=13, min_child_weight=3, n_estimators=388, reg_alpha=1.0, reg_lambda=9.61697262113541e-09, subsample=0.14006440545976545; total time=   4.0s\n",
      "[CV] END colsample_bylevel=0.6170416683147022, colsample_bytree=0.03158505515174435, gamma=2.928628486549676e-05, learning_rate=0.429080541094093, max_delta_step=8, max_depth=13, min_child_weight=3, n_estimators=388, reg_alpha=1.0, reg_lambda=9.61697262113541e-09, subsample=0.14006440545976545; total time=   4.1s\n",
      "[CV] END colsample_bylevel=0.6170416683147022, colsample_bytree=0.03158505515174435, gamma=2.928628486549676e-05, learning_rate=0.429080541094093, max_delta_step=8, max_depth=13, min_child_weight=3, n_estimators=388, reg_alpha=1.0, reg_lambda=9.61697262113541e-09, subsample=0.14006440545976545; total time=   4.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.3251151986978744, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=1, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=0.03180561002309462, subsample=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.3251151986978744, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=1, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=0.03180561002309462, subsample=0.01; total time=   0.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.3251151986978744, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=1, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=0.03180561002309462, subsample=0.01; total time=   0.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.3251151986978744, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=1, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=0.03180561002309462, subsample=0.01; total time=   0.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.3251151986978744, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=1, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=0.03180561002309462, subsample=0.01; total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.2952482739927273, colsample_bytree=0.0640473810251892, gamma=2.451602424618262e-06, learning_rate=0.6588364758655946, max_delta_step=8, max_depth=1, min_child_weight=4, n_estimators=480, reg_alpha=0.09060273436358458, reg_lambda=0.026326996838281373, subsample=0.5103627947645797; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.2952482739927273, colsample_bytree=0.0640473810251892, gamma=2.451602424618262e-06, learning_rate=0.6588364758655946, max_delta_step=8, max_depth=1, min_child_weight=4, n_estimators=480, reg_alpha=0.09060273436358458, reg_lambda=0.026326996838281373, subsample=0.5103627947645797; total time=   5.5s\n",
      "[CV] END colsample_bylevel=0.2952482739927273, colsample_bytree=0.0640473810251892, gamma=2.451602424618262e-06, learning_rate=0.6588364758655946, max_delta_step=8, max_depth=1, min_child_weight=4, n_estimators=480, reg_alpha=0.09060273436358458, reg_lambda=0.026326996838281373, subsample=0.5103627947645797; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.2952482739927273, colsample_bytree=0.0640473810251892, gamma=2.451602424618262e-06, learning_rate=0.6588364758655946, max_delta_step=8, max_depth=1, min_child_weight=4, n_estimators=480, reg_alpha=0.09060273436358458, reg_lambda=0.026326996838281373, subsample=0.5103627947645797; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.2952482739927273, colsample_bytree=0.0640473810251892, gamma=2.451602424618262e-06, learning_rate=0.6588364758655946, max_delta_step=8, max_depth=1, min_child_weight=4, n_estimators=480, reg_alpha=0.09060273436358458, reg_lambda=0.026326996838281373, subsample=0.5103627947645797; total time=   5.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.5449052957508459, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=8, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.5449052957508459, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=8, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.5449052957508459, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=8, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.5449052957508459, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=8, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.5449052957508459, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=8, min_child_weight=5, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=1.0; total time=   5.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.14037764708464362, gamma=0.49999999999999994, learning_rate=0.22337913198735784, max_delta_step=4, max_depth=1, min_child_weight=0, n_estimators=250, reg_alpha=0.0005635081920738189, reg_lambda=1000.0, subsample=0.9163498672468355; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.14037764708464362, gamma=0.49999999999999994, learning_rate=0.22337913198735784, max_delta_step=4, max_depth=1, min_child_weight=0, n_estimators=250, reg_alpha=0.0005635081920738189, reg_lambda=1000.0, subsample=0.9163498672468355; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.14037764708464362, gamma=0.49999999999999994, learning_rate=0.22337913198735784, max_delta_step=4, max_depth=1, min_child_weight=0, n_estimators=250, reg_alpha=0.0005635081920738189, reg_lambda=1000.0, subsample=0.9163498672468355; total time=   2.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.14037764708464362, gamma=0.49999999999999994, learning_rate=0.22337913198735784, max_delta_step=4, max_depth=1, min_child_weight=0, n_estimators=250, reg_alpha=0.0005635081920738189, reg_lambda=1000.0, subsample=0.9163498672468355; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.14037764708464362, gamma=0.49999999999999994, learning_rate=0.22337913198735784, max_delta_step=4, max_depth=1, min_child_weight=0, n_estimators=250, reg_alpha=0.0005635081920738189, reg_lambda=1000.0, subsample=0.9163498672468355; total time=   2.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=1, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=1, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=1, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=1, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=10, max_depth=1, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1e-09, subsample=1.0; total time=   3.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.5078580372891766, colsample_bytree=0.20960770484747895, gamma=1e-09, learning_rate=0.01, max_delta_step=8, max_depth=31, min_child_weight=3, n_estimators=231, reg_alpha=1e-09, reg_lambda=4.837898851917435e-05, subsample=0.01; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.5078580372891766, colsample_bytree=0.20960770484747895, gamma=1e-09, learning_rate=0.01, max_delta_step=8, max_depth=31, min_child_weight=3, n_estimators=231, reg_alpha=1e-09, reg_lambda=4.837898851917435e-05, subsample=0.01; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.5078580372891766, colsample_bytree=0.20960770484747895, gamma=1e-09, learning_rate=0.01, max_delta_step=8, max_depth=31, min_child_weight=3, n_estimators=231, reg_alpha=1e-09, reg_lambda=4.837898851917435e-05, subsample=0.01; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.5078580372891766, colsample_bytree=0.20960770484747895, gamma=1e-09, learning_rate=0.01, max_delta_step=8, max_depth=31, min_child_weight=3, n_estimators=231, reg_alpha=1e-09, reg_lambda=4.837898851917435e-05, subsample=0.01; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.5078580372891766, colsample_bytree=0.20960770484747895, gamma=1e-09, learning_rate=0.01, max_delta_step=8, max_depth=31, min_child_weight=3, n_estimators=231, reg_alpha=1e-09, reg_lambda=4.837898851917435e-05, subsample=0.01; total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.44686293146034456, colsample_bytree=0.4852710175782253, gamma=0.49999999999999994, learning_rate=0.07585144439738514, max_delta_step=6, max_depth=20, min_child_weight=0, n_estimators=264, reg_alpha=1.267561730668103e-07, reg_lambda=6.287882895069734e-08, subsample=0.22260920963235123; total time=  18.5s\n",
      "[CV] END colsample_bylevel=0.44686293146034456, colsample_bytree=0.4852710175782253, gamma=0.49999999999999994, learning_rate=0.07585144439738514, max_delta_step=6, max_depth=20, min_child_weight=0, n_estimators=264, reg_alpha=1.267561730668103e-07, reg_lambda=6.287882895069734e-08, subsample=0.22260920963235123; total time=  19.0s\n",
      "[CV] END colsample_bylevel=0.44686293146034456, colsample_bytree=0.4852710175782253, gamma=0.49999999999999994, learning_rate=0.07585144439738514, max_delta_step=6, max_depth=20, min_child_weight=0, n_estimators=264, reg_alpha=1.267561730668103e-07, reg_lambda=6.287882895069734e-08, subsample=0.22260920963235123; total time=  18.1s\n",
      "[CV] END colsample_bylevel=0.44686293146034456, colsample_bytree=0.4852710175782253, gamma=0.49999999999999994, learning_rate=0.07585144439738514, max_delta_step=6, max_depth=20, min_child_weight=0, n_estimators=264, reg_alpha=1.267561730668103e-07, reg_lambda=6.287882895069734e-08, subsample=0.22260920963235123; total time=  18.1s\n",
      "[CV] END colsample_bylevel=0.44686293146034456, colsample_bytree=0.4852710175782253, gamma=0.49999999999999994, learning_rate=0.07585144439738514, max_delta_step=6, max_depth=20, min_child_weight=0, n_estimators=264, reg_alpha=1.267561730668103e-07, reg_lambda=6.287882895069734e-08, subsample=0.22260920963235123; total time=  18.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.11223421206030774, colsample_bytree=0.6581156882156494, gamma=0.49999999999999994, learning_rate=0.023204171548890436, max_delta_step=7, max_depth=1, min_child_weight=0, n_estimators=437, reg_alpha=0.011861829307728177, reg_lambda=0.009402886016022604, subsample=0.44695633591965944; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.11223421206030774, colsample_bytree=0.6581156882156494, gamma=0.49999999999999994, learning_rate=0.023204171548890436, max_delta_step=7, max_depth=1, min_child_weight=0, n_estimators=437, reg_alpha=0.011861829307728177, reg_lambda=0.009402886016022604, subsample=0.44695633591965944; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.11223421206030774, colsample_bytree=0.6581156882156494, gamma=0.49999999999999994, learning_rate=0.023204171548890436, max_delta_step=7, max_depth=1, min_child_weight=0, n_estimators=437, reg_alpha=0.011861829307728177, reg_lambda=0.009402886016022604, subsample=0.44695633591965944; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.11223421206030774, colsample_bytree=0.6581156882156494, gamma=0.49999999999999994, learning_rate=0.023204171548890436, max_delta_step=7, max_depth=1, min_child_weight=0, n_estimators=437, reg_alpha=0.011861829307728177, reg_lambda=0.009402886016022604, subsample=0.44695633591965944; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.11223421206030774, colsample_bytree=0.6581156882156494, gamma=0.49999999999999994, learning_rate=0.023204171548890436, max_delta_step=7, max_depth=1, min_child_weight=0, n_estimators=437, reg_alpha=0.011861829307728177, reg_lambda=0.009402886016022604, subsample=0.44695633591965944; total time=   4.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.6796464227418711, colsample_bytree=0.7056248443911882, gamma=1.7359479733508814e-09, learning_rate=0.025175585668082798, max_delta_step=9, max_depth=18, min_child_weight=3, n_estimators=314, reg_alpha=0.004692475696510866, reg_lambda=8.748565972013225e-05, subsample=0.6680010900211291; total time=  23.7s\n",
      "[CV] END colsample_bylevel=0.6796464227418711, colsample_bytree=0.7056248443911882, gamma=1.7359479733508814e-09, learning_rate=0.025175585668082798, max_delta_step=9, max_depth=18, min_child_weight=3, n_estimators=314, reg_alpha=0.004692475696510866, reg_lambda=8.748565972013225e-05, subsample=0.6680010900211291; total time=  23.5s\n",
      "[CV] END colsample_bylevel=0.6796464227418711, colsample_bytree=0.7056248443911882, gamma=1.7359479733508814e-09, learning_rate=0.025175585668082798, max_delta_step=9, max_depth=18, min_child_weight=3, n_estimators=314, reg_alpha=0.004692475696510866, reg_lambda=8.748565972013225e-05, subsample=0.6680010900211291; total time=  23.5s\n",
      "[CV] END colsample_bylevel=0.6796464227418711, colsample_bytree=0.7056248443911882, gamma=1.7359479733508814e-09, learning_rate=0.025175585668082798, max_delta_step=9, max_depth=18, min_child_weight=3, n_estimators=314, reg_alpha=0.004692475696510866, reg_lambda=8.748565972013225e-05, subsample=0.6680010900211291; total time=  26.3s\n",
      "[CV] END colsample_bylevel=0.6796464227418711, colsample_bytree=0.7056248443911882, gamma=1.7359479733508814e-09, learning_rate=0.025175585668082798, max_delta_step=9, max_depth=18, min_child_weight=3, n_estimators=314, reg_alpha=0.004692475696510866, reg_lambda=8.748565972013225e-05, subsample=0.6680010900211291; total time=  23.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.12750619091041093, gamma=6.384584642593411e-06, learning_rate=0.19196332719679948, max_delta_step=9, max_depth=49, min_child_weight=0, n_estimators=377, reg_alpha=1.9797251569087194e-09, reg_lambda=7.892286311862437e-05, subsample=0.12424487071388136; total time=   9.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.12750619091041093, gamma=6.384584642593411e-06, learning_rate=0.19196332719679948, max_delta_step=9, max_depth=49, min_child_weight=0, n_estimators=377, reg_alpha=1.9797251569087194e-09, reg_lambda=7.892286311862437e-05, subsample=0.12424487071388136; total time=   9.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.12750619091041093, gamma=6.384584642593411e-06, learning_rate=0.19196332719679948, max_delta_step=9, max_depth=49, min_child_weight=0, n_estimators=377, reg_alpha=1.9797251569087194e-09, reg_lambda=7.892286311862437e-05, subsample=0.12424487071388136; total time=   9.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.12750619091041093, gamma=6.384584642593411e-06, learning_rate=0.19196332719679948, max_delta_step=9, max_depth=49, min_child_weight=0, n_estimators=377, reg_alpha=1.9797251569087194e-09, reg_lambda=7.892286311862437e-05, subsample=0.12424487071388136; total time=   9.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.12750619091041093, gamma=6.384584642593411e-06, learning_rate=0.19196332719679948, max_delta_step=9, max_depth=49, min_child_weight=0, n_estimators=377, reg_alpha=1.9797251569087194e-09, reg_lambda=7.892286311862437e-05, subsample=0.12424487071388136; total time=   9.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.2332223220072433, colsample_bytree=0.65621558857183, gamma=6.80957660035464e-08, learning_rate=0.015844755820747715, max_delta_step=8, max_depth=43, min_child_weight=4, n_estimators=472, reg_alpha=1.2152042387230136e-07, reg_lambda=0.11711095801897622, subsample=0.7324711626843305; total time=  23.2s\n",
      "[CV] END colsample_bylevel=0.2332223220072433, colsample_bytree=0.65621558857183, gamma=6.80957660035464e-08, learning_rate=0.015844755820747715, max_delta_step=8, max_depth=43, min_child_weight=4, n_estimators=472, reg_alpha=1.2152042387230136e-07, reg_lambda=0.11711095801897622, subsample=0.7324711626843305; total time=  22.7s\n",
      "[CV] END colsample_bylevel=0.2332223220072433, colsample_bytree=0.65621558857183, gamma=6.80957660035464e-08, learning_rate=0.015844755820747715, max_delta_step=8, max_depth=43, min_child_weight=4, n_estimators=472, reg_alpha=1.2152042387230136e-07, reg_lambda=0.11711095801897622, subsample=0.7324711626843305; total time=  22.3s\n",
      "[CV] END colsample_bylevel=0.2332223220072433, colsample_bytree=0.65621558857183, gamma=6.80957660035464e-08, learning_rate=0.015844755820747715, max_delta_step=8, max_depth=43, min_child_weight=4, n_estimators=472, reg_alpha=1.2152042387230136e-07, reg_lambda=0.11711095801897622, subsample=0.7324711626843305; total time=  20.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.2332223220072433, colsample_bytree=0.65621558857183, gamma=6.80957660035464e-08, learning_rate=0.015844755820747715, max_delta_step=8, max_depth=43, min_child_weight=4, n_estimators=472, reg_alpha=1.2152042387230136e-07, reg_lambda=0.11711095801897622, subsample=0.7324711626843305; total time=  21.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.29113346264041245, colsample_bytree=0.14066637609620977, gamma=0.49999999999999994, learning_rate=0.3204638063753322, max_delta_step=10, max_depth=43, min_child_weight=3, n_estimators=281, reg_alpha=3.1802965566323563e-06, reg_lambda=0.0003023279272614854, subsample=0.21558648774661857; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.29113346264041245, colsample_bytree=0.14066637609620977, gamma=0.49999999999999994, learning_rate=0.3204638063753322, max_delta_step=10, max_depth=43, min_child_weight=3, n_estimators=281, reg_alpha=3.1802965566323563e-06, reg_lambda=0.0003023279272614854, subsample=0.21558648774661857; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.29113346264041245, colsample_bytree=0.14066637609620977, gamma=0.49999999999999994, learning_rate=0.3204638063753322, max_delta_step=10, max_depth=43, min_child_weight=3, n_estimators=281, reg_alpha=3.1802965566323563e-06, reg_lambda=0.0003023279272614854, subsample=0.21558648774661857; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.29113346264041245, colsample_bytree=0.14066637609620977, gamma=0.49999999999999994, learning_rate=0.3204638063753322, max_delta_step=10, max_depth=43, min_child_weight=3, n_estimators=281, reg_alpha=3.1802965566323563e-06, reg_lambda=0.0003023279272614854, subsample=0.21558648774661857; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.29113346264041245, colsample_bytree=0.14066637609620977, gamma=0.49999999999999994, learning_rate=0.3204638063753322, max_delta_step=10, max_depth=43, min_child_weight=3, n_estimators=281, reg_alpha=3.1802965566323563e-06, reg_lambda=0.0003023279272614854, subsample=0.21558648774661857; total time=   2.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.6013659592313689, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.6013659592313689, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.6013659592313689, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.6013659592313689, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.01, colsample_bytree=0.6013659592313689, gamma=1e-09, learning_rate=1.0, max_delta_step=10, max_depth=50, min_child_weight=0, n_estimators=500, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.01; total time=   5.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.34458092168261834, colsample_bytree=0.31289858042372054, gamma=0.0006803734811500277, learning_rate=0.07285976559647947, max_delta_step=10, max_depth=50, min_child_weight=3, n_estimators=290, reg_alpha=1e-09, reg_lambda=2.3558620822455896e-05, subsample=0.6355246578003555; total time=   8.3s\n",
      "[CV] END colsample_bylevel=0.34458092168261834, colsample_bytree=0.31289858042372054, gamma=0.0006803734811500277, learning_rate=0.07285976559647947, max_delta_step=10, max_depth=50, min_child_weight=3, n_estimators=290, reg_alpha=1e-09, reg_lambda=2.3558620822455896e-05, subsample=0.6355246578003555; total time=   8.6s\n",
      "[CV] END colsample_bylevel=0.34458092168261834, colsample_bytree=0.31289858042372054, gamma=0.0006803734811500277, learning_rate=0.07285976559647947, max_delta_step=10, max_depth=50, min_child_weight=3, n_estimators=290, reg_alpha=1e-09, reg_lambda=2.3558620822455896e-05, subsample=0.6355246578003555; total time=   8.5s\n",
      "[CV] END colsample_bylevel=0.34458092168261834, colsample_bytree=0.31289858042372054, gamma=0.0006803734811500277, learning_rate=0.07285976559647947, max_delta_step=10, max_depth=50, min_child_weight=3, n_estimators=290, reg_alpha=1e-09, reg_lambda=2.3558620822455896e-05, subsample=0.6355246578003555; total time=   8.8s\n",
      "[CV] END colsample_bylevel=0.34458092168261834, colsample_bytree=0.31289858042372054, gamma=0.0006803734811500277, learning_rate=0.07285976559647947, max_delta_step=10, max_depth=50, min_child_weight=3, n_estimators=290, reg_alpha=1e-09, reg_lambda=2.3558620822455896e-05, subsample=0.6355246578003555; total time=   8.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=0, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.01; total time=   0.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=0, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.01; total time=   0.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=0, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.01; total time=   0.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=0, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.01; total time=   0.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=1.0, gamma=0.49999999999999994, learning_rate=1.0, max_delta_step=0, max_depth=50, min_child_weight=0, n_estimators=5, reg_alpha=1e-09, reg_lambda=1000.0, subsample=0.01; total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.4109830295015158, colsample_bytree=0.18170934105312894, gamma=0.0564172488957227, learning_rate=0.12241581872027125, max_delta_step=10, max_depth=43, min_child_weight=2, n_estimators=322, reg_alpha=4.431966063215022e-06, reg_lambda=0.0007303668510461922, subsample=0.36825118119263495; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.4109830295015158, colsample_bytree=0.18170934105312894, gamma=0.0564172488957227, learning_rate=0.12241581872027125, max_delta_step=10, max_depth=43, min_child_weight=2, n_estimators=322, reg_alpha=4.431966063215022e-06, reg_lambda=0.0007303668510461922, subsample=0.36825118119263495; total time=   6.5s\n",
      "[CV] END colsample_bylevel=0.4109830295015158, colsample_bytree=0.18170934105312894, gamma=0.0564172488957227, learning_rate=0.12241581872027125, max_delta_step=10, max_depth=43, min_child_weight=2, n_estimators=322, reg_alpha=4.431966063215022e-06, reg_lambda=0.0007303668510461922, subsample=0.36825118119263495; total time=   6.8s\n",
      "[CV] END colsample_bylevel=0.4109830295015158, colsample_bytree=0.18170934105312894, gamma=0.0564172488957227, learning_rate=0.12241581872027125, max_delta_step=10, max_depth=43, min_child_weight=2, n_estimators=322, reg_alpha=4.431966063215022e-06, reg_lambda=0.0007303668510461922, subsample=0.36825118119263495; total time=   6.6s\n",
      "[CV] END colsample_bylevel=0.4109830295015158, colsample_bytree=0.18170934105312894, gamma=0.0564172488957227, learning_rate=0.12241581872027125, max_delta_step=10, max_depth=43, min_child_weight=2, n_estimators=322, reg_alpha=4.431966063215022e-06, reg_lambda=0.0007303668510461922, subsample=0.36825118119263495; total time=   6.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.13712306629904703, colsample_bytree=0.855180398967242, gamma=1e-09, learning_rate=0.6923238298643144, max_delta_step=10, max_depth=1, min_child_weight=4, n_estimators=56, reg_alpha=3.203341394424593e-05, reg_lambda=6.53786102668518, subsample=0.3245471774387745; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.13712306629904703, colsample_bytree=0.855180398967242, gamma=1e-09, learning_rate=0.6923238298643144, max_delta_step=10, max_depth=1, min_child_weight=4, n_estimators=56, reg_alpha=3.203341394424593e-05, reg_lambda=6.53786102668518, subsample=0.3245471774387745; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.13712306629904703, colsample_bytree=0.855180398967242, gamma=1e-09, learning_rate=0.6923238298643144, max_delta_step=10, max_depth=1, min_child_weight=4, n_estimators=56, reg_alpha=3.203341394424593e-05, reg_lambda=6.53786102668518, subsample=0.3245471774387745; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.13712306629904703, colsample_bytree=0.855180398967242, gamma=1e-09, learning_rate=0.6923238298643144, max_delta_step=10, max_depth=1, min_child_weight=4, n_estimators=56, reg_alpha=3.203341394424593e-05, reg_lambda=6.53786102668518, subsample=0.3245471774387745; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.13712306629904703, colsample_bytree=0.855180398967242, gamma=1e-09, learning_rate=0.6923238298643144, max_delta_step=10, max_depth=1, min_child_weight=4, n_estimators=56, reg_alpha=3.203341394424593e-05, reg_lambda=6.53786102668518, subsample=0.3245471774387745; total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.18477159306220742, colsample_bytree=0.5816024326306483, gamma=1e-09, learning_rate=0.028584211539781253, max_delta_step=10, max_depth=42, min_child_weight=4, n_estimators=500, reg_alpha=1.0854642339777363e-05, reg_lambda=0.003478422459886342, subsample=0.7741804453535521; total time=  19.5s\n",
      "[CV] END colsample_bylevel=0.18477159306220742, colsample_bytree=0.5816024326306483, gamma=1e-09, learning_rate=0.028584211539781253, max_delta_step=10, max_depth=42, min_child_weight=4, n_estimators=500, reg_alpha=1.0854642339777363e-05, reg_lambda=0.003478422459886342, subsample=0.7741804453535521; total time=  19.3s\n",
      "[CV] END colsample_bylevel=0.18477159306220742, colsample_bytree=0.5816024326306483, gamma=1e-09, learning_rate=0.028584211539781253, max_delta_step=10, max_depth=42, min_child_weight=4, n_estimators=500, reg_alpha=1.0854642339777363e-05, reg_lambda=0.003478422459886342, subsample=0.7741804453535521; total time=  18.8s\n",
      "[CV] END colsample_bylevel=0.18477159306220742, colsample_bytree=0.5816024326306483, gamma=1e-09, learning_rate=0.028584211539781253, max_delta_step=10, max_depth=42, min_child_weight=4, n_estimators=500, reg_alpha=1.0854642339777363e-05, reg_lambda=0.003478422459886342, subsample=0.7741804453535521; total time=  18.5s\n",
      "[CV] END colsample_bylevel=0.18477159306220742, colsample_bytree=0.5816024326306483, gamma=1e-09, learning_rate=0.028584211539781253, max_delta_step=10, max_depth=42, min_child_weight=4, n_estimators=500, reg_alpha=1.0854642339777363e-05, reg_lambda=0.003478422459886342, subsample=0.7741804453535521; total time=  18.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.3919631430976366, colsample_bytree=0.0568229059044059, gamma=0.0020086617299530326, learning_rate=0.3921887269028225, max_delta_step=10, max_depth=36, min_child_weight=3, n_estimators=399, reg_alpha=0.006079820595098494, reg_lambda=0.0003819770584321892, subsample=0.7630943569625558; total time=   4.2s\n",
      "[CV] END colsample_bylevel=0.3919631430976366, colsample_bytree=0.0568229059044059, gamma=0.0020086617299530326, learning_rate=0.3921887269028225, max_delta_step=10, max_depth=36, min_child_weight=3, n_estimators=399, reg_alpha=0.006079820595098494, reg_lambda=0.0003819770584321892, subsample=0.7630943569625558; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.3919631430976366, colsample_bytree=0.0568229059044059, gamma=0.0020086617299530326, learning_rate=0.3921887269028225, max_delta_step=10, max_depth=36, min_child_weight=3, n_estimators=399, reg_alpha=0.006079820595098494, reg_lambda=0.0003819770584321892, subsample=0.7630943569625558; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.3919631430976366, colsample_bytree=0.0568229059044059, gamma=0.0020086617299530326, learning_rate=0.3921887269028225, max_delta_step=10, max_depth=36, min_child_weight=3, n_estimators=399, reg_alpha=0.006079820595098494, reg_lambda=0.0003819770584321892, subsample=0.7630943569625558; total time=   4.4s\n",
      "[CV] END colsample_bylevel=0.3919631430976366, colsample_bytree=0.0568229059044059, gamma=0.0020086617299530326, learning_rate=0.3921887269028225, max_delta_step=10, max_depth=36, min_child_weight=3, n_estimators=399, reg_alpha=0.006079820595098494, reg_lambda=0.0003819770584321892, subsample=0.7630943569625558; total time=   4.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.6887899218483838, colsample_bytree=0.36736636475387713, gamma=9.238145480993536e-06, learning_rate=0.32425104787182263, max_delta_step=10, max_depth=1, min_child_weight=1, n_estimators=53, reg_alpha=0.12333785787761536, reg_lambda=1e-09, subsample=0.35465868438772064; total time=   0.5s\n",
      "[CV] END colsample_bylevel=0.6887899218483838, colsample_bytree=0.36736636475387713, gamma=9.238145480993536e-06, learning_rate=0.32425104787182263, max_delta_step=10, max_depth=1, min_child_weight=1, n_estimators=53, reg_alpha=0.12333785787761536, reg_lambda=1e-09, subsample=0.35465868438772064; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.6887899218483838, colsample_bytree=0.36736636475387713, gamma=9.238145480993536e-06, learning_rate=0.32425104787182263, max_delta_step=10, max_depth=1, min_child_weight=1, n_estimators=53, reg_alpha=0.12333785787761536, reg_lambda=1e-09, subsample=0.35465868438772064; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.6887899218483838, colsample_bytree=0.36736636475387713, gamma=9.238145480993536e-06, learning_rate=0.32425104787182263, max_delta_step=10, max_depth=1, min_child_weight=1, n_estimators=53, reg_alpha=0.12333785787761536, reg_lambda=1e-09, subsample=0.35465868438772064; total time=   0.6s\n",
      "[CV] END colsample_bylevel=0.6887899218483838, colsample_bytree=0.36736636475387713, gamma=9.238145480993536e-06, learning_rate=0.32425104787182263, max_delta_step=10, max_depth=1, min_child_weight=1, n_estimators=53, reg_alpha=0.12333785787761536, reg_lambda=1e-09, subsample=0.35465868438772064; total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.32982944506377093, colsample_bytree=0.4059088310353996, gamma=0.0008542039653266948, learning_rate=0.0887657594662025, max_delta_step=10, max_depth=47, min_child_weight=3, n_estimators=272, reg_alpha=1.4677585455191624e-08, reg_lambda=0.0006133568338366972, subsample=0.574726373249033; total time=  10.6s\n",
      "[CV] END colsample_bylevel=0.32982944506377093, colsample_bytree=0.4059088310353996, gamma=0.0008542039653266948, learning_rate=0.0887657594662025, max_delta_step=10, max_depth=47, min_child_weight=3, n_estimators=272, reg_alpha=1.4677585455191624e-08, reg_lambda=0.0006133568338366972, subsample=0.574726373249033; total time=  11.0s\n",
      "[CV] END colsample_bylevel=0.32982944506377093, colsample_bytree=0.4059088310353996, gamma=0.0008542039653266948, learning_rate=0.0887657594662025, max_delta_step=10, max_depth=47, min_child_weight=3, n_estimators=272, reg_alpha=1.4677585455191624e-08, reg_lambda=0.0006133568338366972, subsample=0.574726373249033; total time=  10.8s\n",
      "[CV] END colsample_bylevel=0.32982944506377093, colsample_bytree=0.4059088310353996, gamma=0.0008542039653266948, learning_rate=0.0887657594662025, max_delta_step=10, max_depth=47, min_child_weight=3, n_estimators=272, reg_alpha=1.4677585455191624e-08, reg_lambda=0.0006133568338366972, subsample=0.574726373249033; total time=  10.8s\n",
      "[CV] END colsample_bylevel=0.32982944506377093, colsample_bytree=0.4059088310353996, gamma=0.0008542039653266948, learning_rate=0.0887657594662025, max_delta_step=10, max_depth=47, min_child_weight=3, n_estimators=272, reg_alpha=1.4677585455191624e-08, reg_lambda=0.0006133568338366972, subsample=0.574726373249033; total time=  11.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.4610086076566963, colsample_bytree=0.44452492623210915, gamma=1e-09, learning_rate=0.6315395690231445, max_delta_step=5, max_depth=1, min_child_weight=3, n_estimators=15, reg_alpha=0.0013137377619636507, reg_lambda=1e-09, subsample=1.0; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.4610086076566963, colsample_bytree=0.44452492623210915, gamma=1e-09, learning_rate=0.6315395690231445, max_delta_step=5, max_depth=1, min_child_weight=3, n_estimators=15, reg_alpha=0.0013137377619636507, reg_lambda=1e-09, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bylevel=0.4610086076566963, colsample_bytree=0.44452492623210915, gamma=1e-09, learning_rate=0.6315395690231445, max_delta_step=5, max_depth=1, min_child_weight=3, n_estimators=15, reg_alpha=0.0013137377619636507, reg_lambda=1e-09, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bylevel=0.4610086076566963, colsample_bytree=0.44452492623210915, gamma=1e-09, learning_rate=0.6315395690231445, max_delta_step=5, max_depth=1, min_child_weight=3, n_estimators=15, reg_alpha=0.0013137377619636507, reg_lambda=1e-09, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bylevel=0.4610086076566963, colsample_bytree=0.44452492623210915, gamma=1e-09, learning_rate=0.6315395690231445, max_delta_step=5, max_depth=1, min_child_weight=3, n_estimators=15, reg_alpha=0.0013137377619636507, reg_lambda=1e-09, subsample=1.0; total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.312480580811792, colsample_bytree=0.9102273499973489, gamma=2.2066299439952857e-08, learning_rate=0.027762051448647195, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=331, reg_alpha=9.599943003446333e-06, reg_lambda=0.0003544640795182278, subsample=0.01; total time=   5.1s\n",
      "[CV] END colsample_bylevel=0.312480580811792, colsample_bytree=0.9102273499973489, gamma=2.2066299439952857e-08, learning_rate=0.027762051448647195, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=331, reg_alpha=9.599943003446333e-06, reg_lambda=0.0003544640795182278, subsample=0.01; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.312480580811792, colsample_bytree=0.9102273499973489, gamma=2.2066299439952857e-08, learning_rate=0.027762051448647195, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=331, reg_alpha=9.599943003446333e-06, reg_lambda=0.0003544640795182278, subsample=0.01; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.312480580811792, colsample_bytree=0.9102273499973489, gamma=2.2066299439952857e-08, learning_rate=0.027762051448647195, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=331, reg_alpha=9.599943003446333e-06, reg_lambda=0.0003544640795182278, subsample=0.01; total time=   5.2s\n",
      "[CV] END colsample_bylevel=0.312480580811792, colsample_bytree=0.9102273499973489, gamma=2.2066299439952857e-08, learning_rate=0.027762051448647195, max_delta_step=10, max_depth=19, min_child_weight=2, n_estimators=331, reg_alpha=9.599943003446333e-06, reg_lambda=0.0003544640795182278, subsample=0.01; total time=   5.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.9562265795244695, colsample_bytree=0.06469558253410645, gamma=0.0012366448018352675, learning_rate=1.0, max_delta_step=10, max_depth=27, min_child_weight=2, n_estimators=131, reg_alpha=2.7808291813651987e-05, reg_lambda=0.11295030040315246, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bylevel=0.9562265795244695, colsample_bytree=0.06469558253410645, gamma=0.0012366448018352675, learning_rate=1.0, max_delta_step=10, max_depth=27, min_child_weight=2, n_estimators=131, reg_alpha=2.7808291813651987e-05, reg_lambda=0.11295030040315246, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.9562265795244695, colsample_bytree=0.06469558253410645, gamma=0.0012366448018352675, learning_rate=1.0, max_delta_step=10, max_depth=27, min_child_weight=2, n_estimators=131, reg_alpha=2.7808291813651987e-05, reg_lambda=0.11295030040315246, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.9562265795244695, colsample_bytree=0.06469558253410645, gamma=0.0012366448018352675, learning_rate=1.0, max_delta_step=10, max_depth=27, min_child_weight=2, n_estimators=131, reg_alpha=2.7808291813651987e-05, reg_lambda=0.11295030040315246, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bylevel=0.9562265795244695, colsample_bytree=0.06469558253410645, gamma=0.0012366448018352675, learning_rate=1.0, max_delta_step=10, max_depth=27, min_child_weight=2, n_estimators=131, reg_alpha=2.7808291813651987e-05, reg_lambda=0.11295030040315246, subsample=1.0; total time=   1.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.9389594672770689, gamma=1e-09, learning_rate=0.02244680952861409, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=500, reg_alpha=0.00040855509310934424, reg_lambda=1e-09, subsample=0.7921690232254716; total time=  34.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.9389594672770689, gamma=1e-09, learning_rate=0.02244680952861409, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=500, reg_alpha=0.00040855509310934424, reg_lambda=1e-09, subsample=0.7921690232254716; total time=  33.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.9389594672770689, gamma=1e-09, learning_rate=0.02244680952861409, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=500, reg_alpha=0.00040855509310934424, reg_lambda=1e-09, subsample=0.7921690232254716; total time=  36.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.9389594672770689, gamma=1e-09, learning_rate=0.02244680952861409, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=500, reg_alpha=0.00040855509310934424, reg_lambda=1e-09, subsample=0.7921690232254716; total time=  34.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.9389594672770689, gamma=1e-09, learning_rate=0.02244680952861409, max_delta_step=0, max_depth=11, min_child_weight=5, n_estimators=500, reg_alpha=0.00040855509310934424, reg_lambda=1e-09, subsample=0.7921690232254716; total time=  34.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.2367654915582706, colsample_bytree=1.0, gamma=2.2942940403202923e-09, learning_rate=1.0, max_delta_step=10, max_depth=33, min_child_weight=0, n_estimators=138, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time=  10.1s\n",
      "[CV] END colsample_bylevel=0.2367654915582706, colsample_bytree=1.0, gamma=2.2942940403202923e-09, learning_rate=1.0, max_delta_step=10, max_depth=33, min_child_weight=0, n_estimators=138, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time=  10.2s\n",
      "[CV] END colsample_bylevel=0.2367654915582706, colsample_bytree=1.0, gamma=2.2942940403202923e-09, learning_rate=1.0, max_delta_step=10, max_depth=33, min_child_weight=0, n_estimators=138, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time=  11.4s\n",
      "[CV] END colsample_bylevel=0.2367654915582706, colsample_bytree=1.0, gamma=2.2942940403202923e-09, learning_rate=1.0, max_delta_step=10, max_depth=33, min_child_weight=0, n_estimators=138, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time=  15.8s\n",
      "[CV] END colsample_bylevel=0.2367654915582706, colsample_bytree=1.0, gamma=2.2942940403202923e-09, learning_rate=1.0, max_delta_step=10, max_depth=33, min_child_weight=0, n_estimators=138, reg_alpha=1.0, reg_lambda=1000.0, subsample=1.0; total time=  14.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.5416500725960512, colsample_bytree=0.27439031593340935, gamma=0.0020244954663995113, learning_rate=0.0714067705292769, max_delta_step=7, max_depth=50, min_child_weight=4, n_estimators=239, reg_alpha=2.514858034931483e-07, reg_lambda=1e-09, subsample=0.9630723172770822; total time=  11.4s\n",
      "[CV] END colsample_bylevel=0.5416500725960512, colsample_bytree=0.27439031593340935, gamma=0.0020244954663995113, learning_rate=0.0714067705292769, max_delta_step=7, max_depth=50, min_child_weight=4, n_estimators=239, reg_alpha=2.514858034931483e-07, reg_lambda=1e-09, subsample=0.9630723172770822; total time=  12.0s\n",
      "[CV] END colsample_bylevel=0.5416500725960512, colsample_bytree=0.27439031593340935, gamma=0.0020244954663995113, learning_rate=0.0714067705292769, max_delta_step=7, max_depth=50, min_child_weight=4, n_estimators=239, reg_alpha=2.514858034931483e-07, reg_lambda=1e-09, subsample=0.9630723172770822; total time=  10.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.5416500725960512, colsample_bytree=0.27439031593340935, gamma=0.0020244954663995113, learning_rate=0.0714067705292769, max_delta_step=7, max_depth=50, min_child_weight=4, n_estimators=239, reg_alpha=2.514858034931483e-07, reg_lambda=1e-09, subsample=0.9630723172770822; total time=  11.5s\n",
      "[CV] END colsample_bylevel=0.5416500725960512, colsample_bytree=0.27439031593340935, gamma=0.0020244954663995113, learning_rate=0.0714067705292769, max_delta_step=7, max_depth=50, min_child_weight=4, n_estimators=239, reg_alpha=2.514858034931483e-07, reg_lambda=1e-09, subsample=0.9630723172770822; total time=  13.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.6523850622650216, colsample_bytree=0.7569127871938385, gamma=2.7165845609611862e-08, learning_rate=0.022063776232491943, max_delta_step=6, max_depth=16, min_child_weight=1, n_estimators=264, reg_alpha=1.0, reg_lambda=0.005343774674720804, subsample=1.0; total time=  25.5s\n",
      "[CV] END colsample_bylevel=0.6523850622650216, colsample_bytree=0.7569127871938385, gamma=2.7165845609611862e-08, learning_rate=0.022063776232491943, max_delta_step=6, max_depth=16, min_child_weight=1, n_estimators=264, reg_alpha=1.0, reg_lambda=0.005343774674720804, subsample=1.0; total time=  24.9s\n",
      "[CV] END colsample_bylevel=0.6523850622650216, colsample_bytree=0.7569127871938385, gamma=2.7165845609611862e-08, learning_rate=0.022063776232491943, max_delta_step=6, max_depth=16, min_child_weight=1, n_estimators=264, reg_alpha=1.0, reg_lambda=0.005343774674720804, subsample=1.0; total time=  25.3s\n",
      "[CV] END colsample_bylevel=0.6523850622650216, colsample_bytree=0.7569127871938385, gamma=2.7165845609611862e-08, learning_rate=0.022063776232491943, max_delta_step=6, max_depth=16, min_child_weight=1, n_estimators=264, reg_alpha=1.0, reg_lambda=0.005343774674720804, subsample=1.0; total time=  25.1s\n",
      "[CV] END colsample_bylevel=0.6523850622650216, colsample_bytree=0.7569127871938385, gamma=2.7165845609611862e-08, learning_rate=0.022063776232491943, max_delta_step=6, max_depth=16, min_child_weight=1, n_estimators=264, reg_alpha=1.0, reg_lambda=0.005343774674720804, subsample=1.0; total time=  24.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.3756051864516059, colsample_bytree=0.4213156417827247, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=2, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1.8888401757290463e-07, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bylevel=0.3756051864516059, colsample_bytree=0.4213156417827247, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=2, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1.8888401757290463e-07, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.3756051864516059, colsample_bytree=0.4213156417827247, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=2, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1.8888401757290463e-07, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bylevel=0.3756051864516059, colsample_bytree=0.4213156417827247, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=2, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1.8888401757290463e-07, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bylevel=0.3756051864516059, colsample_bytree=0.4213156417827247, gamma=1e-09, learning_rate=0.01, max_delta_step=2, max_depth=2, min_child_weight=5, n_estimators=500, reg_alpha=1.0, reg_lambda=1.8888401757290463e-07, subsample=1.0; total time=   4.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.41078020139523314, colsample_bytree=0.5580257381137479, gamma=5.002649082465619e-06, learning_rate=0.025729030604246514, max_delta_step=5, max_depth=12, min_child_weight=4, n_estimators=240, reg_alpha=2.6424663241978346e-05, reg_lambda=3.995717615115839e-05, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bylevel=0.41078020139523314, colsample_bytree=0.5580257381137479, gamma=5.002649082465619e-06, learning_rate=0.025729030604246514, max_delta_step=5, max_depth=12, min_child_weight=4, n_estimators=240, reg_alpha=2.6424663241978346e-05, reg_lambda=3.995717615115839e-05, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bylevel=0.41078020139523314, colsample_bytree=0.5580257381137479, gamma=5.002649082465619e-06, learning_rate=0.025729030604246514, max_delta_step=5, max_depth=12, min_child_weight=4, n_estimators=240, reg_alpha=2.6424663241978346e-05, reg_lambda=3.995717615115839e-05, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bylevel=0.41078020139523314, colsample_bytree=0.5580257381137479, gamma=5.002649082465619e-06, learning_rate=0.025729030604246514, max_delta_step=5, max_depth=12, min_child_weight=4, n_estimators=240, reg_alpha=2.6424663241978346e-05, reg_lambda=3.995717615115839e-05, subsample=1.0; total time=   8.9s\n",
      "[CV] END colsample_bylevel=0.41078020139523314, colsample_bytree=0.5580257381137479, gamma=5.002649082465619e-06, learning_rate=0.025729030604246514, max_delta_step=5, max_depth=12, min_child_weight=4, n_estimators=240, reg_alpha=2.6424663241978346e-05, reg_lambda=3.995717615115839e-05, subsample=1.0; total time=   8.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.15105858998043806, colsample_bytree=0.730360728128112, gamma=1.7486867281548325e-07, learning_rate=0.02822569974015645, max_delta_step=10, max_depth=34, min_child_weight=5, n_estimators=500, reg_alpha=4.998998970891211e-05, reg_lambda=19.647236005360007, subsample=1.0; total time=  18.3s\n",
      "[CV] END colsample_bylevel=0.15105858998043806, colsample_bytree=0.730360728128112, gamma=1.7486867281548325e-07, learning_rate=0.02822569974015645, max_delta_step=10, max_depth=34, min_child_weight=5, n_estimators=500, reg_alpha=4.998998970891211e-05, reg_lambda=19.647236005360007, subsample=1.0; total time=  17.2s\n",
      "[CV] END colsample_bylevel=0.15105858998043806, colsample_bytree=0.730360728128112, gamma=1.7486867281548325e-07, learning_rate=0.02822569974015645, max_delta_step=10, max_depth=34, min_child_weight=5, n_estimators=500, reg_alpha=4.998998970891211e-05, reg_lambda=19.647236005360007, subsample=1.0; total time=  17.7s\n",
      "[CV] END colsample_bylevel=0.15105858998043806, colsample_bytree=0.730360728128112, gamma=1.7486867281548325e-07, learning_rate=0.02822569974015645, max_delta_step=10, max_depth=34, min_child_weight=5, n_estimators=500, reg_alpha=4.998998970891211e-05, reg_lambda=19.647236005360007, subsample=1.0; total time=  23.1s\n",
      "[CV] END colsample_bylevel=0.15105858998043806, colsample_bytree=0.730360728128112, gamma=1.7486867281548325e-07, learning_rate=0.02822569974015645, max_delta_step=10, max_depth=34, min_child_weight=5, n_estimators=500, reg_alpha=4.998998970891211e-05, reg_lambda=19.647236005360007, subsample=1.0; total time=  23.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.1182504204508359, colsample_bytree=0.175516005489433, gamma=7.22985006260551e-05, learning_rate=0.15436588974181706, max_delta_step=0, max_depth=48, min_child_weight=5, n_estimators=500, reg_alpha=0.4127962776702092, reg_lambda=0.40309630539778857, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.1182504204508359, colsample_bytree=0.175516005489433, gamma=7.22985006260551e-05, learning_rate=0.15436588974181706, max_delta_step=0, max_depth=48, min_child_weight=5, n_estimators=500, reg_alpha=0.4127962776702092, reg_lambda=0.40309630539778857, subsample=1.0; total time=   5.7s\n",
      "[CV] END colsample_bylevel=0.1182504204508359, colsample_bytree=0.175516005489433, gamma=7.22985006260551e-05, learning_rate=0.15436588974181706, max_delta_step=0, max_depth=48, min_child_weight=5, n_estimators=500, reg_alpha=0.4127962776702092, reg_lambda=0.40309630539778857, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bylevel=0.1182504204508359, colsample_bytree=0.175516005489433, gamma=7.22985006260551e-05, learning_rate=0.15436588974181706, max_delta_step=0, max_depth=48, min_child_weight=5, n_estimators=500, reg_alpha=0.4127962776702092, reg_lambda=0.40309630539778857, subsample=1.0; total time=   5.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.1182504204508359, colsample_bytree=0.175516005489433, gamma=7.22985006260551e-05, learning_rate=0.15436588974181706, max_delta_step=0, max_depth=48, min_child_weight=5, n_estimators=500, reg_alpha=0.4127962776702092, reg_lambda=0.40309630539778857, subsample=1.0; total time=   4.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=4.0708607705278865e-09, learning_rate=1.0, max_delta_step=8, max_depth=1, min_child_weight=0, n_estimators=239, reg_alpha=1.0, reg_lambda=0.0035104941105105537, subsample=0.4591359337398839; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=4.0708607705278865e-09, learning_rate=1.0, max_delta_step=8, max_depth=1, min_child_weight=0, n_estimators=239, reg_alpha=1.0, reg_lambda=0.0035104941105105537, subsample=0.4591359337398839; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=4.0708607705278865e-09, learning_rate=1.0, max_delta_step=8, max_depth=1, min_child_weight=0, n_estimators=239, reg_alpha=1.0, reg_lambda=0.0035104941105105537, subsample=0.4591359337398839; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=4.0708607705278865e-09, learning_rate=1.0, max_delta_step=8, max_depth=1, min_child_weight=0, n_estimators=239, reg_alpha=1.0, reg_lambda=0.0035104941105105537, subsample=0.4591359337398839; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bytree=0.01, gamma=4.0708607705278865e-09, learning_rate=1.0, max_delta_step=8, max_depth=1, min_child_weight=0, n_estimators=239, reg_alpha=1.0, reg_lambda=0.0035104941105105537, subsample=0.4591359337398839; total time=   2.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END colsample_bylevel=0.22890676299408935, colsample_bytree=0.5735438998463577, gamma=2.957584661945408e-07, learning_rate=0.015870050008859493, max_delta_step=8, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.819683006046077e-06, reg_lambda=0.030194689870354178, subsample=1.0; total time=  28.8s\n",
      "[CV] END colsample_bylevel=0.22890676299408935, colsample_bytree=0.5735438998463577, gamma=2.957584661945408e-07, learning_rate=0.015870050008859493, max_delta_step=8, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.819683006046077e-06, reg_lambda=0.030194689870354178, subsample=1.0; total time=  22.9s\n",
      "[CV] END colsample_bylevel=0.22890676299408935, colsample_bytree=0.5735438998463577, gamma=2.957584661945408e-07, learning_rate=0.015870050008859493, max_delta_step=8, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.819683006046077e-06, reg_lambda=0.030194689870354178, subsample=1.0; total time=  24.7s\n",
      "[CV] END colsample_bylevel=0.22890676299408935, colsample_bytree=0.5735438998463577, gamma=2.957584661945408e-07, learning_rate=0.015870050008859493, max_delta_step=8, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.819683006046077e-06, reg_lambda=0.030194689870354178, subsample=1.0; total time=  22.5s\n",
      "[CV] END colsample_bylevel=0.22890676299408935, colsample_bytree=0.5735438998463577, gamma=2.957584661945408e-07, learning_rate=0.015870050008859493, max_delta_step=8, max_depth=50, min_child_weight=5, n_estimators=500, reg_alpha=5.819683006046077e-06, reg_lambda=0.030194689870354178, subsample=1.0; total time=  23.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "              estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                      colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None,\n",
       "                                      enable_categorical=False,\n",
       "                                      eval_metric='error', gamma=None,\n",
       "                                      gpu_id=None, importance_type=None,\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=None, max_delta_step=None...\n",
       "                             'min_child_weight': Integer(low=0, high=5, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=5, high=500, prior='uniform', transform='normalize'),\n",
       "                             'reg_alpha': Real(low=1e-09, high=1.0, prior='log-uniform', transform='normalize'),\n",
       "                             'reg_lambda': Real(low=1e-09, high=1000, prior='log-uniform', transform='normalize'),\n",
       "                             'subsample': Real(low=0.01, high=1.0, prior='uniform', transform='normalize')},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_grid = { # 75 fits of 5 fold cv, takes around 1 1/2 hours\n",
    "    \"learning_rate\": Real(0.01, 1.0, \"log-uniform\"),\n",
    "    \"min_child_weight\": Integer(0, 10),\n",
    "    \"max_depth\": Integer(1, 50),\n",
    "    \"max_delta_step\": Integer(0, 10),\n",
    "    \"subsample\": Real(0.01, 1.0, \"uniform\"),\n",
    "    \"colsample_bytree\": Real(0.01, 1.0, \"log-uniform\"),\n",
    "    \"colsample_bylevel\": Real(0.01, 1.0, \"log-uniform\"),\n",
    "    \"reg_lambda\": Real(1e-9, 1000, \"log-uniform\"),\n",
    "    \"reg_alpha\": Real(1e-9, 1.0, \"log-uniform\"),\n",
    "    \"gamma\": Real(1e-9, 0.5, \"log-uniform\"),\n",
    "    \"min_child_weight\": Integer(0, 5),\n",
    "    \"n_estimators\": Integer(5, 500),\n",
    "}\n",
    "xgb = XGBClassifier(eval_metric='error')\n",
    "#define a stratified cross validation\n",
    "cv_stratified = StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "xgb_bayes = BayesSearchCV(xgb,search_spaces=bayes_grid, cv=cv_stratified, scoring ='f1_macro', refit = True,n_iter=75, random_state = 42,verbose=2)\n",
    "xgb_bayes.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8742\n",
      "The F1-Score on the validation set: 0.8163\n",
      "Confusion Matrix : \n",
      "[[5610  335]\n",
      " [ 648 1222]]\n",
      "The best model has the following hyperparameter:XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1, colsample_bytree=0.9389594672770689,\n",
      "              enable_categorical=False, eval_metric='error', gamma=1e-09,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.02244680952861409, max_delta_step=0, max_depth=11,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=500, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "              random_state=0, reg_alpha=0.00040855509310934424,\n",
      "              reg_lambda=1e-09, scale_pos_weight=1,\n",
      "              subsample=0.7921690232254716, tree_method='exact',\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "#check the results for bayesian optimization\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, xgb_bayes.best_estimator_)\n",
    "print(f'The best model has the following hyperparameter:{xgb_bayes.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make use of the results of the bayesian optimization to narrow down the search space in our grid. Unfortunately, it seems that the results of the 75 samples we used, did not improve our default settings. So, we investigate the range around the default settings of XGBoost for possible further improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   8.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   6.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   7.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   7.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   3.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=6, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.7s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=0.9; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=0.9; total time=   5.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=0.5, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=0.9; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.9s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.9; total time=   4.8s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.4, max_depth=7, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   4.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='error', gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,...\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.9, 1.0], 'gamma': [0, 0.1],\n",
       "                         'learning_rate': [0.2, 0.3, 0.4],\n",
       "                         'max_depth': [5, 6, 7], 'min_child_weight': [0.5, 1],\n",
       "                         'n_estimators': [50, 100], 'subsample': [0.9, 1.0]},\n",
       "             scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid = { #1440 fits -> takes about (start 10:30 until 11:45)\n",
    "        'n_estimators': [50,100],\n",
    "        'gamma': [0,0.1],\n",
    "        'max_depth': [5,6,7],\n",
    "        'min_child_weight': [0.5,1],\n",
    "        'subsample': [0.9,1.0],\n",
    "        'colsample_bytree': [0.9,1.0],\n",
    "        'learning_rate': [0.2,0.3,0.4]\n",
    "        }\n",
    "xgb = XGBClassifier(eval_metric='error')\n",
    "#define a stratified cross validation\n",
    "cv_stratified = StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "# Random search of parameters, using 5 fold cross validation\n",
    "xgb_random = GridSearchCV(xgb, random_grid, cv=cv_stratified, scoring ='f1_macro', verbose=2, refit=True)\n",
    "# Fit the random search model\n",
    "xgb_random.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8755\n",
      "The F1-Score on the validation set: 0.8184\n",
      "Confusion Matrix : \n",
      "[[5612  333]\n",
      " [ 640 1230]]\n",
      "The best model has the following hyperparameter:XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.9,\n",
      "              enable_categorical=False, eval_metric='error', gamma=0, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              subsample=1.0, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "#check the results for the grid search optimization\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, xgb_random.best_estimator_)\n",
    "print(f'The best model has the following hyperparameter:{xgb_random.best_estimator_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   7.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   6.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   5.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   5.0s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bylevel=0.9, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   4.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=0.9, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   2.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   4.0s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.8, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.5s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=4, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=150, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=100, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=0.9, gamma=0, learning_rate=0.3, max_depth=5, min_child_weight=2, n_estimators=150, subsample=1.0; total time=   3.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='error', gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,...\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'colsample_bylevel': [0.9, 1.0],\n",
       "                         'colsample_bynode': [0.9, 1.0],\n",
       "                         'colsample_bytree': [0.8, 0.9], 'gamma': [0],\n",
       "                         'learning_rate': [0.3], 'max_depth': [4, 5],\n",
       "                         'min_child_weight': [1, 2], 'n_estimators': [100, 150],\n",
       "                         'subsample': [1.0]},\n",
       "             scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid = { #320 fits -> takes about 20-30 minutes\n",
    "        'n_estimators': [100,150],\n",
    "        'gamma': [0],\n",
    "        'max_depth': [4,5],\n",
    "        'min_child_weight': [1,2],\n",
    "        'subsample': [1.0],\n",
    "        'colsample_bytree': [0.8, 0.9],\n",
    "        'learning_rate': [0.3],\n",
    "        'colsample_bylevel':[0.9,1.0],\n",
    "        'colsample_bynode':[0.9,1.0]\n",
    "        }\n",
    "xgb = XGBClassifier(eval_metric='error')\n",
    "#define a stratified cross validation\n",
    "cv_stratified = StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "# Random search of parameters, using 5 fold cross validation\n",
    "xgb_random = GridSearchCV(xgb, random_grid, cv=cv_stratified, scoring ='f1_macro', verbose=2, refit=True)\n",
    "# Fit the random search model\n",
    "xgb_random.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the validation set: 0.8773\n",
      "The F1-Score on the validation set: 0.8222\n",
      "Confusion Matrix : \n",
      "[[5603  342]\n",
      " [ 617 1253]]\n",
      "The best model has the following hyperparameter:XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "              colsample_bynode=1.0, colsample_bytree=0.9,\n",
      "              enable_categorical=False, eval_metric='error', gamma=0, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=150, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              subsample=1.0, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "#check the results for the grid search optimization\n",
    "dt,prediction = model_training(data_train, target_train, data_val, target_val, xgb_random.best_estimator_)\n",
    "print(f'The best model has the following hyperparameter:{xgb_random.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After two iterations of refinement for our grid, results show an improvement of 0.07 percentage points from 0.8765 to 0.8773 in accuracy and 0.8215 to 0.8222 in the f1-score. With further parameter refinements it should be possible to increase this improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Test Set and Mistake Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gonna use the results of our hyperparameter optimization with train+val as training data and evaluate how good the model generalizes on the test set and dive into the failures of our model and understand what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.concat([data_train, data_val], axis=0)\n",
    "train_val_target = pd.concat([target_train, target_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
    "              colsample_bynode=1.0, colsample_bytree=0.9,\n",
    "              enable_categorical=False, eval_metric='error', gamma=0, gpu_id=-1,\n",
    "              importance_type=None, interaction_constraints='',\n",
    "              learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1,  monotone_constraints='()',\n",
    "              n_estimators=150, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
    "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "              subsample=1.0, tree_method='exact', validate_parameters=1,\n",
    "              verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy on the test set: 0.8790\n",
      "The F1-Score on the test set: 0.8238\n",
      "Confusion Matrix : \n",
      "[[7027  404]\n",
      " [ 778 1560]]\n"
     ]
    }
   ],
   "source": [
    "#check final results on test set\n",
    "dt,prediction = model_training(train_val, train_val_target, data_test, target_test, xgb_best,test =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a good generalization, as we have nearly the same results as on the validation set. Therefore, we can conclude that approach is able to handle unknown data really well with an accuracy of 0.8790 and an f1_score of 0.8238. In the next step, we investigate the feature importance of the final model to see which features have the highest influence and if that is explainable in reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#modelname.feature_importance_\n",
    "y = dt.feature_importances_\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots() \n",
    "width = 0.4 # the width of the bars \n",
    "ind = np.arange(len(y)) # the x locations for the groups\n",
    "ax.barh(ind, y, width, color='green')\n",
    "ax.set_yticks(ind+width/10)\n",
    "ax.set_yticklabels(train_val, minor=False)\n",
    "plt.title('Feature importance in XGBoost Classifier')\n",
    "plt.xlabel('Relative importance')\n",
    "plt.ylabel('feature') \n",
    "plt.grid()\n",
    "plt.figure(figsize=(12,12))\n",
    "fig.set_size_inches(12, 12, forward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature by far, outshining all other features, is the marital status with the value Married-civ-spouse that has the most influence on the model. The value corresponds to a person that is married and their partner is not part of the US armed forces in any way. Unfortunately, as we can see below it does not seem that there is a clear tendency towards one of the income classes for this feature and it is not directly clear why its influence is that high. Other more important features are better explainable, e.g., the amount of training years: the more training years one has the more probable is a high income. It is also explainable why capital gain and capital loss have a high influence, because if you have an higher income, it is more likely that you invest money, as you do not necessary need all money for living expenses. This leads to capital gains or losses over time. One top of this being an executive as occupation does have a high impact as well, which makes sense, because most often managers earn more than \"normal\" employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People married to a civil partner: 22379\n",
      "People of that group with high income: 9984\n",
      "People of that group with low income: 12395\n"
     ]
    }
   ],
   "source": [
    "print(f'People married to a civil partner: {len(df[(df[\"marital-status\"]==\"Married-civ-spouse\")])}')\n",
    "print(f'People of that group with high income: {len(df[(df[\"marital-status\"]==\"Married-civ-spouse\")&(df[\"income\"]==\">50K\")])}')\n",
    "print(f'People of that group with low income: {len(df[(df[\"marital-status\"]==\"Married-civ-spouse\")&(df[\"income\"]!=\">50K\")])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a last step, we investigate if we can see a tendency in the false negative and false positive predictions that could explain why the model has problems in classifying them. We revert our preprocessing steps again to see if we can recognize tendencies in the original features and look at the distribution of our false negatives and false positives and compare them to their counterparts in the original dataset. We only compare the distributions of the numerical features due to simplicity reasons. It has to be noted that we have changed the naming of educational-num to training-num in the course of this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the defined functions for revert the ohe \n",
    "df_comparison = revert_ohe(data_test)\n",
    "# concate test set, target and final prediction for further use\n",
    "df_comparison = pd.concat([df_comparison.reset_index(), target_test.reset_index(drop=True),pd.Series(prediction),], axis=1).set_index('index')\n",
    "df_comparison.rename(columns={0 :'Prediction'}, inplace=True )\n",
    "# on top of that we inverse transform the numerical columns and change them to integer again\n",
    "numerical_features = ['age','training-num', 'capital-gain','capital-loss','hours-per-week' ]\n",
    "df_comparison[numerical_features] = scaler.inverse_transform(df_comparison[numerical_features])\n",
    "df_comparison[numerical_features] = df_comparison[numerical_features].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe containing only wrong predictions\n",
    "df_wrong_predictions = df_comparison[(df_comparison.income!=df_comparison.Prediction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the comparison of the distribution for high income persons to those that have been misclassified as high income (false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>11687.00</td>\n",
       "      <td>44.28</td>\n",
       "      <td>10.56</td>\n",
       "      <td>19.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational-num</th>\n",
       "      <td>11687.00</td>\n",
       "      <td>11.60</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>11687.00</td>\n",
       "      <td>4042.24</td>\n",
       "      <td>14756.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>11687.00</td>\n",
       "      <td>193.53</td>\n",
       "      <td>593.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3683.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>11687.00</td>\n",
       "      <td>45.45</td>\n",
       "      <td>11.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count     mean       std    min    25%    50%    75%  \\\n",
       "age              11687.00    44.28     10.56  19.00  36.00  43.00  51.00   \n",
       "educational-num  11687.00    11.60      2.38   1.00  10.00  12.00  13.00   \n",
       "capital-gain     11687.00  4042.24  14756.77   0.00   0.00   0.00   0.00   \n",
       "capital-loss     11687.00   193.53    593.21   0.00   0.00   0.00   0.00   \n",
       "hours-per-week   11687.00    45.45     11.09   1.00  40.00  40.00  50.00   \n",
       "\n",
       "                      max  \n",
       "age                 90.00  \n",
       "educational-num     16.00  \n",
       "capital-gain     99999.00  \n",
       "capital-loss      3683.00  \n",
       "hours-per-week      99.00  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['income']=='>50K'].describe().transpose().applymap(\"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>778.00</td>\n",
       "      <td>42.67</td>\n",
       "      <td>11.55</td>\n",
       "      <td>22.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training-num</th>\n",
       "      <td>778.00</td>\n",
       "      <td>10.07</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>778.00</td>\n",
       "      <td>9.55</td>\n",
       "      <td>266.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7430.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>778.00</td>\n",
       "      <td>19.88</td>\n",
       "      <td>191.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2377.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>778.00</td>\n",
       "      <td>43.99</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count   mean     std    min    25%    50%    75%      max\n",
       "age             778.00  42.67   11.55  22.00  34.00  41.00  50.00    81.00\n",
       "training-num    778.00  10.07    2.22   2.00   9.00  10.00  11.00    16.00\n",
       "capital-gain    778.00   9.55  266.38   0.00   0.00   0.00   0.00  7430.00\n",
       "capital-loss    778.00  19.88  191.66   0.00   0.00   0.00   0.00  2377.00\n",
       "hours-per-week  778.00  43.99   11.00   2.00  40.00  40.00  50.00    99.00"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong_predictions[df_wrong_predictions['income']==1][['age','training-num','capital-gain','capital-loss','hours-per-week']].describe().transpose().applymap(\"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are some small differences in the distributions for age that seem rather marginal around the age of 40. However, we can see differences of more than one educational-year lower in the overall mean which might explain, why the algorithm classifies these examples as low income, since lower educational-years are an indicator for lower income. On top of that, we see that those false negatives (high income - low prediction) have overall nearly no capital-gains or capital-losses. This can also be a reason why they are classified as low income, because high values are an indicator for higher income and wealth, e.g., due to invested capital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>37155.00</td>\n",
       "      <td>36.87</td>\n",
       "      <td>14.10</td>\n",
       "      <td>17.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educational-num</th>\n",
       "      <td>37155.00</td>\n",
       "      <td>9.60</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>37155.00</td>\n",
       "      <td>147.01</td>\n",
       "      <td>936.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41310.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>37155.00</td>\n",
       "      <td>54.15</td>\n",
       "      <td>313.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4356.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>37155.00</td>\n",
       "      <td>38.84</td>\n",
       "      <td>12.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count    mean     std    min    25%    50%    75%  \\\n",
       "age              37155.00   36.87   14.10  17.00  25.00  34.00  46.00   \n",
       "educational-num  37155.00    9.60    2.44   1.00   9.00   9.00  10.00   \n",
       "capital-gain     37155.00  147.01  936.75   0.00   0.00   0.00   0.00   \n",
       "capital-loss     37155.00   54.15  313.32   0.00   0.00   0.00   0.00   \n",
       "hours-per-week   37155.00   38.84   12.36   1.00  35.00  40.00  40.00   \n",
       "\n",
       "                      max  \n",
       "age                 90.00  \n",
       "educational-num     16.00  \n",
       "capital-gain     41310.00  \n",
       "capital-loss      4356.00  \n",
       "hours-per-week      99.00  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['income']=='<=50K'].describe().transpose().applymap(\"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>404.00</td>\n",
       "      <td>43.93</td>\n",
       "      <td>10.12</td>\n",
       "      <td>24.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>88.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training-num</th>\n",
       "      <td>404.00</td>\n",
       "      <td>11.83</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>404.00</td>\n",
       "      <td>122.06</td>\n",
       "      <td>789.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6767.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>404.00</td>\n",
       "      <td>46.63</td>\n",
       "      <td>296.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2258.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>404.00</td>\n",
       "      <td>46.49</td>\n",
       "      <td>11.69</td>\n",
       "      <td>2.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count    mean     std    min    25%    50%    75%      max\n",
       "age             404.00   43.93   10.12  24.00  36.00  43.00  51.00    88.00\n",
       "training-num    404.00   11.83    2.06   3.00  10.00  13.00  13.00    16.00\n",
       "capital-gain    404.00  122.06  789.30   0.00   0.00   0.00   0.00  6767.00\n",
       "capital-loss    404.00   46.63  296.81   0.00   0.00   0.00   0.00  2258.00\n",
       "hours-per-week  404.00   46.49   11.69   2.00  40.00  43.00  50.00    99.00"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong_predictions[df_wrong_predictions['income']==0][['age','training-num','capital-gain','capital-loss','hours-per-week']].describe().transpose().applymap(\"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compare the distributions for lower income to those that have been misclassified as higher income, although they have lower income and see if we can spot differences that might explain why it is classified as high income. In this case, we detect that the mean of educational-years are more than two years higher than the one for lower income and even higher than the mean of people with higher income as seen above. In addition, there is a difference of approximately 8 years in the mean of hours-per-week and age, which is again a strong indicatior and possible explanation, why these examples are classified wrongly as high income. The differences in capital-gain and -loss are rather marginal again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a conclusion for this part this part, we will look into different rows that have been classified wrong for the specific target to see if something anomal stands out directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38546</th>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40209</th>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21144</th>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31262</th>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34560</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>England</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36933</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26388</th>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34231</th>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30758</th>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26738</th>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12239</th>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1485</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37834</th>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  training-num  gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "index                                                                          \n",
       "524     53            10       0             0             0              50   \n",
       "38546   42            16       0             0             0              40   \n",
       "40209   50            12       0             0             0              45   \n",
       "21144   41            11       0             0             0              40   \n",
       "31262   32            13       0             0             0              44   \n",
       "34560   72             9       1             0             0              50   \n",
       "36933   32             9       0             0             0              40   \n",
       "26388   31            13       0             0             0              60   \n",
       "34231   57             9       0             0             0              40   \n",
       "30758   31             9       0             0             0              48   \n",
       "2963    57            10       0             0             0              84   \n",
       "26738   39            11       0             0             0              40   \n",
       "12239   35            10       0             0             0              60   \n",
       "8135    28            10       0             0          1485              40   \n",
       "37834   33             9       1             0             0              40   \n",
       "\n",
       "          workclass     education      marital-status        occupation  \\\n",
       "index                                                                     \n",
       "524       Local-gov  Some-college  Married-civ-spouse   Exec-managerial   \n",
       "38546       Private          11th  Married-civ-spouse    Prof-specialty   \n",
       "40209       Private    Assoc-acdm  Married-civ-spouse      Craft-repair   \n",
       "21144     State-gov     Assoc-voc  Married-civ-spouse   Exec-managerial   \n",
       "31262       Private     Bachelors  Married-civ-spouse             Sales   \n",
       "34560       Private       HS-grad  Married-civ-spouse   Exec-managerial   \n",
       "36933   Federal-gov       HS-grad  Married-civ-spouse      Tech-support   \n",
       "26388       Private     Bachelors  Married-civ-spouse      Adm-clerical   \n",
       "34231  Self-emp-inc       HS-grad  Married-civ-spouse   Exec-managerial   \n",
       "30758     Local-gov       HS-grad  Married-civ-spouse   Protective-serv   \n",
       "2963        Private  Some-college  Married-civ-spouse  Transport-moving   \n",
       "26738       Private     Assoc-voc  Married-civ-spouse   Exec-managerial   \n",
       "12239       Private  Some-college  Married-civ-spouse   Exec-managerial   \n",
       "8135        Private  Some-college  Married-civ-spouse      Adm-clerical   \n",
       "37834       Private       HS-grad  Married-civ-spouse   Exec-managerial   \n",
       "\n",
       "      relationship native-country  income  Prediction  \n",
       "index                                                  \n",
       "524        Husband  United-States       0           1  \n",
       "38546      Husband              ?       0           1  \n",
       "40209      Husband  United-States       0           1  \n",
       "21144      Husband  United-States       0           1  \n",
       "31262      Husband  United-States       0           1  \n",
       "34560         Wife        England       0           1  \n",
       "36933      Husband  United-States       0           1  \n",
       "26388      Husband              ?       0           1  \n",
       "34231      Husband  United-States       0           1  \n",
       "30758      Husband  United-States       0           1  \n",
       "2963       Husband  United-States       0           1  \n",
       "26738      Husband  United-States       0           1  \n",
       "12239      Husband  United-States       0           1  \n",
       "8135       Husband  United-States       0           1  \n",
       "37834         Wife  United-States       0           1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong_predictions[df_wrong_predictions['income']==0].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the false positive sample, we can see no direct extreme, interesting behaviour outside the fact the number of educational years seems to be higher on average, which might explain the high prediction and furthermore, that we have a lot of persons in executive roles (occupation feature), which typically earn more money. Otherwise, the features are more of an indicator for lower income class like capital-gains and losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>training-num</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11488</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45549</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34382</th>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38439</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26572</th>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42586</th>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35649</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27715</th>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17642</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37297</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10519</th>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17283</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28769</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760</th>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37902</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  training-num  gender  capital-gain  capital-loss  hours-per-week  \\\n",
       "index                                                                          \n",
       "11488   38             9       0             0             0              40   \n",
       "45549   26            10       0             0             0              55   \n",
       "34382   43             9       0             0             0              40   \n",
       "38439   42             9       0             0             0              40   \n",
       "26572   59             6       0             0             0              40   \n",
       "42586   27            13       0             0             0              40   \n",
       "35649   50             9       0             0             0              40   \n",
       "27715   46             9       0             0             0              40   \n",
       "17642   52             9       0             0             0              40   \n",
       "37297   36             9       0             0             0              50   \n",
       "10519   31             6       0             0             0              55   \n",
       "17283   38             9       1             0             0              40   \n",
       "28769   30             9       0             0             0              65   \n",
       "7760    49            11       0             0             0               9   \n",
       "37902   30             9       0             0             0              40   \n",
       "\n",
       "              workclass     education      marital-status         occupation  \\\n",
       "index                                                                          \n",
       "11488           Private       HS-grad  Married-civ-spouse   Transport-moving   \n",
       "45549         Local-gov  Some-college  Married-civ-spouse    Protective-serv   \n",
       "34382           Private       HS-grad  Married-civ-spouse      Other-service   \n",
       "38439           Private       HS-grad  Married-civ-spouse  Handlers-cleaners   \n",
       "26572           Private          11th  Married-civ-spouse   Transport-moving   \n",
       "42586           Private     Bachelors  Married-civ-spouse       Tech-support   \n",
       "35649  Self-emp-not-inc       HS-grad  Married-civ-spouse   Transport-moving   \n",
       "27715           Private       HS-grad  Married-civ-spouse   Transport-moving   \n",
       "17642           Private       HS-grad  Married-civ-spouse       Craft-repair   \n",
       "37297           Private       HS-grad  Married-civ-spouse       Adm-clerical   \n",
       "10519  Self-emp-not-inc          11th  Married-civ-spouse    Farming-fishing   \n",
       "17283         State-gov       HS-grad  Married-civ-spouse     Prof-specialty   \n",
       "28769           Private       HS-grad  Married-civ-spouse   Transport-moving   \n",
       "7760        Federal-gov     Assoc-voc  Married-civ-spouse       Adm-clerical   \n",
       "37902           Private       HS-grad  Married-civ-spouse  Machine-op-inspct   \n",
       "\n",
       "      relationship native-country  income  Prediction  \n",
       "index                                                  \n",
       "11488      Husband  United-States       1           0  \n",
       "45549      Husband  United-States       1           0  \n",
       "34382      Husband  United-States       1           0  \n",
       "38439      Husband  United-States       1           0  \n",
       "26572      Husband  United-States       1           0  \n",
       "42586      Husband              ?       1           0  \n",
       "35649      Husband  United-States       1           0  \n",
       "27715      Husband  United-States       1           0  \n",
       "17642      Husband  United-States       1           0  \n",
       "37297      Husband  United-States       1           0  \n",
       "10519      Husband              ?       1           0  \n",
       "17283         Wife  United-States       1           0  \n",
       "28769      Husband  United-States       1           0  \n",
       "7760       Husband  United-States       1           0  \n",
       "37902      Husband  United-States       1           0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong_predictions[df_wrong_predictions['income']==1].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is striking about those examples, is the fact that the number of educational years is in most cases 9 years or lower, which can be an indicator for the lower prediction, because they only graduated from high school. Unfortunately, there is no further outlying behaviour in this sample, expect for the fact that one person only works 9 hours per week, a clear reason for the lower prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Summary and Outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will give a short summary over all the finding and an outlook what could be further possibilites for the processing of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "- Good results overall in classification with best model accuracy = 0.8790 and f1 = 0.8238 on the test set.\n",
    "- XGBoost outperforms others by minimum two percentage points.\n",
    "- Bias in features may be present, but hard to verify, because the groups, especially for race, are rather small.\n",
    "- Bias due to a wrong train-test-split can happen fast and that needs to be handled with care. \n",
    "- One feature (marital-status_Married-civ-spouse) is responsible for more than 35% of overall feature importance.\n",
    "- Distributions of wrongly classified examples vary a lot in means of numerical variables compared to the means of the original target overall.\n",
    "- Reduction of features from 102 to 67 possible without performance loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlook:\n",
    "\n",
    "- Deep dive into the feature importance Married-civ-spouse.\n",
    "- Explore wrongly classified examples via, e.g., Lime or Local explainability.\n",
    "- Deep-dive into wrong classifications to come up with features to better distinguish those examples.\n",
    "- Handling or discarding of remaining '?' in dataset.\n",
    "- Checking if removing correlated features can improve the results.\n",
    "- Generate features for possible improvement of models (for example brute force linear combinations of features via featuretools package or brainstorming for possible feature combinations).\n",
    "- Outlier removal via e.g., standard statistics or algorithms like isolation forest to see if the results improve (e.g., missclassified person with only 9 hous of work).\n",
    "- Try out further models, for example LightGBM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}